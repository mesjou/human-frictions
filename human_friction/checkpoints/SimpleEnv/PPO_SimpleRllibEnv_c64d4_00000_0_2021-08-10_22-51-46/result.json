{"episode_reward_max": 36.05, "episode_reward_min": 4.049999999999999, "episode_reward_mean": 22.6049771674, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.049999999999997, 25.049999999999997, 24.049999999999997, 28.049999999999997, 25.05, 16.05, 29.050000000000004, 25.050000000000004, 15.049999999999999, 20.049999999999997, 27.05, 26.049999999999997, 21.049999999999997, 21.049999999999997, 18.049999999999997, 17.049999999999997, 17.05, 20.049999999999997, 27.049999999999997, 28.049999999999997, 30.049999999999997, 14.049999999999999, 30.049999999999997, 32.05, 12.049999999999999, 19.049999999999997, 32.05, 26.050000000000004, 27.049999999999997, 30.050000000000004, 22.049999999999997, 20.05, 29.049999999999997, 22.049999999999997, 18.050000000000004, 17.050000000000004, 17.05, 24.049999999999997, 30.049999999999997, 13.049999999999999, 31.049999999999997, 31.049999999999997, 14.049999999999999, 22.049999999999997, 23.049999999999997, 29.049999999999997, 27.049999999999997, 16.05, 20.05, 10.049999999999999, 25.049999999999997, 25.049999999999997, 23.049999999999997, 30.049999999999997, 21.049999999999997, 32.37519976, 16.049999999999997, 17.049999999999997, 12.049999999999999, 33.46003976, 28.05, 20.049999999999997, 18.05, 18.05, 21.049999999999997, 31.62043176, 27.050000000000004, 16.049999999999997, 24.049999999999997, 14.049999999999999, 21.05, 16.049999999999997, 22.049999999999997, 25.049999999999997, 16.049999999999997, 19.049999999999997, 15.049999999999999, 28.049999999999997, 26.049999999999997, 31.049999999999997, 31.37479176, 28.049999999999997, 32.05, 26.049999999999997, 26.049999999999997, 28.05, 26.049999999999997, 35.05, 29.049999999999997, 27.049999999999997, 16.049999999999997, 25.050000000000004, 31.31398376, 29.049999999999997, 17.049999999999997, 26.049999999999997, 20.050000000000004, 25.049999999999997, 15.049999999999999, 25.049999999999997, 25.049999999999997, 9.049999999999999, 20.049999999999997, 29.049999999999997, 23.049999999999997, 11.049999999999999, 12.049999999999999, 20.05, 25.049999999999997, 18.049999999999997, 26.049999999999997, 13.049999999999999, 23.049999999999997, 20.049999999999997, 25.049999999999997, 14.049999999999999, 16.049999999999997, 29.049999999999997, 22.049999999999997, 16.049999999999997, 14.049999999999999, 24.049999999999997, 27.049999999999997, 23.049999999999997, 20.05, 16.049999999999997, 26.049999999999997, 25.049999999999997, 31.049999999999997, 18.05, 22.05, 18.050000000000004, 21.049999999999997, 31.59961576, 16.049999999999997, 19.049999999999997, 14.049999999999999, 25.049999999999997, 30.049999999999997, 21.050000000000004, 11.049999999999999, 24.049999999999997, 25.049999999999997, 17.050000000000004, 21.050000000000004, 10.049999999999999, 15.049999999999999, 27.049999999999997, 18.049999999999997, 21.049999999999997, 16.049999999999997, 28.049999999999997, 21.049999999999997, 25.050000000000004, 23.049999999999997, 13.049999999999999, 24.049999999999997, 17.049999999999997, 27.049999999999997, 18.049999999999997, 29.050000000000004, 16.05, 17.05, 19.05, 20.049999999999997, 29.049999999999997, 13.049999999999999, 32.05, 23.050000000000004, 28.049999999999997, 25.049999999999997, 26.049999999999997, 22.049999999999997, 27.049999999999997, 28.050000000000004, 13.049999999999999, 22.049999999999997, 33.05, 18.049999999999997, 18.049999999999997, 27.050000000000004, 20.049999999999997, 27.049999999999997, 26.049999999999997, 30.049999999999997, 23.049999999999997, 24.049999999999997, 27.049999999999997, 20.05, 12.049999999999999, 23.05, 20.049999999999997, 28.05, 20.049999999999997, 22.05, 19.05, 21.050000000000004, 18.049999999999997, 26.049999999999997, 30.049999999999997, 16.049999999999997, 19.05, 24.049999999999997, 20.049999999999997, 20.049999999999997, 30.049999999999997, 31.049999999999997, 24.049999999999997, 24.05, 32.59921576, 21.049999999999997, 30.05, 29.049999999999997, 21.049999999999997, 24.05, 24.050000000000004, 27.05, 18.049999999999997, 20.049999999999997, 16.049999999999997, 20.049999999999997, 31.049999999999997, 21.049999999999997, 27.049999999999997, 17.050000000000004, 29.049999999999997, 25.049999999999997, 28.049999999999997, 6.049999999999999, 18.049999999999997, 28.049999999999997, 23.049999999999997, 23.05, 25.05, 26.049999999999997, 30.049999999999997, 17.049999999999997, 17.05, 20.049999999999997, 18.05, 35.05, 15.049999999999999, 21.05, 13.049999999999999, 25.049999999999997, 9.049999999999999, 24.049999999999997, 23.049999999999997, 28.05, 22.049999999999997, 27.049999999999997, 18.049999999999997, 19.05, 19.05, 20.049999999999997, 30.050000000000004, 13.049999999999999, 30.049999999999997, 32.47640776, 31.05, 23.05, 21.049999999999997, 26.049999999999997, 28.049999999999997, 28.05, 23.049999999999997, 22.050000000000004, 32.05, 21.049999999999997, 18.049999999999997, 32.74487176, 30.049999999999997, 30.049999999999997, 19.05, 25.049999999999997, 19.05, 31.049999999999997, 32.25058800000001, 29.049999999999997, 31.270988000000003, 25.049999999999997, 32.31519976, 16.049999999999997, 32.45882376, 20.049999999999997, 29.049999999999997, 26.049999999999997, 30.049999999999997, 27.050000000000004, 30.049999999999997, 12.049999999999999, 23.049999999999997, 19.049999999999997, 15.049999999999999, 28.049999999999997, 22.050000000000004, 25.049999999999997, 21.049999999999997, 18.049999999999997, 33.05, 18.049999999999997, 34.49923176, 24.049999999999997, 31.190188000000003, 19.05, 31.049999999999997, 29.049999999999997, 21.049999999999997, 34.05, 21.049999999999997, 31.049999999999997, 12.049999999999999, 28.049999999999997, 22.049999999999997, 22.049999999999997, 25.049999999999997, 23.049999999999997, 18.05, 17.049999999999997, 15.049999999999999, 31.211583760000003, 31.049999999999997, 20.049999999999997, 23.049999999999997, 21.049999999999997, 22.049999999999997, 28.049999999999997, 24.05, 21.050000000000004, 30.049999999999997, 29.049999999999997, 14.049999999999999, 27.050000000000004, 30.049999999999997, 23.049999999999997, 24.049999999999997, 25.049999999999997, 26.049999999999997, 20.049999999999997, 20.049999999999997, 26.050000000000004, 25.049999999999997, 33.31641576, 21.049999999999997, 19.049999999999997, 31.170188000000003, 26.050000000000004, 23.049999999999997, 27.05, 31.049999999999997, 30.049999999999997, 23.050000000000004, 24.050000000000004, 17.049999999999997, 31.21279176, 28.049999999999997, 16.05, 22.049999999999997, 21.050000000000004, 20.049999999999997, 25.049999999999997, 21.049999999999997, 21.050000000000004, 15.049999999999999, 15.049999999999999, 33.43721576, 24.050000000000004, 28.049999999999997, 15.049999999999999, 31.538007760000003, 23.049999999999997, 23.049999999999997, 25.049999999999997, 13.049999999999999, 31.050000000000004, 28.050000000000004, 11.049999999999999, 28.050000000000004, 27.050000000000004, 21.049999999999997, 29.049999999999997, 30.049999999999997, 29.049999999999997, 25.05, 25.049999999999997, 14.049999999999999, 23.049999999999997, 24.049999999999997, 28.049999999999997, 31.23318376, 31.049999999999997, 28.049999999999997, 20.049999999999997, 18.049999999999997, 16.049999999999997, 20.049999999999997, 25.049999999999997, 31.296415760000002, 17.049999999999997, 22.049999999999997, 22.049999999999997, 10.049999999999999, 15.049999999999999, 31.295199760000003, 28.049999999999997, 30.049999999999997, 16.05, 26.049999999999997, 25.049999999999997, 17.049999999999997, 11.049999999999999, 23.049999999999997, 27.049999999999997, 13.049999999999999, 17.049999999999997, 25.050000000000004, 26.049999999999997, 26.049999999999997, 21.049999999999997, 24.049999999999997, 19.049999999999997, 11.049999999999999, 14.049999999999999, 23.049999999999997, 20.049999999999997, 26.049999999999997, 28.049999999999997, 18.049999999999997, 19.049999999999997, 12.049999999999999, 22.05, 21.05, 28.049999999999997, 31.25439176, 28.049999999999997, 13.049999999999999, 22.05, 16.05, 22.049999999999997, 24.049999999999997, 31.049999999999997, 12.049999999999999, 20.049999999999997, 22.049999999999997, 10.049999999999999, 17.049999999999997, 33.05, 25.049999999999997, 26.049999999999997, 20.049999999999997, 23.050000000000004, 20.049999999999997, 31.31641576, 23.05, 16.049999999999997, 18.049999999999997, 13.049999999999999, 36.05, 21.049999999999997, 20.05, 16.05, 9.049999999999999, 20.049999999999997, 23.049999999999997, 18.049999999999997, 17.049999999999997, 26.049999999999997, 31.497623760000003, 22.05, 14.049999999999999, 30.05, 22.049999999999997, 13.049999999999999, 13.049999999999999, 18.049999999999997, 31.49800776, 24.05, 29.049999999999997, 19.05, 23.049999999999997, 27.049999999999997, 27.049999999999997, 17.049999999999997, 17.05, 11.049999999999999, 18.049999999999997, 28.049999999999997, 15.049999999999999, 25.049999999999997, 21.049999999999997, 22.049999999999997, 26.049999999999997, 27.049999999999997, 28.049999999999997, 25.05, 23.050000000000004, 18.049999999999997, 27.05, 18.049999999999997, 25.049999999999997, 14.049999999999999, 16.05, 21.049999999999997, 30.049999999999997, 29.049999999999997, 12.049999999999999, 15.049999999999999, 29.049999999999997, 12.049999999999999, 15.049999999999999, 7.049999999999999, 18.05, 21.049999999999997, 25.049999999999997, 20.049999999999997, 28.049999999999997, 22.049999999999997, 31.37762376, 31.582455760000002, 16.05, 25.049999999999997, 22.05, 16.049999999999997, 20.049999999999997, 21.049999999999997, 12.049999999999999, 27.049999999999997, 30.049999999999997, 22.049999999999997, 14.049999999999999, 24.049999999999997, 26.050000000000004, 26.049999999999997, 16.05, 21.049999999999997, 29.050000000000004, 17.049999999999997, 12.049999999999999, 26.049999999999997, 24.049999999999997, 12.049999999999999, 31.39479176, 18.05, 19.05, 11.049999999999999, 25.049999999999997, 22.049999999999997, 24.049999999999997, 15.049999999999999, 10.049999999999999, 18.05, 28.049999999999997, 27.049999999999997, 16.049999999999997, 24.049999999999997, 19.049999999999997, 14.049999999999999, 21.049999999999997, 18.05, 21.050000000000004, 22.049999999999997, 19.049999999999997, 21.049999999999997, 27.049999999999997, 19.05, 23.049999999999997, 26.049999999999997, 26.049999999999997, 32.05, 18.049999999999997, 17.049999999999997, 22.05, 9.049999999999999, 24.049999999999997, 22.05, 31.17279176, 30.050000000000004, 26.05, 10.049999999999999, 18.049999999999997, 17.049999999999997, 26.050000000000004, 24.049999999999997, 21.049999999999997, 17.049999999999997, 18.049999999999997, 16.05, 15.049999999999999, 24.049999999999997, 24.049999999999997, 25.05, 32.37600776, 19.049999999999997, 26.049999999999997, 18.05, 22.049999999999997, 21.049999999999997, 32.05, 18.05, 25.049999999999997, 27.049999999999997, 8.049999999999999, 23.05, 16.05, 26.049999999999997, 27.049999999999997, 30.049999999999997, 14.049999999999999, 23.049999999999997, 23.049999999999997, 20.049999999999997, 32.05, 5.049999999999999, 25.050000000000004, 13.049999999999999, 23.049999999999997, 10.049999999999999, 25.049999999999997, 33.62245576, 33.37762376, 21.049999999999997, 31.049999999999997, 21.049999999999997, 32.05, 30.049999999999997, 20.049999999999997, 17.049999999999997, 29.049999999999997, 29.049999999999997, 17.050000000000004, 29.049999999999997, 31.049999999999997, 20.049999999999997, 19.05, 27.05, 16.05, 29.050000000000004, 17.05, 20.05, 29.050000000000004, 31.049999999999997, 29.049999999999997, 21.049999999999997, 28.049999999999997, 19.049999999999997, 31.049999999999997, 19.049999999999997, 15.049999999999999, 19.049999999999997, 28.049999999999997, 26.050000000000004, 20.049999999999997, 12.049999999999999, 27.049999999999997, 24.049999999999997, 29.049999999999997, 18.049999999999997, 32.29560776, 16.05, 26.050000000000004, 31.49841576, 24.049999999999997, 26.049999999999997, 29.049999999999997, 27.049999999999997, 16.049999999999997, 31.580839760000003, 20.049999999999997, 22.05, 27.049999999999997, 7.049999999999999, 31.64123176, 12.049999999999999, 32.05, 10.05, 28.049999999999997, 20.049999999999997, 18.05, 25.050000000000004, 31.27398376, 24.049999999999997, 27.05, 23.049999999999997, 22.049999999999997, 14.049999999999999, 22.049999999999997, 17.049999999999997, 19.049999999999997, 19.05, 20.049999999999997, 16.05, 20.049999999999997, 28.049999999999997, 28.050000000000004, 21.05, 24.049999999999997, 20.05, 16.049999999999997, 30.050000000000004, 27.049999999999997, 23.049999999999997, 20.05, 20.049999999999997, 22.049999999999997, 29.050000000000004, 18.049999999999997, 16.049999999999997, 29.049999999999997, 32.35560776, 17.05, 14.049999999999999, 26.049999999999997, 13.049999999999999, 27.049999999999997, 28.049999999999997, 33.41761576, 18.05, 25.049999999999997, 14.049999999999999, 19.049999999999997, 11.049999999999999, 15.049999999999999, 30.050000000000004, 28.049999999999997, 23.049999999999997, 17.049999999999997, 18.049999999999997, 14.049999999999999, 26.049999999999997, 13.049999999999999, 30.050000000000004, 20.049999999999997, 25.049999999999997, 26.049999999999997, 25.050000000000004, 12.049999999999999, 17.049999999999997, 28.049999999999997, 34.05, 28.049999999999997, 24.049999999999997, 32.29641576, 6.049999999999999, 20.050000000000004, 31.315607760000002, 26.049999999999997, 33.05, 28.050000000000004, 27.049999999999997, 24.050000000000004, 26.049999999999997, 14.049999999999999, 25.049999999999997, 17.05, 18.049999999999997, 20.049999999999997, 31.049999999999997, 7.049999999999999, 21.049999999999997, 23.049999999999997, 15.049999999999999, 17.049999999999997, 14.049999999999999, 18.049999999999997, 24.049999999999997, 24.049999999999997, 23.049999999999997, 26.049999999999997, 17.049999999999997, 19.049999999999997, 22.049999999999997, 31.049999999999997, 24.049999999999997, 27.049999999999997, 28.05, 8.049999999999999, 21.049999999999997, 20.049999999999997, 23.049999999999997, 4.049999999999999, 22.05, 22.05, 24.049999999999997, 21.049999999999997, 17.049999999999997, 22.049999999999997, 29.049999999999997, 18.049999999999997, 20.05, 25.049999999999997, 24.049999999999997, 30.049999999999997, 15.049999999999999, 31.458423760000002, 10.049999999999999, 24.050000000000004, 32.05, 32.41721576, 27.049999999999997, 15.049999999999999], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1363300312047956, "mean_inference_ms": 0.5572812668029693, "mean_action_processing_ms": 0.04220270979469982, "mean_env_wait_ms": 0.04622633608503977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 4000, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 1608.361, "sample_throughput": 2487.004, "load_time_ms": 32.593, "load_throughput": 122724.796, "learn_time_ms": 2431.018, "learn_throughput": 1645.401, "update_time_ms": 1.989}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 67.9622573852539, "policy_loss": -0.11119089275598526, "vf_loss": 68.05682373046875, "vf_explained_var": 0.24310383200645447, "kl": 0.08318272233009338, "entropy": 2.2136783599853516, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 4000, "num_steps_trained": 4000, "num_agent_steps_trained": 4000}, "done": false, "episodes_total": 800, "training_iteration": 1, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-51-59", "timestamp": 1628628719, "time_this_iter_s": 4.11335015296936, "time_total_s": 4.11335015296936, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.11335015296936, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 33.48333333333333, "ram_util_percent": 70.71666666666668}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 36.827287760000004, "episode_reward_min": 4.05, "episode_reward_mean": 26.775840854500004, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.049999999999997, 22.049999999999997, 24.050000000000004, 19.049999999999997, 21.049999999999997, 22.05, 32.37802376, 26.050000000000004, 34.62285576, 27.049999999999997, 17.05, 18.05, 33.05, 26.049999999999997, 27.049999999999997, 31.41842376, 30.049999999999997, 29.05, 27.049999999999997, 25.049999999999997, 27.049999999999997, 33.05, 33.55921576, 27.049999999999997, 31.049999999999997, 21.050000000000004, 16.05, 27.05, 13.049999999999999, 29.049999999999997, 25.050000000000004, 33.641639760000004, 28.049999999999997, 31.33559976, 32.62083976, 31.37681576, 29.049999999999997, 35.05, 29.049999999999997, 31.438015760000003, 32.540839760000004, 27.049999999999997, 30.049999999999997, 35.05, 32.35762376, 36.05, 20.049999999999997, 15.049999999999999, 24.049999999999997, 24.049999999999997, 31.049999999999997, 25.049999999999997, 21.049999999999997, 24.049999999999997, 19.05, 31.049999999999997, 31.45761576, 19.05, 30.049999999999997, 18.05, 29.049999999999997, 31.049999999999997, 29.049999999999997, 28.050000000000004, 24.049999999999997, 22.049999999999997, 29.049999999999997, 23.049999999999997, 25.050000000000004, 31.517599760000003, 27.049999999999997, 23.050000000000004, 31.250588000000004, 24.049999999999997, 32.396415760000004, 32.37640776, 32.294799760000004, 17.049999999999997, 25.049999999999997, 31.230188000000002, 19.049999999999997, 30.049999999999997, 26.049999999999997, 20.049999999999997, 33.05, 24.049999999999997, 23.05, 30.049999999999997, 18.049999999999997, 15.049999999999999, 27.049999999999997, 20.050000000000004, 33.46003976, 19.049999999999997, 26.05, 18.049999999999997, 31.049999999999997, 26.049999999999997, 27.049999999999997, 26.049999999999997, 33.050000000000004, 32.25399976, 28.050000000000004, 31.33438376, 16.049999999999997, 31.049999999999997, 33.52003176, 29.049999999999997, 18.049999999999997, 28.049999999999997, 27.049999999999997, 26.049999999999997, 26.049999999999997, 22.049999999999997, 19.049999999999997, 32.05, 22.05, 24.049999999999997, 31.703655760000004, 32.43801576, 24.049999999999997, 13.049999999999999, 23.049999999999997, 25.049999999999997, 27.049999999999997, 29.049999999999997, 23.049999999999997, 28.049999999999997, 31.270988000000003, 29.049999999999997, 35.60204776, 34.662039760000006, 31.049999999999997, 25.049999999999997, 17.05, 30.049999999999997, 26.05, 34.60043176, 20.049999999999997, 29.049999999999997, 25.049999999999997, 32.05, 32.43801576, 21.049999999999997, 21.049999999999997, 24.049999999999997, 23.05, 28.049999999999997, 31.270988000000003, 27.049999999999997, 31.210188000000002, 26.049999999999997, 16.049999999999997, 28.049999999999997, 23.049999999999997, 33.60083176, 24.050000000000004, 35.58245576, 34.641239760000005, 23.050000000000004, 34.827287760000004, 28.050000000000004, 19.049999999999997, 24.049999999999997, 28.049999999999997, 27.05, 23.05, 25.049999999999997, 23.050000000000004, 28.049999999999997, 14.049999999999999, 27.049999999999997, 29.049999999999997, 23.050000000000004, 18.05, 29.049999999999997, 26.049999999999997, 32.05, 27.049999999999997, 24.05, 32.49841576, 32.35599976, 31.43720776, 17.05, 23.049999999999997, 30.049999999999997, 34.46003976, 30.049999999999997, 34.540439760000005, 34.66325576, 29.049999999999997, 28.049999999999997, 25.050000000000004, 22.049999999999997, 32.05, 20.049999999999997, 19.049999999999997, 35.05, 32.35599976, 33.05, 32.55921576, 28.049999999999997, 33.39721576, 21.049999999999997, 27.049999999999997, 31.275199760000003, 19.049999999999997, 28.049999999999997, 21.05, 24.05, 23.049999999999997, 34.05, 33.41681576, 34.05, 23.049999999999997, 32.05, 30.049999999999997, 19.049999999999997, 30.049999999999997, 31.41721576, 31.049999999999997, 15.049999999999999, 36.827287760000004, 17.049999999999997, 30.049999999999997, 32.39761576, 26.05, 27.049999999999997, 18.050000000000004, 21.049999999999997, 16.049999999999997, 30.05, 32.641231760000004, 23.049999999999997, 35.76486376, 32.05, 24.049999999999997, 22.05, 22.049999999999997, 33.05, 28.049999999999997, 21.049999999999997, 25.049999999999997, 35.05, 25.050000000000004, 30.049999999999997, 23.05, 27.049999999999997, 32.05, 23.049999999999997, 31.43923176, 20.050000000000004, 23.05, 24.050000000000004, 30.049999999999997, 23.049999999999997, 32.418023760000004, 26.049999999999997, 27.050000000000004, 32.050000000000004, 33.05, 29.049999999999997, 33.52043976, 22.049999999999997, 31.190188000000003, 24.049999999999997, 22.049999999999997, 22.049999999999997, 21.049999999999997, 16.049999999999997, 29.049999999999997, 26.049999999999997, 26.049999999999997, 31.049999999999997, 32.43639976, 32.05, 23.049999999999997, 28.049999999999997, 15.049999999999999, 26.049999999999997, 31.050000000000004, 19.05, 30.049999999999997, 23.049999999999997, 27.050000000000004, 27.05, 30.049999999999997, 23.049999999999997, 31.049999999999997, 25.049999999999997, 4.05, 31.21278376, 30.05, 25.05, 27.05, 23.050000000000004, 22.05, 26.049999999999997, 20.049999999999997, 32.31479976, 33.37681576, 27.05, 28.049999999999997, 30.050000000000004, 32.49963176, 20.050000000000004, 22.049999999999997, 27.05, 31.149788, 16.05, 29.049999999999997, 32.47842376, 32.05, 32.05, 25.049999999999997, 30.049999999999997, 25.049999999999997, 33.46003976, 33.050000000000004, 28.049999999999997, 24.05, 18.05, 23.049999999999997, 32.49761576, 18.049999999999997, 25.049999999999997, 34.66325576, 29.049999999999997, 33.05, 26.049999999999997, 23.049999999999997, 28.049999999999997, 25.049999999999997, 16.049999999999997, 27.049999999999997, 18.05, 33.540039760000006, 29.049999999999997, 18.049999999999997, 27.049999999999997, 24.049999999999997, 24.049999999999997, 28.049999999999997, 25.049999999999997, 23.050000000000004, 17.049999999999997, 31.45761576, 22.049999999999997, 26.049999999999997, 32.050000000000004, 27.049999999999997, 21.049999999999997, 30.049999999999997, 32.35721576, 31.049999999999997, 32.35681576, 31.37478376, 24.049999999999997, 29.049999999999997, 32.45761576, 26.049999999999997, 29.049999999999997, 32.05, 32.05, 33.765271760000005, 26.049999999999997, 19.05, 27.049999999999997, 27.050000000000004, 27.05, 34.05, 32.05, 30.049999999999997, 32.41883176, 33.49882376, 31.049999999999997, 12.049999999999999, 33.60083976, 24.049999999999997, 26.050000000000004, 31.049999999999997, 30.049999999999997, 17.05, 18.049999999999997, 21.049999999999997, 25.05, 17.05, 28.05, 28.049999999999997, 33.05, 25.049999999999997, 31.05, 21.05, 21.049999999999997, 31.049999999999997, 23.049999999999997, 33.05, 31.049999999999997, 25.049999999999997, 26.049999999999997, 29.049999999999997, 33.47762376, 32.540839760000004, 36.76607976, 31.049999999999997, 31.049999999999997, 27.049999999999997, 27.050000000000004, 31.60164776, 17.05, 19.05, 19.050000000000004, 31.252791760000004, 20.049999999999997, 29.049999999999997, 33.05, 31.47882376, 31.314799760000003, 33.39761576, 13.049999999999999, 28.049999999999997, 21.049999999999997, 26.05, 24.05, 31.35762376, 29.049999999999997, 13.049999999999999, 22.049999999999997, 20.049999999999997, 23.05, 25.049999999999997, 23.049999999999997, 30.049999999999997, 26.050000000000004, 26.049999999999997, 33.72365576, 20.05, 17.049999999999997, 28.050000000000004, 31.049999999999997, 31.149788, 31.049999999999997, 26.050000000000004, 30.050000000000004, 11.049999999999999, 31.049999999999997, 24.049999999999997, 31.250588000000004, 30.049999999999997, 31.17198376, 31.049999999999997, 27.049999999999997, 15.049999999999999, 24.049999999999997, 32.47883176, 33.540839760000004, 31.049999999999997, 34.05, 32.39721576, 31.049999999999997, 20.05, 31.170188000000003, 32.05, 18.049999999999997, 26.049999999999997, 22.05, 32.53923176, 28.049999999999997, 26.049999999999997, 31.480039760000004, 26.049999999999997, 28.050000000000004, 28.05, 25.049999999999997, 33.642447759999996, 31.049999999999997, 31.37398376, 32.05, 18.049999999999997, 25.049999999999997, 35.581647759999996, 24.05, 25.049999999999997, 24.049999999999997, 17.05, 27.049999999999997, 32.05, 19.049999999999997, 13.049999999999999, 23.049999999999997, 26.05, 31.049999999999997, 27.049999999999997, 18.050000000000004, 31.250988000000003, 29.050000000000004, 18.049999999999997, 31.049999999999997, 30.050000000000004, 19.049999999999997, 30.05, 28.049999999999997, 17.049999999999997, 24.049999999999997, 30.049999999999997, 20.050000000000004, 28.049999999999997, 18.049999999999997, 31.35599976, 10.049999999999999, 31.049999999999997, 28.049999999999997, 26.049999999999997, 34.76486376, 21.05, 31.129788, 24.049999999999997, 16.049999999999997, 34.43923176, 27.049999999999997, 33.62204776, 28.049999999999997, 28.049999999999997, 20.049999999999997, 28.049999999999997, 28.049999999999997, 29.049999999999997, 23.049999999999997, 20.050000000000004, 28.049999999999997, 25.049999999999997, 31.049999999999997, 31.520031760000002, 34.05, 26.049999999999997, 33.37721576, 26.05, 21.049999999999997, 23.050000000000004, 14.049999999999999, 33.05, 31.049999999999997, 25.049999999999997, 26.049999999999997, 15.049999999999999, 25.049999999999997, 31.049999999999997, 25.049999999999997, 21.049999999999997, 24.05, 30.049999999999997, 32.416399760000004, 27.049999999999997, 24.05, 29.049999999999997, 24.050000000000004, 23.049999999999997, 13.049999999999999, 22.049999999999997, 22.05, 32.05, 29.049999999999997, 31.43720776, 32.50003976000001, 20.050000000000004, 15.049999999999999, 27.049999999999997, 25.049999999999997, 30.049999999999997, 31.049999999999997, 28.049999999999997, 26.049999999999997, 21.05, 28.049999999999997, 27.049999999999997, 25.05, 24.049999999999997, 23.05, 29.049999999999997, 27.049999999999997, 22.049999999999997, 18.050000000000004, 24.049999999999997, 33.05, 16.049999999999997, 29.049999999999997, 27.05, 27.049999999999997, 11.049999999999999, 18.049999999999997, 28.049999999999997, 33.68284776, 23.049999999999997, 24.049999999999997, 28.05, 25.049999999999997, 30.049999999999997, 28.049999999999997, 32.35640776, 20.049999999999997, 19.05, 31.41761576, 19.049999999999997, 25.049999999999997, 15.049999999999999, 24.049999999999997, 25.049999999999997, 16.05, 28.049999999999997, 21.05, 27.050000000000004, 27.049999999999997, 31.049999999999997, 29.049999999999997, 31.049999999999997, 29.049999999999997, 27.049999999999997, 27.05, 20.049999999999997, 31.049999999999997, 32.05, 21.05, 25.050000000000004, 21.050000000000004, 31.35519976, 35.56164776, 25.050000000000004, 25.050000000000004, 28.05, 29.049999999999997, 19.049999999999997, 33.702439760000004, 27.049999999999997, 32.643663759999995, 30.049999999999997, 33.662039760000006, 23.049999999999997, 19.05, 29.049999999999997, 29.05, 31.21359176, 27.049999999999997, 15.049999999999999, 31.435199760000003, 34.60003176, 32.25098800000001, 33.05, 33.05, 25.049999999999997, 32.53759976, 19.05, 31.233999760000003, 29.049999999999997, 18.049999999999997, 27.050000000000004, 32.05, 32.540039760000006, 27.049999999999997, 33.642447759999996, 32.05, 14.049999999999999, 30.049999999999997, 28.049999999999997, 17.05, 32.05, 27.049999999999997, 36.05, 26.049999999999997, 32.05, 31.33640776, 25.05, 34.05, 17.049999999999997, 31.049999999999997, 27.049999999999997, 28.049999999999997, 28.049999999999997, 33.05, 31.049999999999997, 18.049999999999997, 30.049999999999997, 31.415607760000004, 31.51882376, 33.66325576, 28.049999999999997, 27.050000000000004, 31.049999999999997, 29.049999999999997, 30.05, 26.049999999999997, 36.05, 24.049999999999997, 31.049999999999997, 25.049999999999997, 8.05, 32.05, 25.05, 25.050000000000004, 24.05, 26.050000000000004, 34.05, 35.05, 28.049999999999997, 25.050000000000004, 18.049999999999997, 19.05, 23.049999999999997, 29.049999999999997, 28.049999999999997, 18.05, 31.049999999999997, 24.049999999999997, 31.33640776, 32.43720776, 25.049999999999997, 32.39639976, 32.05, 24.049999999999997, 21.049999999999997, 21.049999999999997, 31.27278376, 29.049999999999997, 23.049999999999997, 28.049999999999997, 28.049999999999997, 21.049999999999997, 31.210588, 20.049999999999997, 20.049999999999997, 26.049999999999997, 30.05, 32.05, 31.049999999999997, 21.05, 20.050000000000004, 30.05, 22.049999999999997, 22.05, 31.049999999999997, 26.049999999999997, 25.049999999999997, 26.050000000000004, 32.76486376, 16.05, 31.17198376, 21.049999999999997, 34.58245576, 26.050000000000004, 31.58043176, 27.049999999999997, 21.049999999999997, 29.049999999999997, 22.050000000000004, 32.05, 30.049999999999997, 36.78607976, 35.68284776, 32.230588000000004, 15.049999999999999, 26.05, 30.049999999999997, 20.049999999999997, 21.049999999999997, 28.049999999999997, 22.049999999999997, 28.049999999999997, 32.35762376, 18.05, 34.05, 32.05, 32.55962376, 34.05, 33.05, 32.518423760000005, 32.05, 34.56083976, 19.050000000000004, 28.049999999999997, 16.049999999999997, 33.05, 31.29439176, 34.641639760000004, 32.52003176, 34.05, 20.05, 24.049999999999997, 25.049999999999997, 31.049999999999997, 27.049999999999997, 31.273999760000002, 29.049999999999997, 32.05, 24.049999999999997, 32.05, 27.049999999999997, 31.29520776, 29.049999999999997, 18.049999999999997, 20.05, 33.70284776], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336750880505734, "mean_inference_ms": 0.5468507612743726, "mean_action_processing_ms": 0.04173582477946189, "mean_env_wait_ms": 0.045988357713656905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 8000, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 1573.704, "sample_throughput": 2541.775, "load_time_ms": 16.796, "load_throughput": 238152.042, "learn_time_ms": 2234.616, "learn_throughput": 1790.017, "update_time_ms": 1.904}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 39.2804069519043, "policy_loss": -0.0835011899471283, "vf_loss": 39.34994888305664, "vf_explained_var": 0.5384314060211182, "kl": 0.046538256108760834, "entropy": 2.0598297119140625, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 8000, "num_steps_trained": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 1600, "training_iteration": 2, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-03", "timestamp": 1628628723, "time_this_iter_s": 3.596191883087158, "time_total_s": 7.7095420360565186, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.7095420360565186, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 37.65, "ram_util_percent": 69.94999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 37.05, "episode_reward_min": 13.049999999999999, "episode_reward_mean": 29.381162456300004, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.58245576, 27.050000000000004, 34.45883176, 31.458023760000003, 32.518823760000004, 34.52124776, 29.049999999999997, 32.53759976, 33.291388000000005, 33.52003176, 32.62285576, 27.049999999999997, 33.05, 27.049999999999997, 28.049999999999997, 28.049999999999997, 24.049999999999997, 31.189788, 31.291388000000005, 34.66366376, 17.049999999999997, 33.05, 30.049999999999997, 33.39762376, 34.72446376, 28.049999999999997, 31.13158376, 33.52124776, 23.050000000000004, 28.049999999999997, 26.050000000000004, 26.050000000000004, 29.050000000000004, 34.66285576, 33.55921576, 36.80647976, 31.049999999999997, 31.47882376, 29.049999999999997, 28.049999999999997, 25.05, 33.05, 30.049999999999997, 20.049999999999997, 30.049999999999997, 21.049999999999997, 35.05, 32.62123976, 34.05, 33.05, 33.47882376, 34.05, 31.233999760000003, 33.52003176, 28.05, 32.35599976, 30.049999999999997, 30.049999999999997, 29.049999999999997, 33.43923176, 19.050000000000004, 21.049999999999997, 26.050000000000004, 23.049999999999997, 32.05, 30.05, 27.049999999999997, 32.66082376, 35.05, 31.47841576, 29.049999999999997, 31.209788000000003, 31.049999999999997, 26.049999999999997, 19.049999999999997, 23.050000000000004, 28.05, 32.05, 31.49963176, 31.190188000000003, 32.33640776, 29.049999999999997, 33.41842376, 17.05, 31.49800776, 22.049999999999997, 22.050000000000004, 31.294791760000003, 33.05, 18.049999999999997, 28.049999999999997, 21.049999999999997, 31.049999999999997, 25.050000000000004, 24.050000000000004, 19.049999999999997, 21.049999999999997, 34.52124776, 32.478415760000004, 33.60083176, 35.70487176, 31.049999999999997, 28.050000000000004, 18.049999999999997, 33.41883176, 24.049999999999997, 32.45882376, 32.05, 33.37802376, 20.049999999999997, 31.049999999999997, 27.049999999999997, 32.05, 34.05, 33.43923176, 25.049999999999997, 33.45842376, 25.049999999999997, 35.05, 32.05, 25.049999999999997, 33.52124776, 34.05, 31.23279176, 14.049999999999999, 28.049999999999997, 26.049999999999997, 24.049999999999997, 31.170188000000003, 28.049999999999997, 26.049999999999997, 31.270988000000003, 33.05, 31.049999999999997, 29.049999999999997, 25.050000000000004, 33.66366376, 23.049999999999997, 32.64001576, 29.049999999999997, 33.05, 33.62285576, 30.049999999999997, 26.049999999999997, 33.05, 37.05, 31.049999999999997, 31.335199760000002, 31.47680776, 31.541247759999997, 30.05, 31.049999999999997, 31.294791760000003, 27.049999999999997, 32.05, 31.47721576, 16.049999999999997, 23.049999999999997, 31.050000000000004, 21.049999999999997, 33.45762376, 31.19278376, 20.050000000000004, 32.39802376, 25.049999999999997, 28.049999999999997, 22.049999999999997, 29.05, 29.049999999999997, 30.049999999999997, 29.049999999999997, 18.05, 33.46003976, 30.049999999999997, 33.05, 32.05, 25.05, 32.580431759999996, 33.60083176, 32.56083976, 25.049999999999997, 20.049999999999997, 31.169788000000004, 32.37721576, 31.230588000000004, 31.149788, 32.33762376, 26.049999999999997, 31.049999999999997, 32.05, 33.60002376, 29.049999999999997, 19.049999999999997, 31.33399176, 33.050000000000004, 34.05, 25.049999999999997, 31.27439176, 23.049999999999997, 31.19198376, 23.05, 30.050000000000004, 24.049999999999997, 27.049999999999997, 22.05, 31.43518376, 35.05, 30.05, 31.050000000000004, 22.05, 32.45882376, 31.05, 26.049999999999997, 30.050000000000004, 29.049999999999997, 33.642447759999996, 34.62163976, 32.39761576, 26.05, 31.049999999999997, 29.049999999999997, 33.291388000000005, 25.049999999999997, 27.049999999999997, 30.049999999999997, 31.049999999999997, 33.49883176, 31.272791760000004, 24.049999999999997, 31.291388000000005, 26.049999999999997, 27.049999999999997, 27.050000000000004, 31.190188000000003, 15.049999999999999, 33.05, 35.62204776, 33.05, 32.255207760000005, 29.049999999999997, 34.480039760000004, 32.45923176, 18.049999999999997, 31.049999999999997, 26.049999999999997, 27.049999999999997, 33.540039760000006, 32.05, 35.05, 31.049999999999997, 32.37721576, 25.049999999999997, 27.049999999999997, 31.149788, 35.703655760000004, 31.129788, 25.050000000000004, 33.05, 23.049999999999997, 30.049999999999997, 31.37762376, 32.47882376, 13.049999999999999, 33.58003176, 33.62285576, 30.050000000000004, 33.316815760000004, 32.05, 26.049999999999997, 34.56003176, 31.049999999999997, 27.05, 32.05, 26.050000000000004, 31.33640776, 31.170188000000003, 31.05, 26.049999999999997, 25.050000000000004, 15.049999999999999, 23.05, 31.049999999999997, 32.05, 32.43680776, 32.25058800000001, 31.149788, 27.049999999999997, 34.68284776, 24.050000000000004, 27.05, 20.049999999999997, 35.643663759999995, 34.05, 33.05, 28.049999999999997, 34.642447759999996, 36.68406376, 33.05, 32.05, 19.05, 30.049999999999997, 25.049999999999997, 31.250988000000003, 26.049999999999997, 30.049999999999997, 23.049999999999997, 31.45882376, 16.049999999999997, 33.05, 29.049999999999997, 31.458015760000002, 34.74527176000001, 28.049999999999997, 32.05, 33.41762376, 27.049999999999997, 31.149788, 33.05, 34.641231760000004, 32.05, 21.049999999999997, 32.05, 31.049999999999997, 25.05, 32.43720776, 25.049999999999997, 32.05, 24.05, 31.45681576, 26.049999999999997, 26.049999999999997, 22.050000000000004, 27.05, 34.70366376, 27.049999999999997, 31.129788, 30.049999999999997, 33.05, 32.47842376, 34.47923176, 32.05, 32.316815760000004, 32.31519976, 33.43923176, 34.05, 36.05, 24.05, 31.15198376, 28.049999999999997, 27.049999999999997, 31.05, 32.62163976, 33.05, 25.049999999999997, 29.050000000000004, 33.05, 31.149788, 29.049999999999997, 31.293191760000003, 33.49963176, 23.049999999999997, 19.049999999999997, 30.05, 26.049999999999997, 27.049999999999997, 34.480039760000004, 31.210588, 31.049999999999997, 26.049999999999997, 27.05, 35.68406376, 33.37721576, 31.049999999999997, 18.050000000000004, 24.049999999999997, 26.050000000000004, 30.05, 32.43641576, 25.049999999999997, 31.480039760000004, 30.049999999999997, 31.314791760000002, 19.049999999999997, 36.70406376, 31.149788, 34.05, 31.149788, 30.049999999999997, 34.540839760000004, 29.049999999999997, 34.05, 28.049999999999997, 31.35599976, 28.049999999999997, 28.049999999999997, 23.05, 33.56043176, 31.050000000000004, 21.049999999999997, 26.05, 16.05, 29.050000000000004, 29.05, 32.05, 31.049999999999997, 33.37802376, 33.43883176, 29.049999999999997, 32.47760776, 33.62124776, 28.05, 20.049999999999997, 31.27398376, 22.049999999999997, 30.049999999999997, 31.21318376, 27.049999999999997, 29.05, 31.05, 26.05, 31.050000000000004, 33.643663759999995, 33.60083976, 25.049999999999997, 24.05, 22.049999999999997, 31.31600776, 33.41721576, 33.43923176, 32.33519976, 30.049999999999997, 33.05, 27.049999999999997, 31.05, 28.05, 29.049999999999997, 19.050000000000004, 31.233583760000002, 26.049999999999997, 29.05, 25.049999999999997, 33.478415760000004, 23.05, 32.395207760000005, 32.37519976, 32.05, 24.049999999999997, 33.35762376, 27.049999999999997, 29.050000000000004, 25.049999999999997, 33.05, 23.049999999999997, 33.05, 19.049999999999997, 20.049999999999997, 31.23279176, 31.41761576, 31.049999999999997, 32.05, 31.41600776, 22.049999999999997, 28.049999999999997, 34.56164776, 31.049999999999997, 25.049999999999997, 22.049999999999997, 33.41681576, 34.05, 21.049999999999997, 24.050000000000004, 33.05, 30.049999999999997, 36.74527176000001, 23.049999999999997, 26.049999999999997, 23.049999999999997, 30.049999999999997, 28.049999999999997, 32.41883176, 32.05, 30.049999999999997, 30.05, 31.21359176, 28.050000000000004, 31.373991760000003, 32.49841576, 31.049999999999997, 20.05, 32.05, 35.64285576, 24.050000000000004, 30.049999999999997, 34.05, 28.049999999999997, 25.049999999999997, 36.70487176, 31.233583760000002, 32.46003976, 32.29399976, 31.049999999999997, 30.049999999999997, 25.049999999999997, 31.49800776, 27.049999999999997, 23.049999999999997, 32.37439976, 27.049999999999997, 28.049999999999997, 32.05, 30.049999999999997, 22.049999999999997, 31.049999999999997, 19.05, 32.05, 25.049999999999997, 21.05, 33.05, 32.05, 30.049999999999997, 25.049999999999997, 31.049999999999997, 32.05, 32.05, 35.66325576, 31.050000000000004, 31.050000000000004, 31.049999999999997, 34.56043176, 31.049999999999997, 31.250988000000003, 31.129788, 32.315599760000005, 30.049999999999997, 33.41761576, 30.05, 26.049999999999997, 32.05, 32.58002376, 32.29519976, 31.049999999999997, 33.39761576, 32.050000000000004, 28.049999999999997, 33.479631760000004, 34.60043176, 31.54043976, 32.29600776, 32.05, 32.05, 26.049999999999997, 32.46003976, 23.049999999999997, 24.049999999999997, 31.049999999999997, 20.049999999999997, 21.050000000000004, 28.05, 31.049999999999997, 31.35721576, 31.49719976, 19.049999999999997, 33.500439760000006, 35.05, 25.050000000000004, 32.05, 32.050000000000004, 31.39883176, 29.049999999999997, 32.56043176, 34.60083976, 31.049999999999997, 32.417207760000004, 34.45923176, 31.189788, 32.39762376, 35.05, 31.049999999999997, 24.05, 32.29641576, 31.05, 32.05, 31.049999999999997, 30.049999999999997, 23.05, 23.049999999999997, 33.05, 32.580431759999996, 31.049999999999997, 33.39762376, 31.295199760000003, 32.05, 28.049999999999997, 33.05, 33.05, 25.05, 33.46003976, 21.05, 22.049999999999997, 24.05, 31.250988000000003, 28.049999999999997, 32.45760776, 35.78567176000001, 21.049999999999997, 27.049999999999997, 26.049999999999997, 33.05, 27.049999999999997, 33.05, 35.05, 17.05, 22.050000000000004, 27.05, 31.27439176, 27.049999999999997, 27.05, 31.37599976, 32.31641576, 31.51882376, 31.190188000000003, 27.05, 27.049999999999997, 33.05, 26.049999999999997, 18.05, 31.517599760000003, 22.05, 29.049999999999997, 33.291388000000005, 34.39883176, 35.58245576, 30.049999999999997, 30.049999999999997, 31.41761576, 30.049999999999997, 33.56043176, 34.66325576, 35.05, 24.049999999999997, 20.049999999999997, 30.049999999999997, 32.55962376, 29.049999999999997, 32.33762376, 35.78567176000001, 32.05, 32.05, 32.25098800000001, 28.049999999999997, 30.049999999999997, 34.62124776, 27.050000000000004, 31.049999999999997, 26.049999999999997, 32.05, 31.049999999999997, 31.149788, 33.316815760000004, 31.41720776, 29.049999999999997, 27.050000000000004, 35.66366376, 29.050000000000004, 34.60083176, 33.49922376, 32.05, 33.59961576, 28.049999999999997, 34.480039760000004, 31.049999999999997, 33.46003976, 32.05, 22.049999999999997, 36.78567176000001, 24.049999999999997, 30.049999999999997, 30.049999999999997, 25.049999999999997, 34.62163976, 19.049999999999997, 29.049999999999997, 33.05, 28.05, 31.049999999999997, 26.05, 31.169788000000004, 33.41842376, 20.049999999999997, 29.05, 32.315599760000005, 30.049999999999997, 27.049999999999997, 28.049999999999997, 33.050000000000004, 28.049999999999997, 31.53962376, 31.35599976, 25.049999999999997, 16.049999999999997, 30.049999999999997, 35.703655760000004, 23.049999999999997, 30.049999999999997, 31.333591760000004, 26.049999999999997, 31.438015760000003, 18.049999999999997, 31.230188000000002, 34.05, 31.31559976, 23.05, 26.050000000000004, 34.05, 30.049999999999997, 29.049999999999997, 31.49841576, 22.049999999999997, 23.049999999999997, 32.05, 27.050000000000004, 29.049999999999997, 32.66325576, 32.49639976, 23.049999999999997, 31.049999999999997, 31.049999999999997, 24.05, 29.049999999999997, 31.294799760000004, 28.049999999999997, 34.05, 24.050000000000004, 15.049999999999999, 33.35721576, 33.46003976, 33.05, 29.049999999999997, 33.66244776, 25.049999999999997, 30.049999999999997, 33.05, 31.190188000000003, 31.169788000000004, 32.05, 24.049999999999997, 33.53963176, 25.049999999999997, 28.049999999999997, 21.050000000000004, 33.05, 21.049999999999997, 32.05, 25.049999999999997, 36.78567176000001, 25.049999999999997, 31.049999999999997, 25.050000000000004, 29.049999999999997, 36.05, 31.049999999999997, 28.050000000000004, 17.05, 31.458015760000002, 33.316815760000004, 22.049999999999997, 28.049999999999997, 34.05, 32.49882376, 34.05, 29.049999999999997, 33.05, 35.60245576, 31.460039760000004, 24.05, 31.049999999999997, 25.049999999999997, 20.050000000000004, 31.315199760000002, 29.050000000000004, 31.050000000000004, 32.05, 26.049999999999997, 24.050000000000004, 34.05, 31.395207760000005, 26.049999999999997, 31.049999999999997, 31.050000000000004, 33.05, 28.05, 34.05, 34.66204776, 29.05, 28.049999999999997, 32.60204776, 28.049999999999997, 28.049999999999997, 31.47883176, 31.27278376], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13174229593122827, "mean_inference_ms": 0.5373947224285659, "mean_action_processing_ms": 0.04112645002866344, "mean_env_wait_ms": 0.045492557302512164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 12000, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 1545.403, "sample_throughput": 2588.321, "load_time_ms": 11.539, "load_throughput": 346651.019, "learn_time_ms": 2200.005, "learn_throughput": 1818.177, "update_time_ms": 1.799}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 27.875856399536133, "policy_loss": -0.07671143859624863, "vf_loss": 27.937000274658203, "vf_explained_var": 0.683301568031311, "kl": 0.034598905593156815, "entropy": 1.8919119834899902, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 12000, "num_steps_trained": 12000, "num_agent_steps_trained": 12000}, "done": false, "episodes_total": 2400, "training_iteration": 3, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-06", "timestamp": 1628628726, "time_this_iter_s": 3.6376562118530273, "time_total_s": 11.347198247909546, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.347198247909546, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 29.04, "ram_util_percent": 69.82000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 37.80647976, "episode_reward_min": 17.05, "episode_reward_mean": 31.621982709000005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.049999999999997, 31.335207760000003, 32.05, 31.250988000000003, 32.33762376, 32.39721576, 36.74527176000001, 32.05, 32.05, 23.049999999999997, 33.39761576, 32.210588, 30.049999999999997, 32.33600776, 33.46003976, 36.72446376, 31.05, 31.270988000000003, 32.05, 30.049999999999997, 33.05, 32.45882376, 33.45882376, 31.05, 32.05, 32.43923176, 32.33762376, 19.05, 33.62285576, 29.049999999999997, 32.45882376, 31.33762376, 31.049999999999997, 33.05, 24.050000000000004, 34.540839760000004, 34.05, 21.049999999999997, 31.250988000000003, 24.049999999999997, 33.05, 31.395199760000004, 30.049999999999997, 35.68406376, 32.579623760000004, 31.05, 31.190188000000003, 32.05, 32.51759976, 31.049999999999997, 33.05, 22.049999999999997, 29.049999999999997, 34.05, 34.68406376, 31.049999999999997, 31.314791760000002, 33.62285576, 34.05, 31.129788, 33.66285576, 31.41720776, 35.60245576, 28.049999999999997, 25.050000000000004, 31.049999999999997, 24.049999999999997, 34.58123976, 32.33762376, 31.520031760000002, 32.050000000000004, 26.049999999999997, 32.477199760000005, 33.05, 28.050000000000004, 33.05, 33.49842376, 31.049999999999997, 35.05, 31.049999999999997, 36.74527176000001, 31.27399176, 30.049999999999997, 30.049999999999997, 33.56083976, 32.05, 33.68406376, 32.478415760000004, 32.518023760000005, 25.049999999999997, 23.049999999999997, 33.39761576, 27.049999999999997, 32.294399760000005, 34.05, 28.049999999999997, 33.05, 31.31600776, 31.129788, 31.210188000000002, 31.296415760000002, 34.52124776, 32.55921576, 33.827287760000004, 34.49963176, 33.52124776, 31.39883176, 32.31600776, 32.05, 33.56043176, 32.540839760000004, 35.66366376, 34.05, 27.049999999999997, 30.050000000000004, 31.49800776, 33.05, 24.05, 33.050000000000004, 33.05, 32.479631760000004, 31.270988000000003, 33.703655760000004, 33.05, 31.049999999999997, 31.170188000000003, 29.05, 30.05, 29.05, 34.05, 27.050000000000004, 31.250988000000003, 32.29641576, 31.376807760000002, 29.049999999999997, 33.41842376, 32.25058800000001, 32.35762376, 31.05, 31.45882376, 36.05, 31.209788000000003, 31.049999999999997, 35.643663759999995, 31.294791760000003, 35.05, 31.049999999999997, 32.37802376, 33.39761576, 33.56164776, 32.25098800000001, 23.050000000000004, 34.74405576, 33.37802376, 35.05, 36.05, 34.56003176, 29.049999999999997, 33.540839760000004, 34.56043976, 31.129788, 33.05, 31.49719976, 32.050000000000004, 31.27520776, 31.049999999999997, 32.210588, 31.35762376, 28.049999999999997, 34.60083176, 33.316815760000004, 33.58245576, 32.35640776, 31.049999999999997, 32.31560776, 24.049999999999997, 25.049999999999997, 34.62285576, 33.49801576, 33.43801576, 31.230188000000002, 33.05, 35.68406376, 32.43801576, 31.049999999999997, 33.500439760000006, 31.27439176, 35.56164776, 36.05, 32.33559976, 33.43923176, 32.55921576, 31.05, 34.52043976, 33.58002376, 31.210188000000002, 33.45923176, 31.314791760000002, 30.049999999999997, 35.765271760000005, 33.05, 34.05, 31.049999999999997, 32.25098800000001, 34.58245576, 34.57963176, 35.74527176000001, 27.05, 29.050000000000004, 33.39761576, 31.41842376, 34.60204776, 30.049999999999997, 33.41641576, 32.230588000000004, 32.210588, 31.25479976, 26.05, 35.05, 27.049999999999997, 33.05, 28.049999999999997, 25.05, 32.270988, 33.500439760000006, 28.05, 31.582455760000002, 25.049999999999997, 33.05, 33.05, 28.049999999999997, 32.050000000000004, 32.33479976, 34.74446376, 32.05, 31.230588000000004, 30.05, 31.049999999999997, 34.54003176, 31.169788000000004, 34.05, 32.210588, 32.35599976, 33.45801576, 31.395207760000005, 31.296007760000002, 31.41761576, 22.049999999999997, 34.41883176, 33.51963176, 31.21399976, 31.35600776, 32.050000000000004, 33.05, 31.41802376, 29.049999999999997, 32.43923176, 34.05, 28.049999999999997, 30.049999999999997, 31.191583760000004, 17.05, 32.05, 31.210588, 33.53842376, 33.55921576, 31.25359176, 33.05, 32.39761576, 31.049999999999997, 33.51881576, 26.05, 34.46003976, 28.049999999999997, 33.39802376, 31.129788, 32.456007760000006, 29.049999999999997, 32.291388000000005, 32.33762376, 33.49922376, 34.62285576, 31.21319176, 36.80647976, 32.05, 31.438015760000003, 30.049999999999997, 33.39761576, 33.39883176, 32.05, 33.316815760000004, 25.05, 28.050000000000004, 31.170188000000003, 34.05, 32.37680776, 31.129788, 32.29519976, 34.54124776, 26.049999999999997, 31.37681576, 30.05, 33.35762376, 31.210188000000002, 31.190188000000003, 33.35762376, 35.70487176, 32.230588000000004, 29.049999999999997, 33.05, 28.049999999999997, 30.050000000000004, 34.43923176, 31.149788, 27.05, 34.05, 19.049999999999997, 35.58245576, 29.049999999999997, 31.641639760000004, 33.45842376, 36.05, 34.49923176, 33.316815760000004, 31.334399760000004, 29.049999999999997, 32.37599976, 32.35721576, 33.54124776, 24.049999999999997, 29.049999999999997, 30.049999999999997, 33.43923176, 36.05, 31.230588000000004, 29.049999999999997, 31.149788, 32.33640776, 35.62285576, 31.049999999999997, 31.376407760000003, 35.66325576, 32.05, 34.641239760000005, 33.41842376, 28.049999999999997, 31.33559976, 26.049999999999997, 31.189788, 30.050000000000004, 31.049999999999997, 28.049999999999997, 25.050000000000004, 30.049999999999997, 34.45923176, 33.56164776, 31.049999999999997, 31.05, 32.49760776, 27.049999999999997, 25.049999999999997, 33.74405576, 34.500439760000006, 18.05, 31.376407760000003, 27.049999999999997, 31.31681576, 33.291388000000005, 28.049999999999997, 31.25479976, 28.050000000000004, 33.78567176000001, 32.05, 34.500439760000006, 24.049999999999997, 34.05, 31.27479976, 31.049999999999997, 33.52003176, 32.230588000000004, 32.27519976, 27.049999999999997, 36.05, 31.39721576, 31.25479976, 33.418023760000004, 32.49922376, 33.05, 35.72487176, 31.35519176, 30.05, 32.25058800000001, 27.049999999999997, 33.41842376, 32.354799760000006, 32.05, 32.05, 33.05, 34.642447759999996, 32.050000000000004, 33.62042376, 35.66366376, 28.050000000000004, 31.35479176, 20.049999999999997, 31.270988000000003, 34.68406376, 30.049999999999997, 31.250588000000004, 33.37681576, 36.70487176, 34.72446376, 33.49802376, 31.19278376, 33.54124776, 18.05, 34.05, 31.049999999999997, 31.049999999999997, 33.33681576, 33.418023760000004, 34.05, 30.050000000000004, 27.050000000000004, 31.049999999999997, 30.049999999999997, 35.05, 31.049999999999997, 33.05, 30.049999999999997, 34.641231760000004, 32.45882376, 31.25358376, 36.76607976, 33.33762376, 32.29560776, 29.050000000000004, 33.47923176, 33.62163976, 34.05, 34.05, 31.43680776, 31.049999999999997, 31.25479976, 33.49963176, 32.210588, 34.72446376, 28.050000000000004, 31.47841576, 31.294799760000004, 33.641239760000005, 35.54124776, 32.37680776, 32.53962376, 27.049999999999997, 33.05, 32.33762376, 35.56164776, 31.31398376, 33.641231760000004, 31.049999999999997, 33.05, 33.05, 30.049999999999997, 30.049999999999997, 33.39883176, 33.291388000000005, 33.47842376, 31.049999999999997, 29.049999999999997, 32.33479976, 30.049999999999997, 31.17238376, 30.049999999999997, 31.209788000000003, 31.45882376, 31.049999999999997, 31.250588000000004, 32.05, 30.049999999999997, 33.37802376, 26.050000000000004, 35.05, 31.35762376, 32.05, 27.05, 32.05, 24.050000000000004, 31.129788, 30.050000000000004, 31.149788, 31.56003176, 31.170188000000003, 33.05, 31.05, 32.578807760000004, 31.37599976, 32.43802376, 32.31520776, 31.35600776, 31.33762376, 24.049999999999997, 34.05, 35.05, 30.049999999999997, 28.050000000000004, 33.05, 31.23319176, 31.41599176, 29.049999999999997, 32.230588000000004, 28.05, 35.58245576, 24.049999999999997, 31.189788, 33.642447759999996, 31.25439176, 35.62285576, 33.41842376, 31.129788, 32.29600776, 25.049999999999997, 32.39721576, 31.456391760000002, 30.05, 31.270988000000003, 31.210188000000002, 35.60245576, 32.33681576, 25.050000000000004, 34.56164776, 32.57921576, 33.540839760000004, 34.05, 28.050000000000004, 31.41478376, 31.559223760000002, 31.43923176, 34.58124776, 31.39761576, 33.45882376, 31.169788000000004, 31.31359176, 31.210588, 35.05, 32.25058800000001, 33.47721576, 31.049999999999997, 32.210588, 31.049999999999997, 30.049999999999997, 32.39639976, 31.31641576, 32.25058800000001, 18.05, 31.210588, 31.049999999999997, 28.05, 32.05, 33.43923176, 34.62124776, 32.478415760000004, 34.51963176, 33.43801576, 34.54124776, 27.05, 31.049999999999997, 31.25439176, 28.050000000000004, 35.60204776, 33.43721576, 30.049999999999997, 32.05, 31.050000000000004, 35.581647759999996, 32.43883176, 37.80647976, 31.210188000000002, 31.31559976, 32.417207760000004, 31.49800776, 25.05, 31.210188000000002, 29.05, 29.050000000000004, 34.60204776, 32.05, 34.45923176, 23.049999999999997, 27.049999999999997, 33.05, 34.05, 33.33641576, 30.049999999999997, 31.169788000000004, 32.43923176, 33.43802376, 33.540839760000004, 33.35721576, 33.33762376, 34.52003176, 32.27439976, 25.049999999999997, 31.049999999999997, 31.31641576, 31.33519176, 32.210588, 28.05, 27.049999999999997, 32.52043976, 33.52124776, 27.05, 34.05, 32.05, 33.05, 33.41762376, 32.050000000000004, 31.458423760000002, 32.41883176, 32.05, 33.05, 34.05, 35.05, 31.37802376, 31.35762376, 32.05, 32.05, 32.05, 36.76607976, 25.049999999999997, 32.39600776, 32.05, 28.049999999999997, 27.05, 28.049999999999997, 31.37559176, 32.49963176, 31.170188000000003, 32.55921576, 35.68406376, 24.049999999999997, 25.049999999999997, 31.416399760000004, 35.58245576, 30.049999999999997, 34.56124776, 34.05, 31.049999999999997, 29.049999999999997, 31.189788, 30.049999999999997, 31.230588000000004, 32.05, 31.049999999999997, 31.33600776, 31.169788000000004, 31.436799760000003, 33.39883176, 35.05, 31.05, 32.35721576, 25.050000000000004, 33.45882376, 32.45720776, 31.169788000000004, 32.05, 33.37721576, 31.049999999999997, 27.05, 31.315607760000002, 32.230588000000004, 31.049999999999997, 35.05, 31.049999999999997, 36.05, 31.190188000000003, 32.25058800000001, 26.05, 34.68203976000001, 33.479631760000004, 25.049999999999997, 31.230188000000002, 31.049999999999997, 32.43842376, 32.43640776, 28.05, 35.70406376, 35.05, 32.05, 36.643663759999995, 33.35721576, 32.291388000000005, 33.316815760000004, 33.58002376, 31.049999999999997, 32.05, 31.58164776, 31.25439176, 34.05, 32.05, 35.72446376, 33.540839760000004, 28.049999999999997, 31.29398376, 36.827287760000004, 29.049999999999997, 31.049999999999997, 31.27398376, 33.58083976, 33.540439760000005, 34.52003176, 31.31681576, 33.45882376, 34.05, 24.050000000000004, 33.62204776, 33.316815760000004, 30.049999999999997, 34.52124776, 33.49842376, 33.05, 35.05, 32.05, 31.315607760000002, 32.540839760000004, 30.049999999999997, 36.72446376, 34.05, 33.29641576, 32.05, 31.27439176, 33.59961576, 33.54003176, 32.25098800000001, 35.05, 35.703655760000004, 34.72324776, 21.049999999999997, 34.62285576, 36.05, 31.296007760000002, 34.05, 32.60204776, 32.29600776, 32.05, 32.05, 32.270988, 31.050000000000004, 31.049999999999997, 35.52124776, 34.05, 32.477199760000005, 32.51759976, 34.479631760000004, 31.049999999999997, 32.05, 34.05, 36.76486376, 31.210588, 31.31600776, 33.316815760000004, 31.049999999999997, 33.76607976, 29.049999999999997, 33.478415760000004, 33.33681576, 32.37559976, 31.47760776, 31.25439176, 33.62163976, 31.272383760000004, 29.05, 29.050000000000004, 32.47721576, 30.049999999999997, 32.39761576, 31.129788, 25.049999999999997, 33.46003976, 27.049999999999997, 27.049999999999997, 31.049999999999997, 31.57880776, 34.62163976, 32.33479976, 33.56083976, 31.234399760000002, 22.05, 32.05, 33.05, 32.230588000000004, 31.049999999999997, 32.230588000000004, 33.52003176, 32.27519976, 36.05, 27.049999999999997, 32.27479976, 33.05, 34.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1308368215142541, "mean_inference_ms": 0.532703449719847, "mean_action_processing_ms": 0.04085833214920859, "mean_env_wait_ms": 0.0452200273709988, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 16000, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 1531.671, "sample_throughput": 2611.527, "load_time_ms": 8.903, "load_throughput": 449300.456, "learn_time_ms": 2162.473, "learn_throughput": 1849.734, "update_time_ms": 1.687}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 17.491348266601562, "policy_loss": -0.042262740433216095, "vf_loss": 17.521860122680664, "vf_explained_var": 0.8228327035903931, "kl": 0.017408305779099464, "entropy": 1.771051287651062, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 16000, "num_agent_steps_sampled": 16000, "num_steps_trained": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 3200, "training_iteration": 4, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-10", "timestamp": 1628628730, "time_this_iter_s": 3.5582499504089355, "time_total_s": 14.905448198318481, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.905448198318481, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 36.5, "ram_util_percent": 70.76}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 37.827287760000004, "episode_reward_min": 18.049999999999997, "episode_reward_mean": 32.278619238500006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.39802376, 32.49882376, 32.64285576, 31.250988000000003, 31.35721576, 33.35762376, 33.47923176, 37.05, 32.05, 35.05, 35.05, 34.62164776, 36.70366376, 35.66244776, 31.275199760000003, 34.66285576, 32.05, 35.05, 33.05, 31.049999999999997, 32.050000000000004, 33.45842376, 34.56043176, 35.74527176000001, 33.64285576, 32.43923176, 35.58245576, 33.33641576, 33.39883176, 32.25058800000001, 31.294799760000004, 35.703655760000004, 35.68406376, 35.62285576, 34.05, 35.68406376, 34.51963176, 31.170188000000003, 33.58003176, 36.05, 34.05, 30.05, 35.05, 32.05, 31.43923176, 31.049999999999997, 26.049999999999997, 33.05, 35.52124776, 31.149788, 34.56083976, 33.05, 33.580431759999996, 32.230588000000004, 34.05, 33.56043976, 31.233999760000003, 32.45760776, 30.05, 35.62124776, 33.43842376, 36.05, 31.190188000000003, 32.05, 34.05, 33.49922376, 36.05, 36.70487176, 31.296007760000002, 31.049999999999997, 33.642447759999996, 31.129788, 33.479631760000004, 31.374399760000006, 32.05, 29.05, 25.05, 32.52124776, 34.72446376, 31.129788, 30.050000000000004, 33.642447759999996, 35.05, 35.70487176, 32.33681576, 31.41842376, 31.210588, 27.049999999999997, 35.703655760000004, 32.05, 32.33681576, 31.270988000000003, 33.05, 31.250988000000003, 30.049999999999997, 32.29600776, 32.37680776, 33.39721576, 33.05, 33.540439760000005, 33.60083176, 26.05, 32.25098800000001, 31.05, 33.55882376, 31.315607760000002, 32.35599976, 33.05, 31.230588000000004, 31.190188000000003, 33.39802376, 34.46003976, 31.37721576, 31.189788, 31.296007760000002, 36.80647976, 32.394799760000005, 32.05, 32.270988, 35.642447759999996, 28.050000000000004, 29.05, 30.049999999999997, 34.05, 32.37802376, 33.56043176, 32.05, 33.49922376, 31.29560776, 35.70487176, 35.70487176, 34.641231760000004, 33.31641576, 33.05, 32.479631760000004, 33.05, 32.25098800000001, 32.315599760000005, 30.049999999999997, 34.43923176, 32.35640776, 33.540839760000004, 32.479631760000004, 33.05, 31.190188000000003, 32.29600776, 32.39681576, 34.05, 34.49963176, 28.05, 35.703655760000004, 33.80647976, 32.05, 34.05, 33.39883176, 33.45923176, 32.316815760000004, 32.05, 31.189788, 30.049999999999997, 33.291388000000005, 33.52003176, 31.050000000000004, 32.37802376, 32.35721576, 33.316815760000004, 32.25098800000001, 33.479631760000004, 32.270988, 36.05, 32.05, 31.190188000000003, 33.60204776, 33.41842376, 30.049999999999997, 33.49963176, 33.05, 31.376807760000002, 31.39639976, 34.62285576, 32.45882376, 33.37721576, 35.05, 31.190188000000003, 34.05, 34.05, 32.05, 31.416815760000002, 32.25098800000001, 36.643663759999995, 33.33762376, 29.05, 35.76607976, 35.643663759999995, 34.72446376, 33.56043176, 31.049999999999997, 31.43681576, 33.43923176, 33.56164776, 29.049999999999997, 29.05, 31.049999999999997, 35.05, 36.80647976, 31.049999999999997, 34.50003976000001, 34.52003176, 33.41842376, 33.05, 32.27439976, 35.66325576, 31.230588000000004, 31.189788, 33.43801576, 31.270988000000003, 31.049999999999997, 31.272383760000004, 33.291388000000005, 23.049999999999997, 34.702439760000004, 31.049999999999997, 31.129788, 32.050000000000004, 33.37802376, 33.60204776, 36.76607976, 32.25098800000001, 29.049999999999997, 31.41641576, 31.253999760000003, 33.41883176, 35.643663759999995, 31.190188000000003, 34.05, 35.62285576, 31.294791760000003, 32.29600776, 34.05, 31.050000000000004, 32.25098800000001, 32.294799760000004, 31.049999999999997, 30.049999999999997, 31.291388000000005, 31.169788000000004, 33.39721576, 32.05, 33.479631760000004, 32.49963176, 35.70487176, 34.05, 36.05, 32.05, 31.33640776, 32.316815760000004, 33.37802376, 35.581647759999996, 26.049999999999997, 31.35721576, 24.049999999999997, 33.05, 35.05, 31.29439176, 33.316815760000004, 29.049999999999997, 32.05, 32.230588000000004, 31.376807760000002, 26.05, 33.46003976, 32.49842376, 33.33762376, 31.149788, 32.35762376, 32.500439760000006, 35.74527176000001, 32.291388000000005, 32.62285576, 31.41842376, 33.05, 35.05, 33.43802376, 35.66325576, 28.049999999999997, 33.05, 35.66285576, 25.049999999999997, 33.291388000000005, 35.05, 32.35721576, 31.049999999999997, 31.049999999999997, 32.210588, 33.37762376, 33.41842376, 33.05, 33.45883176, 35.52124776, 34.581647759999996, 33.05, 31.210188000000002, 31.31681576, 34.60204776, 33.05, 29.049999999999997, 32.291388000000005, 32.41842376, 32.56164776, 32.050000000000004, 32.518423760000005, 30.049999999999997, 32.46003976, 24.050000000000004, 33.43842376, 28.05, 33.60245576, 36.05, 33.56164776, 32.230588000000004, 34.72365576, 26.050000000000004, 33.45882376, 28.05, 33.500439760000006, 33.05, 34.58123976, 33.05, 32.316815760000004, 35.70366376, 33.39761576, 31.049999999999997, 35.66244776, 31.415607760000004, 34.56043176, 33.52003176, 33.37802376, 32.29600776, 33.66123176, 33.05, 32.25058800000001, 33.49922376, 37.827287760000004, 34.479631760000004, 31.270988000000003, 24.05, 35.62285576, 32.05, 35.05, 33.72446376, 31.129788, 29.05, 34.05, 33.53963176, 35.05, 35.05, 29.05, 33.05, 33.37802376, 36.72446376, 35.05, 32.270988, 34.702439760000004, 32.31641576, 34.56164776, 31.23399176, 33.45681576, 36.05, 30.049999999999997, 23.05, 32.05, 29.049999999999997, 33.540839760000004, 34.43883176, 31.049999999999997, 35.703655760000004, 31.250588000000004, 31.209788000000003, 33.291388000000005, 29.049999999999997, 33.45721576, 32.05, 34.56164776, 29.05, 32.478415760000004, 34.60245576, 31.270988000000003, 33.39802376, 33.05, 33.05, 32.270988, 33.52124776, 28.05, 32.479631760000004, 31.05, 36.05, 34.05, 35.05, 35.72406376, 33.316815760000004, 35.643663759999995, 27.049999999999997, 34.46003976, 33.05, 33.291388000000005, 31.210188000000002, 29.049999999999997, 33.37802376, 34.70406376, 33.05, 33.418023760000004, 26.05, 34.05, 34.540839760000004, 34.72446376, 31.169788000000004, 31.129788, 31.049999999999997, 33.500439760000006, 31.210188000000002, 30.049999999999997, 31.35721576, 31.250988000000003, 34.39883176, 32.05, 30.049999999999997, 32.39802376, 33.51922376, 33.05, 31.19278376, 33.33762376, 35.56164776, 31.050000000000004, 35.78567176000001, 31.25479976, 34.05, 35.52124776, 32.500439760000006, 32.05, 32.05, 35.60204776, 31.39883176, 31.190188000000003, 32.78567176000001, 32.210588, 31.31559976, 33.39883176, 35.05, 31.25479976, 29.049999999999997, 30.049999999999997, 31.049999999999997, 23.049999999999997, 31.35519976, 33.45923176, 31.05, 36.70406376, 34.05, 29.049999999999997, 34.05, 31.049999999999997, 22.049999999999997, 28.049999999999997, 31.270988000000003, 26.050000000000004, 31.41600776, 28.05, 26.05, 34.540839760000004, 28.049999999999997, 33.64204776, 36.05, 33.05, 33.41842376, 36.05, 35.60245576, 28.049999999999997, 33.33762376, 33.55882376, 23.049999999999997, 22.049999999999997, 33.49761576, 32.270988, 32.210588, 35.581647759999996, 26.050000000000004, 33.39761576, 33.35721576, 34.46003976, 30.049999999999997, 35.05, 27.049999999999997, 25.050000000000004, 18.049999999999997, 33.37802376, 31.250588000000004, 32.45681576, 29.049999999999997, 28.050000000000004, 33.05, 33.29641576, 25.050000000000004, 31.049999999999997, 32.41761576, 34.66325576, 31.049999999999997, 33.291388000000005, 34.45923176, 32.46003976, 32.41842376, 34.43923176, 31.35721576, 31.129788, 31.049999999999997, 32.25098800000001, 32.210588, 32.05, 33.43883176, 33.05, 31.21238376, 28.050000000000004, 31.458423760000002, 33.316815760000004, 32.68163176, 28.05, 33.43923176, 32.68163176, 32.53962376, 35.05, 31.230588000000004, 32.35681576, 31.230588000000004, 33.43923176, 33.52124776, 31.05, 31.35599976, 31.230588000000004, 36.05, 34.62285576, 33.29641576, 33.58083976, 26.05, 34.479631760000004, 35.05, 31.049999999999997, 31.05, 34.05, 32.41842376, 35.78567176000001, 33.05, 33.43641576, 32.641639760000004, 27.049999999999997, 31.43720776, 31.47963176, 36.68406376, 31.23399176, 32.642447759999996, 19.05, 33.316815760000004, 35.60204776, 32.35762376, 33.05, 35.05, 32.25439976, 35.52124776, 31.210588, 31.049999999999997, 25.050000000000004, 33.05, 32.25098800000001, 32.254799760000004, 34.05, 33.418023760000004, 35.05, 33.47923176, 33.52003176, 26.05, 29.049999999999997, 32.47923176, 31.050000000000004, 33.33762376, 32.29600776, 34.43923176, 33.56164776, 35.62204776, 31.129788, 31.170188000000003, 29.049999999999997, 32.35721576, 32.43641576, 33.43801576, 31.49922376, 33.05, 32.05, 32.60204776, 33.54124776, 33.35762376, 32.540439760000005, 34.60164776, 33.70487176, 31.149788, 35.64285576, 29.050000000000004, 31.275199760000003, 35.70487176, 33.33681576, 31.230188000000002, 32.27519976, 35.05, 27.049999999999997, 32.43842376, 30.050000000000004, 31.049999999999997, 31.17198376, 29.049999999999997, 30.049999999999997, 34.479631760000004, 33.60083176, 31.049999999999997, 33.54124776, 32.29519976, 35.60245576, 31.190188000000003, 31.049999999999997, 33.35762376, 34.78567176000001, 30.049999999999997, 34.49883176, 31.275199760000003, 20.049999999999997, 34.642447759999996, 23.05, 31.049999999999997, 31.275199760000003, 32.291388000000005, 32.230588000000004, 25.049999999999997, 31.33640776, 31.41720776, 30.049999999999997, 24.05, 33.53881576, 33.540839760000004, 32.05, 28.050000000000004, 32.37559976, 34.05, 33.41641576, 34.66204776, 31.250588000000004, 29.049999999999997, 32.500439760000006, 33.35721576, 31.189788, 33.827287760000004, 33.56043176, 31.230588000000004, 32.41883176, 32.29600776, 33.52124776, 36.05, 32.291388000000005, 32.29600776, 31.230588000000004, 23.049999999999997, 35.05, 31.049999999999997, 35.62245576, 31.129788, 33.47923176, 33.05, 31.51922376, 34.52003176, 31.210588, 32.230588000000004, 25.049999999999997, 32.050000000000004, 31.275199760000003, 34.78567176000001, 32.230588000000004, 32.33762376, 34.540039760000006, 33.291388000000005, 30.050000000000004, 34.56043176, 31.05, 31.291388000000005, 35.68406376, 32.33762376, 31.37802376, 31.049999999999997, 31.35721576, 32.58002376, 31.39761576, 29.049999999999997, 33.35721576, 31.250988000000003, 33.43842376, 34.500439760000006, 33.56164776, 31.250988000000003, 32.29600776, 32.478415760000004, 35.643663759999995, 31.434791760000003, 31.05, 32.43720776, 36.05, 32.37721576, 34.74527176000001, 32.210588, 33.703655760000004, 34.05, 27.049999999999997, 35.05, 32.27439976, 31.190188000000003, 35.643663759999995, 35.643663759999995, 26.049999999999997, 23.049999999999997, 33.52043976, 32.540839760000004, 31.170188000000003, 31.049999999999997, 31.129788, 34.05, 27.049999999999997, 31.31681576, 33.05, 31.275199760000003, 33.05, 34.05, 31.270988000000003, 24.049999999999997, 33.43801576, 33.49922376, 32.050000000000004, 32.35640776, 34.479631760000004, 33.33762376, 32.05, 31.250588000000004, 31.250588000000004, 31.35721576, 32.418023760000004, 32.315599760000005, 31.050000000000004, 20.050000000000004, 33.47842376, 31.457607760000002, 32.51922376, 34.05, 27.049999999999997, 22.049999999999997, 32.210588, 30.049999999999997, 31.049999999999997, 35.05, 26.049999999999997, 33.05, 34.50003976000001, 33.478415760000004, 32.53841576, 31.210588, 35.76607976, 31.049999999999997, 32.39883176, 34.580431759999996, 31.149788, 30.049999999999997, 32.49963176, 35.74527176000001, 33.41761576, 36.05, 32.35640776, 34.68244776, 33.05, 32.05, 33.396415760000004, 32.254799760000004, 32.291388000000005, 28.05, 31.050000000000004, 33.39883176, 32.46003976, 33.291388000000005, 31.270988000000003, 37.05, 34.05, 36.643663759999995, 34.52043976, 29.049999999999997, 31.295199760000003, 32.37802376, 34.05, 31.049999999999997, 32.35721576, 34.60245576], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13054130006082032, "mean_inference_ms": 0.5317125638929943, "mean_action_processing_ms": 0.040825337555966075, "mean_env_wait_ms": 0.045235342245652135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 20000, "agent_timesteps_total": 20000, "timers": {"sample_time_ms": 1528.163, "sample_throughput": 2617.522, "load_time_ms": 7.306, "load_throughput": 547516.383, "learn_time_ms": 2139.214, "learn_throughput": 1869.845, "update_time_ms": 1.619}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 11.247367858886719, "policy_loss": -0.03561104089021683, "vf_loss": 11.274770736694336, "vf_explained_var": 0.892004132270813, "kl": 0.012162037193775177, "entropy": 1.667542815208435, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 20000, "num_steps_trained": 20000, "num_agent_steps_trained": 20000}, "done": false, "episodes_total": 4000, "training_iteration": 5, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-14", "timestamp": 1628628734, "time_this_iter_s": 3.578450918197632, "time_total_s": 18.483899116516113, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.483899116516113, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 37.38, "ram_util_percent": 70.8}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 21.049999999999997, "episode_reward_mean": 33.0110936095, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.37802376, 34.500439760000006, 35.05, 35.68406376, 34.05, 32.35599976, 33.29641576, 30.049999999999997, 32.37479976, 31.19198376, 28.050000000000004, 33.05, 33.05, 32.25058800000001, 32.050000000000004, 34.52043976, 34.46003976, 33.39681576, 32.25098800000001, 32.23439976, 34.05, 31.129788, 32.51963176, 32.395207760000005, 32.58245576, 33.41883176, 31.230588000000004, 33.46003976, 31.29560776, 31.376407760000003, 30.05, 36.68406376, 35.72487176, 33.39802376, 34.39883176, 33.41842376, 33.479631760000004, 35.58245576, 34.05, 35.66325576, 36.05, 31.050000000000004, 34.540439760000005, 31.33681576, 35.62285576, 36.68406376, 32.25098800000001, 34.62123976, 31.169788000000004, 31.33640776, 36.72487176, 31.049999999999997, 32.210588, 26.050000000000004, 33.58123976, 31.35599976, 34.05, 35.68406376, 33.39802376, 33.37762376, 36.72487176, 24.049999999999997, 33.66082376, 34.47923176, 30.049999999999997, 33.39883176, 31.23399176, 33.51881576, 36.70487176, 28.049999999999997, 33.66366376, 26.049999999999997, 32.39883176, 33.479631760000004, 33.29641576, 35.52124776, 31.230588000000004, 35.581647759999996, 32.31519976, 35.581647759999996, 33.05, 32.230588000000004, 34.540839760000004, 34.05, 34.62163976, 31.210188000000002, 31.169788000000004, 31.05, 35.66366376, 33.316815760000004, 33.05, 31.27560776, 31.05, 33.39883176, 35.64285576, 34.05, 33.51963176, 34.05, 34.60204776, 35.70487176, 28.049999999999997, 33.39883176, 35.05, 35.05, 35.60204776, 26.05, 32.35520776, 34.72446376, 31.05, 34.56164776, 34.05, 33.316815760000004, 28.049999999999997, 32.43923176, 33.05, 33.291388000000005, 34.05, 31.190188000000003, 34.60245576, 26.05, 36.05, 36.70487176, 31.47841576, 32.31600776, 34.41883176, 31.275199760000003, 32.05, 33.479631760000004, 33.643663759999995, 30.049999999999997, 33.050000000000004, 33.291388000000005, 33.60204776, 31.37600776, 32.25058800000001, 35.05, 33.05, 36.827287760000004, 32.05, 34.46003976, 35.74527176000001, 33.316815760000004, 33.41842376, 32.05, 32.05, 32.29600776, 32.27519976, 32.05, 35.64285576, 33.29641576, 34.05, 33.52124776, 31.230588000000004, 35.58245576, 33.05, 34.480039760000004, 28.05, 33.39883176, 34.05, 37.05, 31.250988000000003, 31.049999999999997, 31.250588000000004, 31.049999999999997, 33.05, 33.41842376, 32.29399976, 34.05, 32.210588, 31.210588, 31.170188000000003, 33.41761576, 33.05, 33.291388000000005, 30.049999999999997, 33.56043176, 32.39761576, 31.05, 31.049999999999997, 34.581647759999996, 31.291388000000005, 31.050000000000004, 34.05, 33.52003176, 35.66366376, 33.62285576, 35.05, 33.56083976, 32.27519976, 31.41842376, 32.05, 33.41681576, 33.29641576, 32.291388000000005, 33.66325576, 33.46003976, 31.41519976, 36.78607976, 33.43923176, 35.56164776, 33.41842376, 31.049999999999997, 33.49963176, 32.43681576, 33.29641576, 36.05, 32.25098800000001, 32.316815760000004, 26.049999999999997, 31.129788, 33.05, 33.29641576, 31.25479976, 33.45761576, 32.29600776, 31.129788, 34.05, 31.33762376, 34.05, 33.500439760000006, 32.05, 32.35640776, 31.275199760000003, 28.049999999999997, 33.05, 34.60043176, 32.210588, 33.05, 31.296007760000002, 34.05, 34.43923176, 34.642455760000004, 31.35399176, 30.049999999999997, 25.049999999999997, 36.68406376, 36.05, 29.049999999999997, 34.58123976, 33.58245576, 30.050000000000004, 34.74527176000001, 35.54124776, 31.21278376, 33.33641576, 29.05, 29.05, 32.55841576, 34.05, 31.272791760000004, 31.13158376, 33.33681576, 33.53842376, 36.05, 33.702439760000004, 31.47841576, 31.356407760000003, 33.37721576, 32.29600776, 32.29600776, 31.335607760000002, 31.210188000000002, 36.70406376, 32.291388000000005, 32.05, 31.275199760000003, 32.43842376, 33.662039760000006, 33.43842376, 33.39802376, 31.049999999999997, 30.049999999999997, 31.250588000000004, 31.169788000000004, 32.230588000000004, 35.58245576, 34.479631760000004, 33.74527176000001, 33.05, 31.233583760000002, 32.27519976, 32.230588000000004, 33.33762376, 34.72487176, 32.31600776, 32.05, 32.39721576, 34.500439760000006, 33.47923176, 27.049999999999997, 33.37721576, 31.21359176, 34.57963176, 31.049999999999997, 35.581647759999996, 32.210588, 32.05, 34.60245576, 31.170188000000003, 32.500439760000006, 31.233583760000002, 32.37802376, 34.500439760000006, 35.05, 33.05, 34.52043976, 31.210588, 35.62285576, 34.62285576, 31.049999999999997, 33.45882376, 33.37802376, 31.27560776, 35.05, 33.316815760000004, 33.37802376, 34.05, 33.33762376, 31.39761576, 36.72446376, 35.62245576, 35.66325576, 33.35721576, 33.05, 30.05, 33.70487176, 34.642447759999996, 33.500439760000006, 32.291388000000005, 33.39761576, 33.39883176, 29.05, 29.049999999999997, 32.05, 33.43762376, 33.480039760000004, 35.68284776, 32.05, 35.56164776, 33.41842376, 31.129788, 35.60204776, 33.52043976, 34.500439760000006, 30.049999999999997, 32.05, 34.05, 33.540839760000004, 32.55963176, 34.52003176, 33.35721576, 32.210588, 33.43883176, 34.480039760000004, 29.049999999999997, 32.579623760000004, 31.275199760000003, 35.642447759999996, 35.05, 32.05, 34.58245576, 32.37681576, 32.27519976, 32.29600776, 35.64285576, 33.72324776, 34.52124776, 31.459231759999998, 32.25098800000001, 35.62204776, 37.78607976, 33.43842376, 33.05, 33.39802376, 34.43923176, 32.43842376, 32.43842376, 31.169788000000004, 32.291388000000005, 33.479631760000004, 32.41883176, 31.169788000000004, 35.05, 33.41842376, 31.129788, 32.05, 36.05, 35.58245576, 31.149788, 33.05, 33.05, 33.58002376, 33.58245576, 35.62285576, 34.43923176, 33.37802376, 31.049999999999997, 30.049999999999997, 32.05, 21.049999999999997, 35.70406376, 32.43801576, 31.049999999999997, 30.049999999999997, 31.233583760000002, 35.74405576, 33.62285576, 32.51881576, 34.05, 30.049999999999997, 35.05, 31.33640776, 36.68366376, 34.52043976, 29.049999999999997, 35.643663759999995, 26.049999999999997, 36.80647976, 33.418023760000004, 32.479631760000004, 32.05, 35.60204776, 34.39883176, 35.60204776, 32.46003976, 33.49963176, 32.27519976, 33.479631760000004, 32.05, 32.356415760000004, 33.05, 35.56164776, 33.35721576, 34.62285576, 31.190188000000003, 32.35721576, 33.479631760000004, 33.05, 31.581239760000003, 34.39883176, 30.049999999999997, 32.316815760000004, 35.643663759999995, 33.37721576, 33.35721576, 35.05, 34.66325576, 33.316815760000004, 30.05, 30.049999999999997, 35.58245576, 32.05, 33.05, 33.37802376, 34.68325576, 33.500439760000006, 32.25098800000001, 33.62163976, 29.050000000000004, 32.46003976, 35.52124776, 26.05, 35.05, 33.478415760000004, 32.270988, 33.52003176, 28.05, 35.68406376, 33.37802376, 33.55921576, 32.62163976, 32.37802376, 33.291388000000005, 32.27519976, 33.456415760000006, 31.210188000000002, 33.49882376, 31.39761576, 36.05, 32.41721576, 36.05, 31.233583760000002, 33.52003176, 33.52003176, 34.540839760000004, 34.05, 35.58245576, 36.05, 33.66244776, 34.52003176, 33.52124776, 32.39883176, 31.33762376, 31.37802376, 27.050000000000004, 31.31641576, 32.35721576, 31.149788, 34.480039760000004, 35.74527176000001, 32.291388000000005, 33.05, 33.33762376, 36.68406376, 36.70487176, 34.58124776, 32.316815760000004, 32.43720776, 31.149788, 35.68406376, 32.31520776, 34.540839760000004, 36.05, 33.37721576, 33.43801576, 33.37802376, 34.39883176, 31.049999999999997, 32.291388000000005, 31.049999999999997, 31.210588, 31.210588, 33.46003976, 34.56164776, 34.58123976, 32.25098800000001, 33.39802376, 33.05, 33.316815760000004, 32.49800776, 33.39883176, 33.291388000000005, 34.05, 34.46003976, 37.05, 34.703655760000004, 32.254799760000004, 34.66244776, 32.254799760000004, 34.54124776, 35.05, 32.395607760000004, 33.45923176, 32.25098800000001, 31.291388000000005, 32.37680776, 34.581647759999996, 32.254799760000004, 30.05, 32.39802376, 33.39761576, 29.05, 34.52124776, 36.68406376, 33.35762376, 32.05, 35.72446376, 32.05, 35.56164776, 34.05, 34.46003976, 34.05, 31.230588000000004, 36.80647976, 34.62204776, 32.41842376, 32.316815760000004, 22.049999999999997, 36.74527176000001, 33.56164776, 32.05, 35.643663759999995, 33.37802376, 36.05, 31.190188000000003, 35.74405576, 34.479631760000004, 32.230588000000004, 35.70487176, 31.049999999999997, 33.35681576, 33.500439760000006, 33.45802376, 33.49922376, 33.35721576, 36.74527176000001, 32.479631760000004, 36.05, 33.46003976, 35.05, 32.356415760000004, 33.43883176, 32.43679976, 31.21399976, 32.316815760000004, 33.39761576, 35.76486376, 31.049999999999997, 33.316815760000004, 32.210588, 26.050000000000004, 32.05, 32.05, 33.641231760000004, 31.049999999999997, 33.35762376, 34.58245576, 33.480039760000004, 33.41883176, 33.33762376, 36.70487176, 33.56164776, 29.049999999999997, 32.33762376, 33.37802376, 30.050000000000004, 31.396415760000004, 33.49922376, 33.05, 29.049999999999997, 30.049999999999997, 33.37802376, 35.72446376, 31.250588000000004, 36.76607976, 26.049999999999997, 31.149788, 36.643663759999995, 33.35721576, 33.500439760000006, 33.43802376, 32.05, 30.049999999999997, 32.25098800000001, 33.41842376, 33.05, 34.56083976, 35.05, 33.33641576, 32.31641576, 36.643663759999995, 32.37721576, 27.050000000000004, 33.33681576, 35.05, 28.049999999999997, 33.518423760000005, 33.05, 35.581647759999996, 32.05, 31.33640776, 33.43923176, 35.70406376, 27.049999999999997, 33.05, 34.39883176, 32.210588, 33.41842376, 32.05, 33.050000000000004, 31.17238376, 36.643663759999995, 36.05, 38.05, 33.62285576, 30.050000000000004, 34.05, 33.05, 35.62285576, 31.250988000000003, 31.05, 35.643663759999995, 34.500439760000006, 33.37681576, 33.05, 34.05, 33.58123976, 35.05, 34.43923176, 33.05, 32.05, 32.05, 32.050000000000004, 33.39762376, 32.210588, 31.049999999999997, 29.049999999999997, 32.05, 34.60204776, 32.45760776, 33.39883176, 35.52124776, 34.66325576, 33.58083976, 33.58245576, 30.049999999999997, 32.05, 31.049999999999997, 34.54124776, 31.270988000000003, 31.210588, 31.170188000000003, 33.37721576, 31.190188000000003, 33.52003176, 32.53962376, 34.480039760000004, 34.46003976, 27.049999999999997, 34.05, 35.05, 32.29641576, 33.58245576, 27.050000000000004, 34.68406376, 35.56164776, 35.05, 34.66366376, 36.66366376, 34.480039760000004, 32.27560776, 33.60083176, 35.05, 33.43923176, 32.230588000000004, 34.480039760000004, 37.76607976, 32.05, 33.41883176, 34.60204776, 35.643663759999995, 35.05, 33.55881576, 34.05, 36.80647976, 34.540839760000004, 31.31520776, 35.70487176, 33.29641576, 32.33762376, 31.169788000000004, 34.47883176, 37.05, 32.43681576, 33.43761576, 32.316815760000004, 31.35478376, 31.190188000000003, 34.45923176, 31.129788, 33.52003176, 35.58245576, 33.53882376, 31.37802376, 33.52003976, 30.049999999999997, 34.05, 31.27479976, 32.270988, 35.72324776, 32.41641576, 34.68366376, 34.58123976, 33.39761576, 33.316815760000004, 32.25098800000001, 30.05, 31.149788, 33.43923176, 34.62245576, 33.37802376, 35.05, 33.500439760000006, 31.05, 30.050000000000004, 33.37721576, 32.39883176, 36.76607976, 35.72446376, 36.76607976, 33.05, 32.05, 34.52003176, 32.230588000000004, 36.72446376, 35.581647759999996, 33.55921576, 33.74527176000001, 32.210588, 33.316815760000004, 32.230588000000004, 34.39883176, 31.250588000000004, 32.62285576, 31.230588000000004, 32.45760776, 32.05, 34.05, 35.76607976, 32.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1301388473930324, "mean_inference_ms": 0.5298909838224845, "mean_action_processing_ms": 0.040695802558115064, "mean_env_wait_ms": 0.045124306975578364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 24000, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 1522.912, "sample_throughput": 2626.547, "load_time_ms": 6.239, "load_throughput": 641118.488, "learn_time_ms": 2123.911, "learn_throughput": 1883.318, "update_time_ms": 1.572}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 4.926975250244141, "policy_loss": -0.046116117388010025, "vf_loss": 4.960971832275391, "vf_explained_var": 0.9545429348945618, "kl": 0.017955001443624496, "entropy": 1.5757508277893066, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 24000, "num_agent_steps_sampled": 24000, "num_steps_trained": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 4800, "training_iteration": 6, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-17", "timestamp": 1628628737, "time_this_iter_s": 3.562436819076538, "time_total_s": 22.04633593559265, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.04633593559265, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 36.58, "ram_util_percent": 70.52}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 19.05, "episode_reward_mean": 33.63645086340001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.33762376, 33.35721576, 34.05, 33.43923176, 35.62285576, 31.518815760000003, 31.169788000000004, 33.580431759999996, 33.35721576, 35.62285576, 31.190188000000003, 33.05, 34.703655760000004, 34.43923176, 34.479631760000004, 35.827287760000004, 27.049999999999997, 33.33762376, 34.05, 31.209788000000003, 31.296007760000002, 33.316815760000004, 28.050000000000004, 30.049999999999997, 35.827287760000004, 34.05, 36.05, 33.291388000000005, 31.35721576, 32.050000000000004, 33.49922376, 35.52124776, 33.41842376, 35.827287760000004, 31.049999999999997, 31.049999999999997, 33.35681576, 35.643663759999995, 33.35762376, 32.05, 34.05, 33.291388000000005, 34.68284776, 34.52124776, 33.291388000000005, 34.52124776, 32.25098800000001, 33.540839760000004, 33.316815760000004, 33.05, 30.049999999999997, 33.35721576, 32.291388000000005, 35.05, 35.68406376, 33.47923176, 34.56124776, 32.33762376, 33.35721576, 33.41842376, 32.230588000000004, 33.72487176, 32.25098800000001, 34.43923176, 31.210588, 34.05, 31.17158376, 34.70406376, 33.05, 37.05, 31.049999999999997, 35.78567176000001, 33.39883176, 33.37802376, 33.05, 35.68284776, 33.33762376, 36.643663759999995, 32.25058800000001, 35.827287760000004, 33.37802376, 35.581647759999996, 32.540839760000004, 33.643663759999995, 34.52124776, 33.540839760000004, 33.39883176, 34.74527176000001, 33.39761576, 35.642447759999996, 33.41842376, 30.050000000000004, 31.05, 31.35721576, 33.35681576, 31.049999999999997, 35.68366376, 32.05, 34.52124776, 36.05, 33.54003176, 35.56164776, 34.540839760000004, 33.43842376, 34.05, 32.39883176, 33.60083176, 31.31559976, 31.25439176, 33.316815760000004, 26.05, 31.518815760000003, 31.050000000000004, 35.643663759999995, 29.05, 31.049999999999997, 37.05, 35.05, 36.643663759999995, 36.80647976, 36.74487176, 34.540839760000004, 34.05, 33.41883176, 35.60204776, 31.050000000000004, 33.33762376, 32.45679976, 34.05, 34.74446376, 36.70487176, 31.049999999999997, 35.62204776, 33.316815760000004, 36.76607976, 33.43923176, 36.643663759999995, 35.643663759999995, 30.049999999999997, 33.291388000000005, 35.52124776, 35.52124776, 34.58123976, 31.250588000000004, 30.049999999999997, 33.291388000000005, 33.05, 34.66244776, 36.72446376, 33.35721576, 34.05, 33.05, 35.60164776, 31.374799760000002, 33.316815760000004, 33.49842376, 32.33762376, 32.70487176, 30.05, 34.43923176, 31.49800776, 35.56124776, 34.581647759999996, 34.62163976, 33.05, 35.52124776, 32.05, 34.46003976, 32.270988, 34.58083976, 35.58245576, 34.60204776, 27.05, 32.39802376, 30.050000000000004, 34.56164776, 35.05, 33.43923176, 34.05, 34.52124776, 34.52124776, 31.050000000000004, 32.05, 31.210588, 31.210588, 35.05, 36.05, 31.31559976, 34.46003976, 33.51883176, 34.52124776, 31.050000000000004, 32.05, 35.56164776, 32.49800776, 31.35721576, 32.25098800000001, 34.581647759999996, 33.291388000000005, 33.35721576, 35.703655760000004, 32.37802376, 36.05, 31.170188000000003, 35.05, 33.31641576, 32.27519976, 34.52124776, 33.35721576, 35.58245576, 34.49923176, 32.35721576, 35.78567176000001, 34.46003976, 35.66245576, 32.33762376, 33.316815760000004, 33.41842376, 34.43923176, 33.37802376, 35.05, 32.05, 34.500439760000006, 32.25098800000001, 36.643663759999995, 33.500439760000006, 35.56164776, 32.05, 34.480039760000004, 36.827287760000004, 32.31600776, 33.43883176, 32.33600776, 33.41842376, 33.37802376, 33.05, 33.05, 31.050000000000004, 33.43923176, 33.41842376, 34.05, 33.70487176, 34.642447759999996, 34.56083976, 36.05, 30.049999999999997, 35.56164776, 33.37802376, 33.479631760000004, 33.05, 35.62285576, 35.66325576, 31.33681576, 35.05, 35.703655760000004, 32.417207760000004, 33.291388000000005, 36.70487176, 35.68406376, 36.76607976, 33.05, 33.49922376, 32.270988, 33.49922376, 33.05, 33.43923176, 33.56164776, 34.500439760000006, 35.52124776, 34.58245576, 33.316815760000004, 33.35721576, 33.39883176, 33.291388000000005, 33.52124776, 32.210588, 32.05, 32.210588, 33.291388000000005, 31.250988000000003, 33.291388000000005, 34.39883176, 36.70487176, 35.62285576, 34.05, 33.37721576, 35.76486376, 34.68325576, 32.05, 31.170188000000003, 35.62285576, 32.316815760000004, 31.296007760000002, 34.39883176, 33.29641576, 32.210588, 35.66325576, 33.43923176, 31.31681576, 33.35721576, 33.478415760000004, 35.52124776, 36.72487176, 33.39883176, 33.500439760000006, 32.05, 35.05, 33.35681576, 33.35721576, 28.050000000000004, 31.270988000000003, 34.62285576, 34.56043176, 31.050000000000004, 33.58002376, 35.54124776, 31.050000000000004, 37.05, 33.05, 32.29600776, 35.703655760000004, 33.05, 33.41883176, 34.540839760000004, 32.35721576, 32.62285576, 37.05, 36.05, 33.56164776, 35.62204776, 32.230588000000004, 30.049999999999997, 32.25098800000001, 36.643663759999995, 36.74527176000001, 33.33762376, 35.70366376, 32.25058800000001, 35.05, 33.05, 31.210588, 32.291388000000005, 33.54124776, 35.70284776, 34.480039760000004, 32.49721576, 30.049999999999997, 33.33762376, 36.643663759999995, 30.05, 31.050000000000004, 30.05, 33.41842376, 36.05, 32.29600776, 32.33762376, 32.27560776, 35.62285576, 35.05, 33.05, 31.230588000000004, 35.70406376, 35.70284776, 36.70487176, 35.05, 32.33640776, 36.80647976, 30.049999999999997, 34.479631760000004, 35.05, 35.68406376, 35.643663759999995, 31.129788, 31.270988000000003, 30.049999999999997, 33.72446376, 34.52003976, 33.43801576, 33.35721576, 34.500439760000006, 33.43923176, 32.291388000000005, 36.68406376, 33.56164776, 36.05, 36.68406376, 34.46003976, 35.581647759999996, 34.62204776, 30.049999999999997, 28.050000000000004, 34.500439760000006, 33.291388000000005, 34.56164776, 33.316815760000004, 33.05, 35.643663759999995, 33.35721576, 32.29641576, 33.291388000000005, 35.66204776, 34.52003176, 31.170188000000003, 29.050000000000004, 33.291388000000005, 35.74446376, 37.05, 34.70487176, 31.049999999999997, 32.254799760000004, 33.479631760000004, 36.80647976, 35.70487176, 34.05, 33.66082376, 33.49841576, 31.31681576, 35.56164776, 34.479631760000004, 34.500439760000006, 31.33762376, 32.43923176, 36.70487176, 34.41883176, 33.33762376, 34.52124776, 34.56003976, 34.39883176, 31.33559976, 33.418023760000004, 36.70406376, 32.210588, 33.291388000000005, 32.050000000000004, 35.05, 31.47721576, 32.354799760000006, 34.52124776, 34.58123976, 31.47963176, 32.291388000000005, 33.49963176, 33.41842376, 34.76607976, 31.250588000000004, 34.78567176000001, 19.05, 33.316815760000004, 32.210588, 35.58245576, 33.39761576, 35.64164776, 34.39883176, 33.643663759999995, 32.37802376, 35.58245576, 34.05, 31.35681576, 34.60204776, 36.72446376, 35.05, 32.578807760000004, 29.049999999999997, 31.25479976, 35.54124776, 33.58002376, 32.25058800000001, 35.70487176, 33.05, 34.56164776, 33.05, 35.05, 35.68406376, 34.500439760000006, 33.56164776, 35.581647759999996, 34.41883176, 31.049999999999997, 33.37762376, 35.58245576, 31.275199760000003, 33.49922376, 31.250588000000004, 32.37721576, 31.049999999999997, 36.66366376, 35.703655760000004, 34.39883176, 31.049999999999997, 33.35762376, 32.230588000000004, 31.050000000000004, 35.52124776, 33.52124776, 34.68284776, 36.643663759999995, 34.58123976, 35.827287760000004, 33.37721576, 33.60204776, 33.05, 38.05, 33.52003176, 32.25098800000001, 34.70406376, 31.049999999999997, 36.78567176000001, 34.43923176, 34.39883176, 32.41842376, 33.62285576, 35.60204776, 34.60043176, 35.05, 33.05, 32.37680776, 33.291388000000005, 34.479631760000004, 33.39883176, 33.41842376, 37.827287760000004, 32.291388000000005, 34.62123976, 32.316815760000004, 32.05, 33.41883176, 33.37802376, 37.76607976, 33.37802376, 34.43923176, 36.05, 31.050000000000004, 31.210588, 31.209788000000003, 32.41842376, 33.43923176, 32.33762376, 35.64285576, 33.46003976, 33.43923176, 30.049999999999997, 33.37802376, 34.642447759999996, 35.58245576, 33.35721576, 33.050000000000004, 33.05, 34.39883176, 36.70487176, 33.39883176, 35.05, 35.05, 32.70487176, 33.66325576, 35.66325576, 33.46003976, 34.05, 38.05, 32.05, 32.05, 35.62285576, 33.35721576, 36.05, 32.210588, 33.291388000000005, 35.74405576, 31.050000000000004, 34.46003976, 34.46003976, 32.05, 35.05, 34.46003976, 29.049999999999997, 32.354799760000006, 32.270988, 32.316815760000004, 31.275199760000003, 32.291388000000005, 34.540839760000004, 35.60164776, 35.60204776, 31.210588, 35.56164776, 32.540839760000004, 34.540839760000004, 31.230588000000004, 36.68406376, 33.53962376, 36.05, 34.58123976, 35.64285576, 33.39883176, 36.643663759999995, 34.05, 32.291388000000005, 35.52124776, 31.416399760000004, 35.05, 34.43923176, 34.62285576, 32.25098800000001, 33.33681576, 33.43802376, 32.270988, 35.643663759999995, 35.68406376, 35.52124776, 32.61961576, 33.37802376, 32.37802376, 31.210588, 32.31600776, 32.291388000000005, 33.39721576, 36.72446376, 32.58245576, 27.049999999999997, 32.29600776, 33.35721576, 32.291388000000005, 33.05, 33.05, 34.479631760000004, 33.33762376, 34.52124776, 31.538407760000002, 35.66366376, 33.39883176, 35.60204776, 34.540839760000004, 33.05, 34.39883176, 33.643663759999995, 35.62285576, 33.500439760000006, 34.58123976, 34.05, 35.70487176, 35.76607976, 31.210188000000002, 33.050000000000004, 33.43923176, 31.049999999999997, 33.33762376, 34.05, 33.66325576, 36.78567176000001, 35.643663759999995, 34.52003176, 34.46003976, 29.049999999999997, 33.52124776, 32.05, 34.05, 33.52124776, 34.479631760000004, 34.66325576, 33.316815760000004, 35.58245576, 36.72446376, 31.049999999999997, 35.70487176, 35.05, 27.049999999999997, 31.37762376, 35.642447759999996, 32.46003976, 34.05, 33.291388000000005, 34.68284776, 36.70406376, 34.827287760000004, 32.05, 33.316815760000004, 33.291388000000005, 34.480039760000004, 33.41883176, 33.66325576, 34.54003176, 33.05, 35.66244776, 31.049999999999997, 36.68406376, 35.05, 35.643663759999995, 33.05, 34.05, 31.39721576, 33.52003176, 32.05, 37.05, 33.05, 35.78567176000001, 35.56164776, 32.270988, 35.58245576, 32.479631760000004, 36.05, 33.500439760000006, 34.05, 35.05, 33.479631760000004, 33.35721576, 34.39883176, 33.05, 35.56164776, 35.60245576, 35.76486376, 34.52124776, 32.316815760000004, 32.05, 32.25098800000001, 36.05, 33.05, 32.35599976, 32.25058800000001, 33.500439760000006, 35.60245576, 33.396415760000004, 32.29600776, 34.43923176, 34.43923176, 32.230588000000004, 34.479631760000004, 33.643663759999995, 34.56164776, 36.70487176, 35.66245576, 32.270988, 33.43923176, 35.05, 34.43923176, 34.62285576, 34.500439760000006, 35.60204776, 32.05, 32.230588000000004, 33.05, 31.049999999999997, 34.05, 33.41842376, 30.050000000000004, 34.49963176, 34.74527176000001, 35.05, 33.05, 33.291388000000005, 34.52003176, 33.45882376, 35.643663759999995, 34.56124776, 35.05, 34.56164776, 36.05, 36.72446376, 35.56164776, 33.33762376, 33.35762376, 34.43923176, 32.43842376, 31.169788000000004, 31.25399176, 33.39761576, 33.316815760000004, 34.52124776, 32.291388000000005, 34.46003976, 32.270988, 34.643663759999995, 33.05, 32.50003976000001, 35.58245576, 34.500439760000006, 36.80647976, 33.05, 32.05, 31.45721576, 31.478423760000002, 36.66366376, 31.230588000000004, 33.60204776, 34.62285576, 31.27560776, 33.05, 35.643663759999995, 33.43801576, 34.479631760000004, 32.255207760000005, 32.05, 32.417207760000004, 36.05, 36.74527176000001, 35.52124776, 34.70487176, 34.43923176, 33.47923176, 35.68406376, 31.049999999999997, 32.05, 32.230588000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.12984993406537856, "mean_inference_ms": 0.527894290019236, "mean_action_processing_ms": 0.040580992885644346, "mean_env_wait_ms": 0.0450196551234456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 28000, "agent_timesteps_total": 28000, "timers": {"sample_time_ms": 1517.641, "sample_throughput": 2635.67, "load_time_ms": 5.48, "load_throughput": 729915.672, "learn_time_ms": 2113.427, "learn_throughput": 1892.66, "update_time_ms": 1.543}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 2.8073248863220215, "policy_loss": -0.056080978363752365, "vf_loss": 2.8522789478302, "vf_explained_var": 0.9744778275489807, "kl": 0.01648520678281784, "entropy": 1.4741542339324951, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 28000, "num_agent_steps_sampled": 28000, "num_steps_trained": 28000, "num_agent_steps_trained": 28000}, "done": false, "episodes_total": 5600, "training_iteration": 7, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-21", "timestamp": 1628628741, "time_this_iter_s": 3.5550389289855957, "time_total_s": 25.601374864578247, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.601374864578247, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 36.46, "ram_util_percent": 69.92}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 24.049999999999997, "episode_reward_mean": 34.1483112325, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.70487176, 36.765271760000005, 33.58002376, 32.230588000000004, 34.76486376, 35.56164776, 25.05, 31.23399176, 34.43923176, 35.05, 33.05, 34.643663759999995, 29.049999999999997, 33.37802376, 32.25098800000001, 32.230588000000004, 34.39883176, 33.52124776, 34.66285576, 34.52124776, 32.46003976, 35.68406376, 35.52124776, 33.39883176, 33.39802376, 33.37802376, 35.642447759999996, 32.37802376, 34.05, 35.52124776, 31.149788, 31.05, 32.05, 35.66325576, 32.270988, 34.500439760000006, 34.480039760000004, 34.46003976, 32.316815760000004, 33.479631760000004, 35.66325576, 35.581647759999996, 35.05, 34.49963176, 35.05, 38.05, 34.540839760000004, 32.05, 33.05, 36.05, 35.52124776, 35.64285576, 33.316815760000004, 35.74527176000001, 35.68406376, 33.827287760000004, 34.43923176, 36.78567176000001, 33.479631760000004, 36.80647976, 27.050000000000004, 33.33681576, 31.049999999999997, 33.291388000000005, 33.05, 36.74527176000001, 35.62285576, 35.62204776, 29.05, 35.56164776, 31.55921576, 36.74527176000001, 36.70487176, 32.270988, 31.149788, 31.169788000000004, 35.56164776, 35.58245576, 32.46003976, 36.05, 35.05, 34.46003976, 33.39883176, 31.05, 34.540839760000004, 32.478415760000004, 32.37802376, 36.68406376, 34.46003976, 34.68406376, 32.27519976, 32.31600776, 34.479631760000004, 34.52124776, 36.05, 37.76607976, 34.56043176, 34.62163976, 33.33681576, 32.35721576, 36.72446376, 34.43883176, 35.60245576, 33.45923176, 35.58245576, 33.35721576, 32.58083976, 35.05, 35.581647759999996, 31.049999999999997, 33.35721576, 36.76607976, 32.05, 29.049999999999997, 34.05, 36.70487176, 35.703655760000004, 34.52003176, 31.049999999999997, 35.58245576, 31.049999999999997, 35.52124776, 36.68406376, 33.316815760000004, 32.37520776, 34.68406376, 34.46003976, 33.05, 33.62204776, 34.43923176, 34.66325576, 33.51881576, 33.41883176, 34.56164776, 34.58245576, 30.049999999999997, 35.58245576, 32.05, 33.43801576, 35.68406376, 32.270988, 35.52124776, 35.52124776, 33.05, 32.43923176, 36.05, 35.642447759999996, 30.049999999999997, 32.52043976, 33.500439760000006, 35.52124776, 34.642447759999996, 34.05, 36.76486376, 35.66325576, 35.62285576, 33.55921576, 34.54124776, 35.60245576, 27.049999999999997, 35.56164776, 35.56164776, 34.43883176, 33.478415760000004, 33.05, 34.52003176, 34.479631760000004, 34.60245576, 31.230588000000004, 32.05, 34.56083976, 34.480039760000004, 34.500439760000006, 32.230588000000004, 33.39883176, 36.70487176, 32.270988, 34.62163976, 35.62285576, 35.60204776, 31.170188000000003, 34.46003976, 33.35721576, 34.46003976, 36.76607976, 33.291388000000005, 36.70487176, 33.31641576, 32.43721576, 35.52124776, 35.643663759999995, 34.05, 35.58245576, 35.76607976, 32.05, 33.33681576, 32.05, 34.480039760000004, 36.68406376, 24.049999999999997, 34.39883176, 33.41842376, 36.05, 34.52124776, 35.60245576, 36.78567176000001, 34.39883176, 33.52043976, 34.39883176, 35.643663759999995, 34.05, 33.05, 31.250588000000004, 33.33762376, 31.291388000000005, 33.05, 32.05, 31.250988000000003, 35.56164776, 32.230588000000004, 36.68406376, 36.74527176000001, 33.43923176, 31.47882376, 33.43923176, 36.72446376, 34.56083976, 35.05, 34.68284776, 33.37802376, 35.05, 36.05, 34.52043976, 35.64285576, 34.52124776, 31.355207760000003, 31.230588000000004, 33.43883176, 34.05, 32.27519976, 33.49841576, 34.05, 35.56164776, 35.62204776, 37.05, 33.39883176, 35.60245576, 35.827287760000004, 35.52124776, 35.60204776, 34.540839760000004, 35.05, 30.049999999999997, 36.68406376, 35.62285576, 36.66366376, 35.58245576, 33.35762376, 36.70406376, 36.68406376, 37.80647976, 32.291388000000005, 32.540839760000004, 35.64285576, 34.62285576, 35.05, 35.58245576, 33.52003176, 35.52124776, 35.68406376, 35.643663759999995, 28.050000000000004, 34.43883176, 36.74527176000001, 34.62163976, 33.45923176, 33.291388000000005, 34.05, 34.39883176, 37.05, 33.39883176, 34.41883176, 34.43923176, 36.70487176, 36.68406376, 34.43923176, 31.41720776, 29.049999999999997, 32.316815760000004, 35.56164776, 31.396415760000004, 31.270988000000003, 32.230588000000004, 33.05, 33.49922376, 31.05, 33.05, 33.291388000000005, 33.35681576, 35.66325576, 34.05, 33.39883176, 35.52124776, 33.35762376, 30.05, 35.66325576, 34.68325576, 32.33762376, 34.500439760000006, 31.189788, 36.05, 30.049999999999997, 26.05, 33.316815760000004, 33.41883176, 32.29600776, 35.70487176, 31.149788, 35.56164776, 35.52124776, 35.60245576, 35.56164776, 33.316815760000004, 31.149788, 34.70487176, 33.35721576, 36.76607976, 33.43721576, 34.479631760000004, 35.58245576, 33.43802376, 35.05, 33.39761576, 35.52124776, 33.39883176, 29.049999999999997, 33.291388000000005, 33.39802376, 36.74487176, 35.66366376, 35.62285576, 36.643663759999995, 33.43923176, 33.41883176, 35.643663759999995, 30.049999999999997, 32.51881576, 32.35599976, 33.49963176, 35.05, 35.68284776, 34.56164776, 35.52124776, 34.58245576, 35.05, 36.78607976, 35.54124776, 34.500439760000006, 36.05, 35.60204776, 32.230588000000004, 35.05, 35.58245576, 34.58245576, 31.190188000000003, 35.58245576, 34.62245576, 34.62285576, 34.39883176, 34.52124776, 31.230588000000004, 37.827287760000004, 33.316815760000004, 28.049999999999997, 35.703255760000005, 33.39802376, 34.05, 34.52043976, 33.68284776, 33.581647759999996, 31.049999999999997, 34.52124776, 35.68406376, 35.62285576, 35.643663759999995, 34.479631760000004, 31.230588000000004, 35.58245576, 35.60204776, 33.39761576, 33.43842376, 34.43923176, 35.70487176, 35.52124776, 35.52124776, 32.33640776, 32.210588, 35.58245576, 36.05, 35.56164776, 35.52124776, 36.643663759999995, 35.52124776, 34.60204776, 33.37802376, 33.540839760000004, 33.316815760000004, 31.31641576, 34.500439760000006, 33.05, 35.52124776, 33.52124776, 35.68406376, 34.39883176, 35.58245576, 35.56164776, 35.703655760000004, 34.60204776, 34.580431759999996, 33.316815760000004, 32.05, 36.72446376, 34.41883176, 35.581647759999996, 33.35762376, 35.05, 35.52124776, 35.56164776, 33.43842376, 36.643663759999995, 35.05, 34.05, 33.45882376, 34.46003976, 34.39883176, 32.230588000000004, 34.500439760000006, 31.05, 29.050000000000004, 32.05, 33.43721576, 34.60204776, 33.33641576, 35.80647976, 35.05, 33.05, 34.52003176, 36.68366376, 33.33762376, 34.43923176, 34.68284776, 34.49963176, 32.35599976, 35.68406376, 32.05, 33.291388000000005, 31.149788, 35.72446376, 33.52124776, 33.37802376, 32.25098800000001, 34.74527176000001, 32.270988, 33.35721576, 35.58245576, 34.62285576, 32.27560776, 34.56164776, 35.58245576, 36.643663759999995, 33.500439760000006, 35.56164776, 37.76607976, 33.05, 35.62285576, 33.479631760000004, 36.78567176000001, 35.642447759999996, 36.68406376, 35.643663759999995, 34.39883176, 33.39883176, 35.58124776, 35.60204776, 32.41842376, 36.80647976, 32.35599976, 35.52124776, 32.230588000000004, 31.33600776, 34.642447759999996, 34.641639760000004, 35.58245576, 27.050000000000004, 34.500439760000006, 32.25098800000001, 34.500439760000006, 36.72446376, 31.43923176, 33.33762376, 34.52124776, 35.60245576, 33.66325576, 36.72446376, 30.05, 35.643663759999995, 35.66244776, 33.05, 33.291388000000005, 35.703655760000004, 36.70487176, 33.33762376, 34.05, 33.291388000000005, 31.49800776, 36.76607976, 36.66366376, 34.60204776, 33.316815760000004, 35.54124776, 34.05, 35.05, 35.52124776, 37.76607976, 35.58245576, 33.05, 34.39883176, 32.05, 33.05, 31.049999999999997, 34.46003976, 35.62285576, 34.60204776, 34.05, 31.35721576, 31.209788000000003, 31.05, 34.49963176, 36.05, 33.41883176, 35.62285576, 36.80647976, 35.68406376, 34.62285576, 33.05, 35.68406376, 35.643663759999995, 32.230588000000004, 36.70406376, 33.316815760000004, 34.70487176, 35.70487176, 30.05, 34.05, 33.45923176, 33.418023760000004, 34.39883176, 35.58245576, 31.210188000000002, 33.291388000000005, 33.43923176, 31.27560776, 31.05, 32.316815760000004, 34.05, 33.05, 34.43923176, 34.60245576, 35.52124776, 35.56164776, 34.39883176, 32.70487176, 35.52124776, 34.58123976, 35.581647759999996, 31.049999999999997, 35.643663759999995, 33.37721576, 33.39761576, 33.05, 36.76607976, 33.540839760000004, 32.05, 33.33681576, 35.56164776, 35.05, 33.662039760000006, 32.479631760000004, 33.52124776, 32.254799760000004, 34.05, 31.049999999999997, 34.46003976, 33.37721576, 34.52043976, 36.76486376, 33.05, 32.29600776, 35.62245576, 36.74527176000001, 33.39802376, 33.51922376, 35.60204776, 31.169788000000004, 37.05, 36.76607976, 35.70487176, 34.60083176, 33.52003176, 33.33762376, 35.66325576, 35.66366376, 37.78607976, 35.642447759999996, 33.479631760000004, 34.643663759999995, 31.170188000000003, 37.05, 37.80647976, 34.05, 32.230588000000004, 31.210588, 31.049999999999997, 32.291388000000005, 32.05, 33.291388000000005, 33.29641576, 35.52124776, 34.66325576, 29.05, 29.049999999999997, 31.049999999999997, 36.74527176000001, 36.68406376, 36.05, 35.05, 35.05, 35.05, 33.70487176, 34.68325576, 35.643663759999995, 36.05, 34.05, 32.05, 35.58245576, 33.35721576, 34.39883176, 36.643663759999995, 30.05, 33.33762376, 35.52124776, 33.35762376, 32.37802376, 36.74527176000001, 37.76607976, 32.47923176, 36.643663759999995, 35.60204776, 37.80647976, 34.41883176, 35.52124776, 34.39883176, 34.642447759999996, 34.56164776, 35.56164776, 34.46003976, 31.129788, 35.62285576, 35.58245576, 32.25098800000001, 33.39761576, 33.316815760000004, 37.76607976, 35.643663759999995, 36.66366376, 34.52043976, 31.275199760000003, 33.37721576, 36.643663759999995, 35.58245576, 33.316815760000004, 34.39883176, 35.56124776, 33.05, 34.641231760000004, 37.76607976, 36.643663759999995, 34.39883176, 31.53962376, 36.05, 33.479631760000004, 32.210588, 34.50003976000001, 36.68406376, 36.643663759999995, 35.60204776, 32.05, 33.43801576, 36.05, 33.52003176, 34.46003976, 31.049999999999997, 33.37802376, 35.60245576, 35.643663759999995, 35.60245576, 34.46003976, 35.58245576, 33.05, 35.52124776, 31.05, 35.56164776, 36.70406376, 34.56164776, 34.540839760000004, 32.210588, 35.642447759999996, 34.60204776, 33.39802376, 36.70487176, 35.70487176, 30.049999999999997, 33.291388000000005, 31.149788, 35.70487176, 35.52124776, 35.58245576, 33.35721576, 33.29641576, 36.643663759999995, 36.76607976, 33.479631760000004, 33.43842376, 31.270988000000003, 36.72446376, 35.72487176, 34.46003976, 35.52124776, 33.29641576, 37.05, 33.05, 33.43923176, 35.05, 35.52124776, 32.39761576, 32.291388000000005, 33.05, 35.66325576, 34.56043176, 35.62285576, 33.291388000000005, 33.05, 33.05, 35.05, 32.05, 35.05, 35.52124776, 34.05, 34.39883176, 36.05, 34.05, 34.43923176, 36.76607976, 33.05, 33.43762376, 35.58245576, 35.827287760000004, 31.049999999999997, 36.05, 33.05, 31.049999999999997, 33.37802376, 34.500439760000006, 37.80647976, 35.66366376, 33.43923176, 34.500439760000006, 35.05, 32.25098800000001, 37.827287760000004, 35.56164776, 37.80647976, 35.60204776, 32.05, 34.68325576, 33.39883176, 33.33762376, 32.43801576, 35.52124776, 35.54124776, 33.43923176, 33.33762376, 34.500439760000006, 35.58245576, 34.500439760000006, 36.70406376, 35.05, 35.58245576, 27.050000000000004, 36.643663759999995], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.12990801969577906, "mean_inference_ms": 0.5285644313706643, "mean_action_processing_ms": 0.04064982387842399, "mean_env_wait_ms": 0.04508767111004461, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 32000, "agent_timesteps_total": 32000, "timers": {"sample_time_ms": 1519.203, "sample_throughput": 2632.96, "load_time_ms": 4.908, "load_throughput": 814922.453, "learn_time_ms": 2109.96, "learn_throughput": 1895.771, "update_time_ms": 1.523}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 2.782726764678955, "policy_loss": -0.0624372772872448, "vf_loss": 2.8334245681762695, "vf_explained_var": 0.9752786755561829, "kl": 0.017391961067914963, "entropy": 1.3334869146347046, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 32000, "num_agent_steps_sampled": 32000, "num_steps_trained": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 6400, "training_iteration": 8, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-25", "timestamp": 1628628745, "time_this_iter_s": 3.6335089206695557, "time_total_s": 29.234883785247803, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.234883785247803, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 38.0, "ram_util_percent": 70.38}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 27.05, "episode_reward_mean": 34.7258447227, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.62285576, 35.66325576, 36.643663759999995, 35.60204776, 35.70406376, 36.643663759999995, 35.642447759999996, 36.643663759999995, 33.56043176, 33.316815760000004, 35.62204776, 31.291388000000005, 28.05, 34.52124776, 33.316815760000004, 33.35721576, 35.66366376, 34.50003976000001, 37.76607976, 34.480039760000004, 35.643663759999995, 34.41883176, 35.52124776, 31.049999999999997, 36.68406376, 34.43923176, 35.66325576, 34.43923176, 35.05, 34.05, 34.41883176, 35.62285576, 35.60204776, 34.45923176, 33.05, 32.050000000000004, 35.05, 35.76607976, 36.68406376, 35.56164776, 32.05, 35.56164776, 35.62285576, 34.39883176, 35.66325576, 35.642447759999996, 33.05, 34.62163976, 35.52124776, 35.68406376, 32.05, 36.05, 35.68406376, 36.68406376, 35.05, 36.643663759999995, 34.68406376, 34.58123976, 36.72487176, 34.56164776, 37.80647976, 36.70406376, 33.316815760000004, 32.210588, 33.35721576, 36.70487176, 36.05, 35.70406376, 34.52124776, 36.05, 33.316815760000004, 35.643663759999995, 36.76607976, 35.60204776, 34.49963176, 35.643663759999995, 33.39883176, 32.500439760000006, 32.33640776, 33.39761576, 35.66285576, 36.05, 34.479631760000004, 35.54124776, 33.05, 36.643663759999995, 36.74527176000001, 34.68406376, 32.050000000000004, 35.56164776, 33.41842376, 34.56083976, 35.68406376, 33.05, 33.05, 35.64285576, 34.479631760000004, 34.60204776, 35.66244776, 35.54124776, 32.540039760000006, 34.05, 34.56164776, 35.581647759999996, 35.52124776, 36.70487176, 36.643663759999995, 35.66325576, 35.703255760000005, 35.62285576, 34.500439760000006, 35.52124776, 31.049999999999997, 35.05, 33.37802376, 32.05, 33.05, 35.05, 36.70487176, 32.291388000000005, 37.76607976, 35.703655760000004, 31.35721576, 33.479631760000004, 35.52124776, 33.05, 35.52124776, 36.70406376, 34.43923176, 35.58245576, 36.643663759999995, 35.05, 33.540839760000004, 35.643663759999995, 33.479631760000004, 35.62285576, 35.642447759999996, 32.25098800000001, 34.05, 34.540839760000004, 35.52124776, 37.80647976, 34.43923176, 36.72446376, 35.581647759999996, 36.643663759999995, 35.66244776, 33.45882376, 33.500439760000006, 37.05, 34.540839760000004, 32.37721576, 36.68406376, 35.60124776, 33.316815760000004, 34.64285576, 34.54124776, 31.049999999999997, 27.05, 32.291388000000005, 33.39883176, 31.149788, 34.39883176, 35.58245576, 34.43923176, 35.62285576, 35.60245576, 35.62285576, 36.643663759999995, 35.643663759999995, 33.50003976000001, 35.05, 33.39883176, 35.66325576, 33.291388000000005, 34.05, 36.643663759999995, 34.39883176, 31.049999999999997, 33.479631760000004, 35.05, 36.74527176000001, 35.66325576, 32.316815760000004, 34.52124776, 33.291388000000005, 33.291388000000005, 34.58245576, 31.35721576, 35.642447759999996, 35.56164776, 36.643663759999995, 31.189788, 34.39883176, 33.291388000000005, 34.52043976, 36.643663759999995, 35.52124776, 37.76607976, 36.70487176, 34.500439760000006, 34.479631760000004, 35.58245576, 35.66325576, 34.56043176, 34.58245576, 35.56164776, 37.05, 34.60204776, 35.05, 35.58245576, 34.39883176, 35.05, 34.43923176, 34.500439760000006, 36.68406376, 35.56164776, 35.58245576, 34.60204776, 36.80647976, 35.05, 33.33762376, 34.68406376, 35.56164776, 36.05, 33.41761576, 33.43801576, 36.68406376, 35.62285576, 34.43923176, 36.74527176000001, 34.43923176, 34.76607976, 33.37802376, 35.643663759999995, 31.170188000000003, 34.46003976, 33.52124776, 34.62285576, 33.05, 33.33681576, 35.05, 33.39883176, 35.643663759999995, 33.35721576, 35.68406376, 32.230588000000004, 35.05, 35.58245576, 33.05, 33.35762376, 33.33762376, 36.66366376, 32.230588000000004, 36.70487176, 34.58245576, 35.62285576, 36.827287760000004, 33.05, 34.480039760000004, 31.05, 34.39883176, 35.60204776, 35.66366376, 34.43923176, 33.500439760000006, 34.05, 36.05, 34.43923176, 32.05, 33.050000000000004, 34.05, 35.52124776, 34.479631760000004, 31.049999999999997, 32.05, 34.43923176, 34.68163176, 32.37762376, 34.39883176, 34.66244776, 35.60204776, 35.05, 36.643663759999995, 35.62285576, 35.52124776, 35.60204776, 35.05, 38.05, 35.643663759999995, 35.58245576, 34.46003976, 35.68406376, 33.35721576, 31.190188000000003, 35.56164776, 34.39883176, 33.39883176, 33.39761576, 33.418023760000004, 36.70487176, 35.52124776, 32.37802376, 31.05, 33.316815760000004, 36.66366376, 33.56083976, 35.52124776, 34.46003976, 33.316815760000004, 36.68366376, 33.05, 34.479631760000004, 33.33762376, 35.56164776, 35.52124776, 34.54124776, 35.68406376, 34.41883176, 32.29600776, 37.827287760000004, 36.72446376, 35.56164776, 35.643663759999995, 35.642447759999996, 33.46003976, 35.52124776, 34.70487176, 34.662039760000006, 34.39883176, 34.60083976, 35.70487176, 34.43923176, 35.642447759999996, 36.643663759999995, 35.70487176, 35.60204776, 35.52124776, 34.52043976, 35.60204776, 36.72487176, 34.662039760000006, 34.39883176, 31.049999999999997, 35.58245576, 34.05, 33.35721576, 33.05, 34.540839760000004, 36.05, 33.291388000000005, 35.643663759999995, 36.765271760000005, 36.70406376, 34.56043176, 34.41883176, 29.050000000000004, 34.43923176, 35.68325576, 35.74405576, 35.58124776, 35.52124776, 31.250588000000004, 35.66325576, 33.316815760000004, 35.62285576, 34.58124776, 36.66366376, 34.479631760000004, 36.74527176000001, 33.291388000000005, 34.43923176, 32.05, 38.05, 35.56164776, 31.313999760000005, 35.52124776, 35.52124776, 35.52124776, 36.80647976, 35.70487176, 33.46003976, 36.643663759999995, 35.643663759999995, 34.479631760000004, 33.291388000000005, 35.05, 36.72487176, 34.58245576, 33.37762376, 35.52124776, 34.45923176, 35.56164776, 31.049999999999997, 35.60164776, 35.60204776, 34.05, 34.500439760000006, 35.56164776, 34.68366376, 36.643663759999995, 31.210588, 33.291388000000005, 37.827287760000004, 35.62285576, 35.66366376, 36.68406376, 36.80647976, 35.643663759999995, 36.643663759999995, 37.76607976, 33.05, 35.58245576, 35.52124776, 32.56164776, 28.050000000000004, 35.78607976, 32.39761576, 36.70487176, 33.643663759999995, 34.479631760000004, 33.39883176, 34.60083176, 35.70406376, 36.68406376, 36.76486376, 36.72487176, 33.479631760000004, 30.049999999999997, 35.68284776, 38.05, 34.56164776, 33.050000000000004, 35.52124776, 34.39883176, 36.70487176, 33.37802376, 35.62285576, 29.05, 35.68406376, 33.47923176, 36.70487176, 35.68406376, 32.05, 36.78567176000001, 36.643663759999995, 36.05, 33.316815760000004, 35.62285576, 34.66325576, 33.33681576, 32.25098800000001, 33.37802376, 36.68406376, 31.210588, 35.66325576, 35.54124776, 33.35721576, 36.643663759999995, 34.56043176, 32.316815760000004, 30.050000000000004, 35.703655760000004, 35.643663759999995, 34.58245576, 35.05, 35.60204776, 35.62285576, 34.52124776, 36.76607976, 36.76607976, 34.05, 35.72487176, 35.642447759999996, 35.62285576, 33.05, 34.601239760000006, 35.52124776, 35.56164776, 36.643663759999995, 36.68406376, 32.39761576, 34.52124776, 32.43519976, 34.05, 35.78607976, 33.35721576, 32.210588, 33.60204776, 37.76607976, 35.54124776, 35.72446376, 34.52003176, 35.52124776, 34.56164776, 36.80647976, 35.58245576, 35.56164776, 35.80647976, 36.74527176000001, 36.68406376, 36.70487176, 34.62285576, 36.643663759999995, 32.29600776, 35.60204776, 35.76607976, 33.05, 31.37802376, 36.70487176, 30.049999999999997, 35.60245576, 33.05, 33.291388000000005, 35.642447759999996, 34.580431759999996, 35.52124776, 33.05, 35.62285576, 34.500439760000006, 35.60164776, 36.643663759999995, 35.66325576, 34.52043976, 36.78607976, 34.540839760000004, 35.62285576, 34.46003976, 34.05, 32.33762376, 35.66325576, 35.52124776, 36.643663759999995, 33.05, 35.52124776, 34.39883176, 32.316815760000004, 35.58245576, 35.581647759999996, 35.66366376, 33.37802376, 35.72446376, 35.66325576, 35.52124776, 35.62285576, 34.46003976, 35.60245576, 33.52124776, 33.33762376, 34.479631760000004, 34.39883176, 35.62285576, 35.58245576, 33.43923176, 33.479631760000004, 34.55923176, 35.60204776, 34.53963176, 31.33762376, 35.68406376, 34.540839760000004, 32.25098800000001, 35.60204776, 36.643663759999995, 36.80647976, 35.60204776, 35.05, 32.29600776, 33.05, 34.58245576, 35.60204776, 32.05, 35.52124776, 34.479631760000004, 33.500439760000006, 34.05, 36.74446376, 35.643663759999995, 35.05, 33.05, 36.05, 33.41842376, 36.643663759999995, 35.54124776, 35.62285576, 35.643663759999995, 36.76486376, 33.35721576, 34.540839760000004, 36.68406376, 35.58245576, 37.05, 35.52124776, 34.66325576, 35.05, 34.479631760000004, 37.76607976, 32.210588, 34.479631760000004, 34.39883176, 34.60083176, 35.58245576, 31.210588, 32.29600776, 35.05, 35.74527176000001, 36.76607976, 36.70487176, 32.33640776, 34.43923176, 35.05, 35.05, 35.58245576, 35.52124776, 36.643663759999995, 36.78567176000001, 33.37802376, 35.643663759999995, 34.642455760000004, 33.479631760000004, 35.52124776, 34.52124776, 36.80647976, 35.05, 32.500439760000006, 37.05, 34.39883176, 35.05, 31.049999999999997, 36.74527176000001, 34.05, 35.52124776, 32.050000000000004, 35.62285576, 35.827287760000004, 32.39680776, 33.29641576, 34.56043176, 35.56164776, 36.72487176, 36.643663759999995, 34.46003976, 36.72446376, 35.52124776, 34.43923176, 34.46003976, 37.827287760000004, 34.43923176, 36.68406376, 34.05, 31.250988000000003, 33.316815760000004, 35.58245576, 35.54124776, 37.80647976, 33.39883176, 30.050000000000004, 34.51883176, 35.60245576, 31.460039760000004, 32.27519976, 31.33519176, 36.643663759999995, 36.76607976, 34.39883176, 34.500439760000006, 35.703655760000004, 35.68406376, 34.56043176, 36.78567176000001, 32.37802376, 35.62285576, 35.62285576, 34.480039760000004, 36.70487176, 35.52124776, 34.540839760000004, 33.72324776, 34.62285576, 34.479631760000004, 34.62163976, 34.52043976, 35.72446376, 36.76607976, 36.643663759999995, 35.52124776, 34.45923176, 35.56164776, 31.190188000000003, 35.72446376, 35.66325576, 34.05, 35.54124776, 35.56164776, 32.315599760000005, 34.41883176, 34.540839760000004, 35.66366376, 35.52124776, 32.05, 34.52003176, 35.05, 35.581647759999996, 35.68406376, 35.643663759999995, 33.05, 36.68406376, 35.58245576, 34.479631760000004, 32.05, 35.58245576, 35.66325576, 34.43923176, 31.049999999999997, 32.210588, 34.500439760000006, 33.291388000000005, 35.64285576, 34.540839760000004, 34.540839760000004, 33.55921576, 33.41883176, 33.35721576, 34.43923176, 34.43923176, 34.52124776, 38.05, 34.52043976, 35.643663759999995, 35.703655760000004, 35.643663759999995, 35.62285576, 34.43923176, 35.56164776, 36.66366376, 30.049999999999997, 32.25058800000001, 36.74527176000001, 36.643663759999995, 35.54124776, 33.33762376, 32.05, 35.52124776, 31.37721576, 33.05, 33.47882376, 33.49963176, 34.43923176, 36.70487176, 33.37802376, 35.52124776, 33.35721576, 35.72446376, 31.129788, 34.50003976000001, 34.05, 36.643663759999995, 36.76607976, 35.68406376, 33.37802376, 36.643663759999995, 31.170188000000003, 35.58245576, 32.050000000000004, 35.643663759999995, 32.05, 35.05, 33.43801576, 36.68406376, 35.52124776, 34.500439760000006, 35.62285576, 34.703655760000004, 33.05, 36.68406376, 36.68406376, 34.43923176, 34.480039760000004, 34.39883176, 34.43923176, 36.70487176, 33.35762376, 35.643663759999995, 34.56164776, 35.70487176, 33.33762376, 34.41883176, 35.54124776, 34.60204776, 35.60204776, 34.540839760000004, 35.56164776, 34.64285576, 33.05, 35.05, 34.58245576, 35.52124776, 34.43923176, 35.62285576, 37.827287760000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13043166438670073, "mean_inference_ms": 0.5307316177454626, "mean_action_processing_ms": 0.04088632941649997, "mean_env_wait_ms": 0.04529104015044548, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 36000, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 1525.433, "sample_throughput": 2622.207, "load_time_ms": 4.464, "load_throughput": 896069.884, "learn_time_ms": 2110.756, "learn_throughput": 1895.055, "update_time_ms": 1.499}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1.469135046005249, "policy_loss": -0.06588740646839142, "vf_loss": 1.5237998962402344, "vf_explained_var": 0.9868228435516357, "kl": 0.016626128926873207, "entropy": 1.212689757347107, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 36000, "num_agent_steps_sampled": 36000, "num_steps_trained": 36000, "num_agent_steps_trained": 36000}, "done": false, "episodes_total": 7200, "training_iteration": 9, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-28", "timestamp": 1628628748, "time_this_iter_s": 3.710465908050537, "time_total_s": 32.94534969329834, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.94534969329834, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 39.983333333333334, "ram_util_percent": 71.25}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 26.049999999999997, "episode_reward_mean": 35.1073212582, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.05, 33.479631760000004, 35.643663759999995, 36.70487176, 32.76486376, 33.35762376, 32.05, 32.33762376, 35.56164776, 36.80647976, 33.56164776, 35.62285576, 35.643663759999995, 35.60204776, 37.05, 32.05, 32.316815760000004, 35.66366376, 36.70487176, 35.60204776, 36.70406376, 34.05, 35.66325576, 37.05, 35.66325576, 36.70487176, 35.62204776, 32.210588, 33.39883176, 37.05, 35.58245576, 34.540839760000004, 36.72446376, 35.60204776, 36.72446376, 32.46003976, 35.58245576, 35.56164776, 33.33762376, 38.05, 35.56164776, 33.41842376, 35.52124776, 35.05, 34.39883176, 35.54124776, 35.58245576, 32.395199760000004, 32.210588, 37.78607976, 36.643663759999995, 37.827287760000004, 32.46003976, 35.62285576, 37.05, 35.56164776, 35.58245576, 35.643663759999995, 37.827287760000004, 35.05, 36.05, 32.05, 36.70487176, 37.827287760000004, 35.76607976, 36.05, 35.62285576, 34.52124776, 35.642447759999996, 35.56164776, 36.68406376, 36.643663759999995, 36.76607976, 33.37802376, 35.68406376, 34.39883176, 36.643663759999995, 35.68406376, 35.68406376, 35.52124776, 32.25098800000001, 38.05, 32.35721576, 35.60204776, 36.643663759999995, 34.46003976, 35.52124776, 35.56164776, 34.05, 35.643663759999995, 35.60204776, 35.60245576, 33.05, 35.703655760000004, 36.70487176, 35.56124776, 34.05, 35.56164776, 36.76607976, 36.76607976, 35.60204776, 35.56164776, 38.05, 35.68406376, 36.05, 35.58245576, 35.643663759999995, 35.56124776, 36.643663759999995, 35.05, 35.52124776, 34.60204776, 35.52124776, 35.62285576, 36.05, 31.049999999999997, 35.52124776, 36.643663759999995, 34.43923176, 37.76607976, 35.581647759999996, 34.62285576, 37.76607976, 34.56164776, 35.52124776, 31.41842376, 36.70487176, 35.60204776, 34.52124776, 34.68284776, 34.70487176, 36.643663759999995, 35.76607976, 36.05, 36.643663759999995, 33.35721576, 36.68406376, 34.60083176, 34.52124776, 33.05, 36.66366376, 35.703655760000004, 35.60245576, 34.05, 37.05, 34.60204776, 33.58245576, 35.643663759999995, 35.62204776, 33.642447759999996, 34.540839760000004, 37.76607976, 35.66325576, 37.05, 34.39883176, 35.58245576, 35.62285576, 35.56164776, 35.05, 37.76607976, 33.33762376, 34.500439760000006, 31.25479976, 35.72446376, 35.62204776, 35.54124776, 35.72446376, 35.765271760000005, 38.05, 36.643663759999995, 34.39883176, 35.56164776, 36.05, 35.72487176, 35.70284776, 35.58245576, 36.78607976, 32.230588000000004, 35.62285576, 35.58245576, 31.270988000000003, 33.43923176, 36.72446376, 34.66366376, 36.643663759999995, 33.58245576, 33.05, 35.05, 34.479631760000004, 34.46003976, 36.70487176, 36.68406376, 35.52124776, 35.58245576, 35.643663759999995, 35.60245576, 35.72446376, 35.62285576, 36.72446376, 34.52124776, 34.43923176, 35.52124776, 35.05, 35.581647759999996, 32.641231760000004, 35.52124776, 33.05, 35.05, 35.68406376, 37.78607976, 36.74527176000001, 33.43923176, 35.62285576, 33.291388000000005, 35.52124776, 35.52124776, 35.05, 34.52124776, 35.52124776, 36.70487176, 35.66244776, 34.43923176, 32.51923176, 34.479631760000004, 36.70487176, 35.76607976, 35.60204776, 35.56164776, 33.46003976, 33.56164776, 34.45923176, 34.479631760000004, 34.39883176, 35.643663759999995, 33.46003976, 32.05, 35.72446376, 35.52124776, 35.56164776, 35.66366376, 35.05, 33.05, 37.05, 36.66366376, 34.39883176, 35.52124776, 36.643663759999995, 34.05, 35.56164776, 36.70487176, 35.56164776, 35.643663759999995, 34.43923176, 36.827287760000004, 36.78607976, 35.52124776, 36.643663759999995, 35.52124776, 36.643663759999995, 34.480039760000004, 35.56164776, 36.765271760000005, 34.66325576, 31.23359176, 35.68406376, 35.05, 36.643663759999995, 32.480039760000004, 35.52124776, 34.479631760000004, 35.58245576, 32.210588, 34.60204776, 35.62285576, 35.52124776, 33.39883176, 36.72487176, 33.35721576, 34.52003976, 35.52124776, 36.72446376, 34.39883176, 35.60204776, 34.39883176, 33.39883176, 35.52124776, 35.52124776, 35.52124776, 32.395607760000004, 35.66325576, 36.643663759999995, 36.74527176000001, 36.68406376, 36.80647976, 35.64204776, 36.74487176, 33.43923176, 36.68406376, 36.76607976, 35.52124776, 34.62245576, 35.643663759999995, 31.234399760000002, 36.765271760000005, 33.37802376, 36.643663759999995, 33.33762376, 34.60083176, 33.291388000000005, 31.43842376, 35.52124776, 36.70487176, 31.210188000000002, 35.58245576, 33.291388000000005, 36.70487176, 34.39883176, 32.500439760000006, 33.39883176, 35.58245576, 37.05, 35.05, 32.25058800000001, 34.581647759999996, 32.230588000000004, 31.436799760000003, 34.60204776, 35.52124776, 35.58245576, 35.56124776, 38.05, 35.58245576, 36.70487176, 34.46003976, 37.827287760000004, 35.60204776, 35.58245576, 34.540839760000004, 35.52124776, 36.643663759999995, 36.72487176, 37.05, 32.05, 31.049999999999997, 36.643663759999995, 35.56164776, 35.54124776, 35.60204776, 35.58245576, 35.62285576, 32.05, 36.05, 34.54124776, 35.703655760000004, 36.70406376, 35.52124776, 32.53840776, 34.500439760000006, 36.643663759999995, 32.41883176, 36.70487176, 35.52124776, 35.72365576, 37.76607976, 36.68406376, 34.39883176, 35.58245576, 34.58123976, 34.68284776, 35.54124776, 34.56043976, 35.52124776, 35.56164776, 35.68284776, 32.25058800000001, 37.05, 33.291388000000005, 31.049999999999997, 34.56043176, 36.68406376, 34.52124776, 34.68406376, 31.233999760000003, 30.049999999999997, 36.05, 35.52124776, 34.479631760000004, 35.56164776, 35.56164776, 34.49963176, 29.049999999999997, 30.049999999999997, 35.827287760000004, 36.78567176000001, 36.76607976, 31.250588000000004, 35.54124776, 34.60204776, 34.05, 35.05, 35.60204776, 36.05, 36.74527176000001, 35.62285576, 36.643663759999995, 34.479631760000004, 37.05, 34.05, 35.56164776, 31.35721576, 35.56164776, 33.643663759999995, 36.70487176, 32.480039760000004, 31.31681576, 34.479631760000004, 35.52124776, 35.58245576, 35.60204776, 36.643663759999995, 34.05, 36.70487176, 35.56164776, 36.76486376, 36.643663759999995, 34.66325576, 35.72446376, 35.581647759999996, 36.76607976, 36.66366376, 34.62163976, 35.58245576, 34.827287760000004, 35.56164776, 34.60204776, 36.70487176, 33.35721576, 35.56164776, 34.39883176, 31.250988000000003, 32.25098800000001, 36.68406376, 35.56164776, 38.05, 35.62285576, 34.480039760000004, 38.05, 36.643663759999995, 31.33600776, 34.46003976, 33.316815760000004, 33.29641576, 35.52124776, 36.68406376, 32.43923176, 35.05, 35.70487176, 37.76607976, 34.540839760000004, 38.05, 35.56164776, 35.64285576, 36.68366376, 35.60204776, 35.70487176, 36.05, 35.72487176, 35.56164776, 37.76607976, 35.52124776, 33.35721576, 34.46003976, 35.56164776, 36.68406376, 35.643663759999995, 35.52124776, 35.52124776, 35.52124776, 34.52124776, 32.25098800000001, 32.291388000000005, 35.56164776, 35.52124776, 36.643663759999995, 32.291388000000005, 34.41883176, 36.827287760000004, 36.66366376, 36.70487176, 35.56164776, 35.643663759999995, 36.78567176000001, 33.53962376, 35.56164776, 33.39883176, 36.643663759999995, 35.52124776, 35.74527176000001, 36.72487176, 36.76607976, 32.35721576, 34.60204776, 33.05, 30.05, 35.60204776, 35.60245576, 36.70487176, 36.72487176, 35.58245576, 30.049999999999997, 35.70487176, 34.641231760000004, 32.050000000000004, 31.291388000000005, 34.39883176, 35.52124776, 35.62285576, 35.581647759999996, 33.33762376, 34.581647759999996, 35.05, 36.72446376, 36.05, 35.643663759999995, 35.05, 34.72324776, 34.479631760000004, 33.05, 37.76607976, 35.58245576, 35.56164776, 35.52124776, 36.643663759999995, 34.46003976, 35.643663759999995, 35.70487176, 34.39883176, 35.58245576, 35.643663759999995, 32.05, 32.05, 36.72487176, 35.05, 35.62285576, 34.56124776, 33.05, 35.05, 35.58245576, 35.58245576, 36.643663759999995, 33.37802376, 35.58245576, 35.60245576, 35.66325576, 35.52124776, 36.05, 34.500439760000006, 34.05, 36.70487176, 34.46003976, 34.52124776, 31.049999999999997, 36.68406376, 35.05, 37.05, 35.60204776, 36.70487176, 35.70487176, 36.70487176, 36.80647976, 33.291388000000005, 33.74527176000001, 35.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 33.37802376, 37.76607976, 35.56164776, 33.70487176, 36.643663759999995, 34.66325576, 36.76607976, 35.52124776, 33.43923176, 33.39883176, 35.70487176, 35.68366376, 36.68406376, 35.56164776, 35.62285576, 36.72487176, 35.58245576, 35.52124776, 37.76607976, 36.76607976, 35.52124776, 35.58245576, 34.68163176, 36.72446376, 34.05, 33.39883176, 35.52124776, 37.76607976, 34.50003976000001, 36.643663759999995, 35.60204776, 35.68406376, 31.250588000000004, 33.35721576, 32.05, 36.70487176, 36.68406376, 36.70487176, 28.049999999999997, 34.480039760000004, 33.316815760000004, 34.56164776, 37.76607976, 35.68406376, 35.52124776, 34.58245576, 35.52124776, 36.76607976, 34.56043176, 34.39883176, 36.76607976, 35.643663759999995, 33.316815760000004, 35.58245576, 35.62285576, 35.80647976, 35.05, 35.60204776, 32.270988, 32.05, 36.68406376, 34.43923176, 35.62285576, 35.643663759999995, 35.56164776, 34.52124776, 32.05, 35.62285576, 36.643663759999995, 36.70487176, 33.33641576, 35.643663759999995, 38.05, 37.05, 35.74527176000001, 35.62285576, 35.52124776, 35.58245576, 35.62124776, 31.35599976, 34.52124776, 35.60245576, 34.43923176, 35.56164776, 35.643663759999995, 35.58245576, 31.27560776, 36.70487176, 36.643663759999995, 33.05, 35.643663759999995, 34.60204776, 36.70487176, 31.049999999999997, 35.70487176, 33.35721576, 34.05, 34.480039760000004, 34.56083976, 36.76607976, 35.52124776, 31.291388000000005, 35.56164776, 35.52124776, 36.72446376, 35.56164776, 34.39883176, 29.049999999999997, 35.62285576, 36.643663759999995, 35.58245576, 36.70487176, 30.050000000000004, 35.56164776, 35.56164776, 35.76607976, 35.05, 35.64285576, 34.43923176, 37.05, 36.76607976, 35.643663759999995, 33.29641576, 32.050000000000004, 36.66366376, 36.643663759999995, 35.52124776, 36.643663759999995, 34.43923176, 34.76607976, 36.74527176000001, 34.52043976, 35.52124776, 34.39883176, 35.643663759999995, 36.05, 35.66325576, 34.52124776, 34.39883176, 34.39883176, 36.74527176000001, 36.643663759999995, 34.479631760000004, 35.05, 33.43923176, 36.76486376, 34.479631760000004, 36.05, 37.76607976, 34.68325576, 26.049999999999997, 35.68284776, 33.43801576, 32.33681576, 35.74527176000001, 35.56124776, 33.41842376, 37.05, 36.643663759999995, 36.68406376, 34.500439760000006, 35.58245576, 35.78567176000001, 36.70487176, 33.05, 33.70487176, 35.60245576, 35.58245576, 31.458023760000003, 37.76607976, 33.05, 34.479631760000004, 35.60164776, 36.76607976, 35.58245576, 33.58245576, 33.41842376, 30.050000000000004, 35.60164776, 34.43923176, 33.35762376, 33.60083176, 35.56164776, 34.05, 35.56164776, 35.52124776, 37.80647976, 35.66244776, 35.54124776, 35.56164776, 35.70406376, 34.46003976, 36.70487176, 35.58245576, 37.05, 35.54124776, 36.643663759999995, 35.52124776, 35.643663759999995, 37.76607976, 36.05, 32.05, 35.60204776, 35.643663759999995, 32.210588, 34.540839760000004, 33.291388000000005, 35.56164776, 35.56164776, 34.52124776, 35.56164776, 36.643663759999995, 33.39883176, 34.74527176000001, 35.05, 37.05, 34.39883176, 34.66325576, 35.56164776, 35.68284776, 34.62285576, 31.049999999999997, 34.500439760000006, 36.68406376], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1428526381565138, "mean_inference_ms": 0.5832696448540152, "mean_action_processing_ms": 0.04498854642343261, "mean_env_wait_ms": 0.04970783007442339, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 40000, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 1674.693, "sample_throughput": 2388.497, "load_time_ms": 4.195, "load_throughput": 953554.313, "learn_time_ms": 2309.249, "learn_throughput": 1732.165, "update_time_ms": 1.641}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1.4029338359832764, "policy_loss": -0.060375723987817764, "vf_loss": 1.4555813074111938, "vf_explained_var": 0.9874565005302429, "kl": 0.0114491181448102, "entropy": 1.1052780151367188, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 40000, "num_steps_trained": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 8000, "training_iteration": 10, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-35", "timestamp": 1628628755, "time_this_iter_s": 7.149119853973389, "time_total_s": 40.09446954727173, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 40.09446954727173, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 41.260000000000005, "ram_util_percent": 72.32}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 27.05, "episode_reward_mean": 35.5571442303, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.56164776, 33.33681576, 36.78567176000001, 36.70487176, 36.72446376, 35.58245576, 36.05, 36.05, 35.66325576, 35.54124776, 36.827287760000004, 36.643663759999995, 35.52124776, 35.643663759999995, 35.52124776, 36.68406376, 36.70487176, 36.66366376, 33.316815760000004, 36.76607976, 35.62285576, 35.54124776, 36.76607976, 36.643663759999995, 35.56164776, 34.46003976, 35.64164776, 35.56164776, 36.643663759999995, 36.643663759999995, 35.52124776, 33.35721576, 34.41883176, 31.33681576, 35.58245576, 35.62285576, 36.643663759999995, 35.52124776, 35.52124776, 36.827287760000004, 35.52124776, 34.643663759999995, 35.56164776, 36.72446376, 30.049999999999997, 32.291388000000005, 34.52003176, 35.68406376, 34.540839760000004, 37.05, 31.190188000000003, 37.05, 35.60204776, 36.05, 36.643663759999995, 36.78567176000001, 33.45882376, 36.68406376, 35.52124776, 35.68406376, 34.540839760000004, 35.56164776, 35.52124776, 35.56164776, 34.05, 35.52124776, 35.581647759999996, 37.76607976, 35.60204776, 35.52124776, 36.68406376, 36.643663759999995, 35.52124776, 36.66366376, 36.68406376, 31.37802376, 36.05, 35.62285576, 36.76607976, 35.52124776, 36.827287760000004, 37.76607976, 35.56164776, 35.58245576, 36.76607976, 34.05, 36.76607976, 36.70487176, 36.643663759999995, 35.642447759999996, 38.05, 36.78567176000001, 37.76607976, 33.33762376, 36.68406376, 35.643663759999995, 35.643663759999995, 35.60204776, 37.76607976, 35.58245576, 36.643663759999995, 35.58245576, 32.25058800000001, 35.58245576, 32.05, 36.70487176, 37.76607976, 37.827287760000004, 36.72446376, 36.70487176, 35.58245576, 36.72446376, 37.76607976, 35.581647759999996, 36.76607976, 35.581647759999996, 38.05, 36.70406376, 33.479631760000004, 32.29600776, 35.56164776, 35.643663759999995, 35.52124776, 36.05, 31.05, 36.70487176, 36.74527176000001, 36.643663759999995, 35.56164776, 32.21399976, 38.05, 35.62285576, 36.76607976, 35.58245576, 35.56164776, 36.68406376, 34.581647759999996, 34.05, 33.05, 34.46003976, 37.76607976, 33.37802376, 35.52124776, 36.643663759999995, 36.643663759999995, 35.60204776, 35.60245576, 35.56164776, 35.05, 35.62285576, 35.52124776, 33.37721576, 35.52124776, 36.643663759999995, 35.58245576, 36.68366376, 35.70487176, 36.68406376, 35.52124776, 36.643663759999995, 32.41842376, 32.050000000000004, 33.39883176, 35.58245576, 35.68406376, 35.642447759999996, 35.52124776, 37.76607976, 34.56164776, 34.500439760000006, 35.52124776, 35.52124776, 36.68366376, 35.68406376, 35.56164776, 35.66325576, 35.62285576, 34.68406376, 27.05, 35.643663759999995, 36.70487176, 37.05, 35.70487176, 35.05, 36.72446376, 34.52003176, 35.72446376, 36.68406376, 36.68366376, 36.70487176, 36.70487176, 36.72446376, 35.58245576, 35.58245576, 35.642447759999996, 36.78607976, 37.76607976, 34.43923176, 36.72487176, 35.05, 37.76607976, 36.80647976, 35.643663759999995, 35.58245576, 37.76607976, 33.62285576, 36.72446376, 35.52124776, 37.827287760000004, 36.70487176, 36.643663759999995, 33.37802376, 34.60204776, 35.54124776, 36.76607976, 35.05, 35.58245576, 35.54124776, 35.56164776, 34.05, 36.72446376, 35.60204776, 34.58123976, 36.05, 37.76607976, 36.643663759999995, 33.45923176, 35.05, 35.52124776, 36.70487176, 34.56164776, 36.643663759999995, 35.66325576, 37.05, 35.66325576, 37.827287760000004, 35.60245576, 36.72446376, 33.35721576, 37.05, 36.70487176, 35.703655760000004, 35.60204776, 35.52124776, 33.291388000000005, 33.41842376, 35.56164776, 34.05, 35.62285576, 34.41883176, 36.68406376, 35.68406376, 32.60204776, 35.60245576, 37.05, 36.643663759999995, 36.76607976, 35.56164776, 35.58245576, 34.540839760000004, 35.56164776, 35.05, 36.643663759999995, 36.70487176, 33.39883176, 37.05, 35.66366376, 32.291388000000005, 35.56164776, 35.52124776, 37.827287760000004, 36.643663759999995, 35.62204776, 36.70487176, 36.72446376, 31.05, 36.68406376, 36.05, 35.52124776, 35.52124776, 36.643663759999995, 36.72487176, 36.76607976, 35.70406376, 35.05, 36.68406376, 37.827287760000004, 33.316815760000004, 36.70487176, 35.60245576, 35.66325576, 35.52124776, 35.52124776, 35.68406376, 35.56164776, 35.58245576, 36.76607976, 35.66366376, 35.56124776, 33.05, 35.64285576, 35.62285576, 36.643663759999995, 36.05, 35.78567176000001, 35.52124776, 37.78607976, 35.643663759999995, 36.70406376, 33.33681576, 36.643663759999995, 35.52124776, 35.62285576, 35.56164776, 34.05, 35.56164776, 36.72487176, 36.643663759999995, 36.643663759999995, 32.51881576, 35.52124776, 35.58245576, 35.58245576, 36.74527176000001, 36.05, 35.60204776, 35.56164776, 35.05, 36.70487176, 33.33762376, 37.76607976, 36.72446376, 34.52003976, 33.316815760000004, 35.643663759999995, 36.643663759999995, 35.58245576, 32.35721576, 35.52124776, 34.05, 35.52124776, 35.643663759999995, 36.68406376, 36.05, 36.643663759999995, 35.60204776, 34.39883176, 35.58245576, 36.643663759999995, 35.05, 35.60245576, 36.74527176000001, 34.05, 35.05, 36.70487176, 33.35721576, 35.643663759999995, 36.70487176, 36.78567176000001, 35.72446376, 35.52124776, 34.39883176, 34.39883176, 35.72324776, 36.643663759999995, 35.56164776, 36.68406376, 33.39883176, 35.643663759999995, 36.643663759999995, 34.05, 35.52124776, 35.66325576, 36.05, 35.52124776, 35.58245576, 35.56164776, 35.58245576, 35.05, 32.270988, 36.76607976, 36.68406376, 37.78607976, 35.66325576, 36.643663759999995, 31.33640776, 35.703655760000004, 36.643663759999995, 35.52124776, 36.68406376, 36.05, 35.58245576, 36.643663759999995, 33.291388000000005, 35.56164776, 36.643663759999995, 35.76607976, 34.05, 35.52124776, 34.480039760000004, 36.72487176, 36.68406376, 33.35762376, 35.52124776, 36.70487176, 36.68406376, 34.540839760000004, 34.500439760000006, 36.70487176, 37.827287760000004, 32.33762376, 32.53840776, 36.76607976, 36.76607976, 35.56164776, 35.60245576, 34.479631760000004, 34.500439760000006, 32.05, 33.58245576, 36.643663759999995, 35.54124776, 33.43923176, 36.68406376, 34.62285576, 36.72487176, 37.76607976, 35.62285576, 33.39802376, 34.70487176, 35.68406376, 35.52124776, 35.62285576, 32.39761576, 33.05, 35.56164776, 31.291388000000005, 35.68406376, 32.05, 36.76607976, 35.56164776, 35.05, 35.66325576, 38.05, 36.643663759999995, 35.60204776, 35.72446376, 35.62285576, 35.56124776, 36.70487176, 36.643663759999995, 34.43923176, 35.66325576, 32.39802376, 35.52124776, 31.31681576, 36.643663759999995, 35.54124776, 35.54124776, 35.642447759999996, 38.05, 36.643663759999995, 35.643663759999995, 36.643663759999995, 35.56164776, 33.05, 31.050000000000004, 36.70487176, 37.80647976, 37.76607976, 35.58245576, 35.56164776, 36.80647976, 35.58245576, 35.62164776, 35.56164776, 36.05, 36.66366376, 36.70487176, 35.62285576, 35.56164776, 36.643663759999995, 35.66366376, 37.78607976, 35.05, 36.68406376, 32.33681576, 35.56164776, 32.05, 35.643663759999995, 34.49923176, 31.33762376, 35.66366376, 36.643663759999995, 35.62285576, 35.52124776, 35.68406376, 34.66204776, 35.58245576, 37.78607976, 34.46003976, 35.62285576, 31.43923176, 35.62285576, 36.68406376, 33.29641576, 34.46003976, 36.05, 35.52124776, 37.05, 34.49963176, 34.70487176, 35.56124776, 35.56164776, 37.78607976, 35.60204776, 36.70487176, 36.05, 32.05, 35.52124776, 33.643663759999995, 35.56164776, 37.05, 36.643663759999995, 37.76607976, 35.58245576, 35.54124776, 35.52124776, 35.56164776, 35.52124776, 35.54124776, 37.76607976, 34.581647759999996, 35.827287760000004, 35.62285576, 35.70487176, 34.52043976, 37.76607976, 35.54124776, 36.70487176, 35.52124776, 36.70487176, 34.39883176, 32.35721576, 36.78567176000001, 32.270988, 33.33762376, 36.76607976, 35.62285576, 35.05, 37.76607976, 35.52124776, 34.540839760000004, 36.68406376, 34.43923176, 36.66366376, 37.05, 31.291388000000005, 34.480039760000004, 35.60204776, 36.68406376, 36.05, 36.70487176, 36.70487176, 35.58245576, 35.56164776, 35.54124776, 35.643663759999995, 34.39883176, 35.60204776, 35.52124776, 35.62285576, 35.58245576, 35.643663759999995, 35.60204776, 35.62285576, 35.58245576, 35.62285576, 36.66366376, 35.58245576, 35.66325576, 33.316815760000004, 36.643663759999995, 32.210588, 35.72487176, 34.58245576, 34.60083176, 35.56164776, 35.643663759999995, 35.52124776, 35.56164776, 35.52124776, 35.52124776, 35.56164776, 35.52124776, 35.58245576, 35.70487176, 34.05, 36.827287760000004, 35.56164776, 34.39883176, 36.72487176, 35.56164776, 35.827287760000004, 35.60204776, 33.05, 33.05, 34.70487176, 35.05, 36.643663759999995, 36.05, 34.46003976, 35.52124776, 35.68284776, 32.291388000000005, 34.52124776, 35.643663759999995, 36.70487176, 35.52124776, 35.56164776, 36.70406376, 36.05, 35.56164776, 35.54124776, 35.58245576, 35.52124776, 36.643663759999995, 36.643663759999995, 35.58245576, 35.642447759999996, 35.60204776, 36.643663759999995, 35.58245576, 35.52124776, 37.827287760000004, 36.643663759999995, 36.68406376, 35.66325576, 34.703655760000004, 35.52124776, 35.66325576, 34.43923176, 36.68406376, 35.56164776, 34.39883176, 36.643663759999995, 35.62285576, 36.70487176, 35.58245576, 34.39883176, 36.66366376, 35.56164776, 36.68406376, 35.60204776, 35.56164776, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.56164776, 35.58245576, 36.643663759999995, 36.70487176, 35.52124776, 37.76607976, 37.827287760000004, 35.58245576, 33.500439760000006, 36.643663759999995, 35.58245576, 35.62285576, 35.74405576, 31.33762376, 34.43923176, 36.643663759999995, 36.643663759999995, 35.56164776, 35.72446376, 35.52124776, 35.62285576, 35.76607976, 34.56164776, 36.70487176, 35.54124776, 35.05, 35.60245576, 36.66366376, 35.66325576, 31.35721576, 35.52124776, 34.68406376, 34.56164776, 35.52124776, 34.05, 36.05, 36.70487176, 36.643663759999995, 36.643663759999995, 34.60204776, 36.05, 35.52124776, 36.70487176, 35.62285576, 35.56164776, 35.56164776, 36.70487176, 36.68406376, 35.62285576, 35.60204776, 35.58245576, 34.43923176, 36.643663759999995, 36.66366376, 36.68406376, 33.76607976, 36.70487176, 36.643663759999995, 35.54124776, 36.68406376, 36.72446376, 35.52124776, 33.35721576, 37.05, 32.43923176, 36.643663759999995, 34.56043176, 34.60204776, 36.643663759999995, 33.39883176, 35.54124776, 36.68406376, 36.80647976, 36.643663759999995, 36.70487176, 35.703655760000004, 36.72487176, 36.643663759999995, 37.827287760000004, 35.58245576, 35.62285576, 33.39883176, 34.540839760000004, 35.52124776, 33.35721576, 36.643663759999995, 36.68406376, 35.643663759999995, 35.68284776, 35.56164776, 33.33762376, 33.05, 32.05, 36.68406376, 35.58245576, 35.52124776, 37.827287760000004, 35.58245576, 35.52124776, 36.643663759999995, 34.500439760000006, 35.56164776, 35.66366376, 36.68406376, 33.39883176, 35.62285576, 35.58245576, 36.05, 33.39681576, 35.58245576, 34.05, 36.70487176, 35.58245576, 35.78567176000001, 35.62285576, 35.58245576, 35.58245576, 33.37802376, 35.05, 35.52124776, 35.52124776, 36.05, 33.29641576, 37.76607976, 35.54124776, 35.56164776, 35.58245576, 35.52124776, 34.500439760000006, 35.66325576, 36.76607976, 36.68406376, 36.643663759999995, 35.56164776, 33.31641576, 36.643663759999995, 35.70487176, 35.643663759999995, 35.05, 36.05, 35.52124776, 35.58245576], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1527330105014619, "mean_inference_ms": 0.624370820944615, "mean_action_processing_ms": 0.04818254067439296, "mean_env_wait_ms": 0.05324919827065356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 44000, "agent_timesteps_total": 44000, "timers": {"sample_time_ms": 1810.567, "sample_throughput": 2209.252, "load_time_ms": 1.108, "load_throughput": 3609400.628, "learn_time_ms": 2421.116, "learn_throughput": 1652.131, "update_time_ms": 1.616}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.8252362608909607, "policy_loss": -0.061077725142240524, "vf_loss": 0.8798786997795105, "vf_explained_var": 0.9925084710121155, "kl": 0.009533836506307125, "entropy": 0.9903944134712219, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 44000, "num_agent_steps_sampled": 44000, "num_steps_trained": 44000, "num_agent_steps_trained": 44000}, "done": false, "episodes_total": 8800, "training_iteration": 11, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-42", "timestamp": 1628628762, "time_this_iter_s": 6.535716772079468, "time_total_s": 46.630186319351196, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 46.630186319351196, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 39.455555555555556, "ram_util_percent": 71.36666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 27.05, "episode_reward_mean": 35.7148136633, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.643663759999995, 36.643663759999995, 37.76607976, 35.58245576, 36.643663759999995, 36.68406376, 31.050000000000004, 33.05, 36.643663759999995, 34.39883176, 34.05, 37.76607976, 37.78607976, 36.643663759999995, 35.642447759999996, 36.643663759999995, 33.05, 36.643663759999995, 32.31641576, 35.66325576, 36.68406376, 33.43923176, 36.68406376, 35.52124776, 37.76607976, 34.05, 36.74527176000001, 35.581647759999996, 36.70487176, 36.643663759999995, 35.60204776, 35.60204776, 36.68406376, 36.68406376, 33.39883176, 36.643663759999995, 36.643663759999995, 35.52124776, 35.58245576, 35.52124776, 36.643663759999995, 35.62285576, 33.35721576, 36.643663759999995, 34.46003976, 36.643663759999995, 35.60245576, 37.05, 33.45882376, 36.643663759999995, 33.41842376, 35.68406376, 35.58245576, 36.643663759999995, 35.52124776, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.827287760000004, 35.52124776, 36.70406376, 35.60204776, 35.58245576, 38.05, 36.68406376, 35.58245576, 38.05, 32.05, 36.643663759999995, 36.70487176, 35.56164776, 35.05, 36.70487176, 35.64204776, 35.56164776, 36.68406376, 35.56164776, 36.70487176, 36.70487176, 34.46003976, 34.52124776, 36.72487176, 36.643663759999995, 36.643663759999995, 34.56083976, 36.68406376, 35.66325576, 35.643663759999995, 36.72446376, 35.68284776, 36.643663759999995, 35.58245576, 36.05, 36.643663759999995, 33.29641576, 34.643663759999995, 27.05, 35.56164776, 35.05, 35.52124776, 36.72446376, 36.05, 31.049999999999997, 33.37802376, 36.70487176, 34.39883176, 36.76607976, 35.52124776, 35.60204776, 36.76607976, 35.58245576, 30.049999999999997, 31.050000000000004, 36.643663759999995, 36.643663759999995, 36.72446376, 36.643663759999995, 34.54003176, 35.52124776, 35.52124776, 36.74527176000001, 36.643663759999995, 37.827287760000004, 35.64285576, 36.66366376, 35.68406376, 34.05, 33.05, 36.70487176, 36.643663759999995, 35.54124776, 36.643663759999995, 35.56164776, 35.643663759999995, 36.643663759999995, 35.54124776, 35.643663759999995, 36.76607976, 36.643663759999995, 35.52124776, 36.70487176, 35.52124776, 35.58245576, 35.58245576, 37.78607976, 35.56164776, 35.52124776, 36.72446376, 35.52124776, 35.62285576, 32.05, 36.68406376, 34.46003976, 36.643663759999995, 35.60204776, 35.68244776, 35.05, 35.76607976, 36.76607976, 36.643663759999995, 36.70487176, 35.52124776, 37.05, 36.68406376, 36.05, 31.189788, 31.210188000000002, 35.60204776, 36.643663759999995, 33.35721576, 36.827287760000004, 36.643663759999995, 35.05, 36.76607976, 33.05, 36.643663759999995, 36.68406376, 36.74527176000001, 35.60204776, 35.52124776, 36.643663759999995, 37.827287760000004, 35.76607976, 36.643663759999995, 36.76607976, 36.643663759999995, 31.210188000000002, 35.68284776, 34.68284776, 36.643663759999995, 34.500439760000006, 35.60204776, 35.56164776, 34.46003976, 36.643663759999995, 35.58245576, 35.70487176, 36.05, 36.76607976, 32.05, 37.76607976, 37.76607976, 36.643663759999995, 32.316815760000004, 36.74527176000001, 36.643663759999995, 34.43923176, 36.643663759999995, 35.05, 36.70406376, 36.643663759999995, 36.643663759999995, 33.33762376, 36.70487176, 35.52124776, 35.643663759999995, 34.39883176, 34.66325576, 35.60204776, 36.76607976, 36.70487176, 36.643663759999995, 35.60245576, 36.76607976, 35.60204776, 35.56164776, 36.643663759999995, 35.05, 36.643663759999995, 33.05, 36.643663759999995, 35.52124776, 36.643663759999995, 34.52124776, 35.70487176, 36.68406376, 36.68406376, 37.76607976, 35.643663759999995, 35.66325576, 36.72487176, 36.05, 35.52124776, 36.05, 36.643663759999995, 35.52124776, 37.827287760000004, 36.70487176, 35.52124776, 35.52124776, 35.62285576, 35.62285576, 35.76607976, 37.05, 36.70487176, 35.56164776, 35.56164776, 35.62164776, 35.62285576, 35.643663759999995, 36.66366376, 34.05, 35.643663759999995, 34.500439760000006, 37.78607976, 35.56164776, 36.70487176, 34.46003976, 34.56164776, 36.643663759999995, 34.05, 35.58245576, 34.60204776, 36.643663759999995, 35.56164776, 34.500439760000006, 36.643663759999995, 34.54124776, 35.62285576, 36.70487176, 36.70487176, 36.643663759999995, 32.316815760000004, 36.76486376, 37.76607976, 35.76607976, 34.46003976, 33.05, 35.60204776, 36.643663759999995, 31.296007760000002, 35.642447759999996, 33.33762376, 34.39883176, 36.643663759999995, 33.05, 33.05, 36.643663759999995, 35.52124776, 36.643663759999995, 35.62285576, 35.56164776, 35.05, 36.643663759999995, 35.643663759999995, 36.643663759999995, 36.70487176, 35.05, 36.643663759999995, 35.05, 36.74527176000001, 38.05, 30.050000000000004, 36.643663759999995, 36.05, 36.643663759999995, 35.62204776, 35.70487176, 35.60204776, 35.52124776, 35.58245576, 35.56164776, 37.76607976, 36.643663759999995, 36.643663759999995, 36.05, 35.52124776, 36.643663759999995, 34.642447759999996, 36.643663759999995, 35.58245576, 35.52124776, 35.62285576, 36.643663759999995, 36.68406376, 36.70487176, 36.74527176000001, 36.827287760000004, 38.05, 33.37802376, 35.56164776, 36.72446376, 35.643663759999995, 36.643663759999995, 36.70487176, 34.43923176, 35.52124776, 35.56164776, 32.05, 33.479631760000004, 36.05, 35.52124776, 36.643663759999995, 35.62285576, 35.52124776, 36.68406376, 35.62285576, 35.58245576, 36.70487176, 37.76607976, 35.52124776, 35.52124776, 33.05, 36.68406376, 35.52124776, 36.72487176, 36.68406376, 37.76607976, 35.56164776, 35.60204776, 36.643663759999995, 35.581647759999996, 38.05, 36.643663759999995, 34.540839760000004, 36.643663759999995, 36.643663759999995, 35.58245576, 36.70487176, 36.74527176000001, 34.43923176, 34.41883176, 36.70487176, 36.68406376, 36.643663759999995, 35.56164776, 35.52124776, 32.315599760000005, 36.05, 37.80647976, 35.74527176000001, 34.52124776, 36.05, 35.60204776, 35.60204776, 35.52124776, 36.76607976, 36.827287760000004, 35.62285576, 36.643663759999995, 36.76486376, 35.62204776, 35.56164776, 35.58245576, 35.62285576, 35.56164776, 36.70487176, 35.52124776, 34.52124776, 36.68406376, 35.827287760000004, 36.643663759999995, 35.52124776, 35.52124776, 35.58245576, 35.52124776, 36.643663759999995, 35.58245576, 33.33762376, 32.33640776, 35.05, 37.05, 36.68406376, 36.643663759999995, 34.56083976, 34.479631760000004, 35.60204776, 35.52124776, 34.46003976, 36.76607976, 35.56164776, 36.76607976, 33.41842376, 36.68406376, 38.05, 35.58245576, 36.70487176, 36.76607976, 34.52124776, 36.66366376, 35.60204776, 35.52124776, 32.25058800000001, 35.56164776, 35.643663759999995, 36.70487176, 35.52124776, 37.76607976, 33.35721576, 34.52003176, 37.76607976, 35.52124776, 35.643663759999995, 35.62285576, 32.05, 35.58245576, 35.52124776, 36.643663759999995, 34.43923176, 35.05, 36.76607976, 35.52124776, 37.827287760000004, 36.68406376, 34.46003976, 36.68366376, 37.76607976, 35.58245576, 36.70487176, 35.60204776, 36.72446376, 31.37802376, 34.540839760000004, 34.52124776, 36.643663759999995, 36.827287760000004, 37.05, 37.05, 34.479631760000004, 36.05, 36.643663759999995, 34.05, 35.52124776, 37.76607976, 34.05, 35.52124776, 37.827287760000004, 35.52124776, 36.68406376, 36.05, 36.70406376, 36.643663759999995, 36.05, 35.643663759999995, 36.70487176, 33.581647759999996, 35.642447759999996, 35.56124776, 36.05, 38.05, 36.68406376, 36.70487176, 36.68366376, 36.70487176, 36.643663759999995, 36.643663759999995, 35.58245576, 36.643663759999995, 35.52124776, 33.35721576, 34.52124776, 37.827287760000004, 30.049999999999997, 35.68406376, 35.58245576, 35.581647759999996, 36.643663759999995, 36.72446376, 34.56164776, 36.643663759999995, 33.05, 35.60245576, 35.76607976, 35.643663759999995, 35.68284776, 32.33762376, 36.76607976, 35.52124776, 37.76607976, 35.54124776, 33.291388000000005, 35.52124776, 36.643663759999995, 36.76607976, 35.581647759999996, 33.05, 35.76607976, 36.70487176, 36.05, 34.500439760000006, 36.70487176, 35.56164776, 38.05, 36.643663759999995, 35.52124776, 35.62285576, 35.52124776, 35.52124776, 35.60204776, 36.643663759999995, 35.66325576, 35.58245576, 32.25098800000001, 35.52124776, 36.70487176, 35.56164776, 36.643663759999995, 35.58245576, 35.52124776, 35.68284776, 35.56164776, 36.78567176000001, 37.76607976, 36.70487176, 37.76607976, 37.05, 36.68406376, 33.316815760000004, 35.60204776, 35.52124776, 35.643663759999995, 35.56164776, 37.76607976, 36.643663759999995, 35.58245576, 34.500439760000006, 36.643663759999995, 35.76607976, 35.62285576, 33.05, 35.58245576, 36.643663759999995, 32.05, 35.66325576, 37.76607976, 35.52124776, 35.642447759999996, 35.56164776, 33.05, 36.70487176, 36.643663759999995, 35.56164776, 34.479631760000004, 35.58245576, 36.80647976, 33.479631760000004, 32.68406376, 34.46003976, 36.68406376, 35.80647976, 35.703255760000005, 36.70487176, 36.05, 35.54124776, 35.56164776, 28.049999999999997, 35.58245576, 36.643663759999995, 36.68406376, 35.05, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 35.52124776, 35.56164776, 35.58245576, 32.270988, 35.58245576, 36.643663759999995, 36.643663759999995, 35.643663759999995, 36.70487176, 35.52124776, 35.58245576, 35.643663759999995, 36.05, 35.56164776, 35.58245576, 35.643663759999995, 36.643663759999995, 35.58245576, 35.70487176, 34.46003976, 35.68406376, 36.70487176, 36.643663759999995, 35.66325576, 35.58245576, 36.643663759999995, 35.62285576, 35.643663759999995, 35.58245576, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.66325576, 35.52124776, 36.70487176, 36.70487176, 35.62285576, 36.68406376, 35.643663759999995, 36.76607976, 37.827287760000004, 33.39883176, 36.05, 38.05, 36.05, 35.58245576, 35.54124776, 35.54124776, 33.05, 35.68406376, 36.643663759999995, 35.60164776, 36.68406376, 36.643663759999995, 35.56164776, 32.05, 35.52124776, 33.43923176, 36.643663759999995, 36.643663759999995, 35.68406376, 35.581647759999996, 34.43923176, 36.05, 35.58245576, 36.643663759999995, 34.05, 35.642447759999996, 35.70487176, 33.500439760000006, 35.56164776, 36.05, 35.62245576, 36.72446376, 35.52124776, 35.60204776, 32.291388000000005, 31.33762376, 36.68406376, 35.60204776, 35.58245576, 36.70487176, 36.66366376, 33.291388000000005, 34.500439760000006, 35.52124776, 36.643663759999995, 37.76607976, 36.05, 33.050000000000004, 35.54124776, 35.68406376, 36.643663759999995, 36.68406376, 37.05, 36.643663759999995, 35.60204776, 35.60204776, 37.76607976, 35.66325576, 33.316815760000004, 35.52124776, 35.52124776, 35.62285576, 36.643663759999995, 36.643663759999995, 35.56164776, 36.70487176, 35.62285576, 36.765271760000005, 37.05, 35.52124776, 35.52124776, 36.70487176, 35.52124776, 35.68406376, 35.52124776, 35.60204776, 35.68406376, 35.74527176000001, 34.39883176, 37.05, 36.72487176, 35.52124776, 35.56164776, 35.60204776, 29.049999999999997, 36.78607976, 35.05, 34.05, 35.60204776, 31.541247759999997, 34.54124776, 36.70406376, 35.05, 36.05, 34.500439760000006, 36.643663759999995, 37.827287760000004, 38.05, 35.58245576, 36.643663759999995, 35.60204776, 34.70487176, 36.76607976, 37.76607976, 37.827287760000004, 36.643663759999995, 34.479631760000004, 35.642447759999996, 36.643663759999995, 35.52124776, 32.270988, 34.43923176, 36.643663759999995, 35.62285576, 35.62285576, 37.76607976, 36.643663759999995, 35.643663759999995, 35.62285576, 37.78607976, 35.62285576, 36.66366376, 35.52124776, 36.76607976, 35.58245576, 36.643663759999995, 37.827287760000004, 36.78567176000001, 35.78607976, 35.52124776, 35.62285576, 37.76607976, 36.643663759999995, 36.68406376, 35.58245576, 35.60204776, 35.58245576, 35.05, 35.56164776, 31.050000000000004, 36.74446376, 34.05, 36.68406376], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15123352587836458, "mean_inference_ms": 0.6179463877776659, "mean_action_processing_ms": 0.0477259439516304, "mean_env_wait_ms": 0.05266949621956874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 48000, "agent_timesteps_total": 48000, "timers": {"sample_time_ms": 1814.124, "sample_throughput": 2204.921, "load_time_ms": 1.105, "load_throughput": 3620773.481, "learn_time_ms": 2427.9, "learn_throughput": 1647.514, "update_time_ms": 1.567}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1.1355646848678589, "policy_loss": -0.053539637476205826, "vf_loss": 1.181974172592163, "vf_explained_var": 0.9899097084999084, "kl": 0.010562936775386333, "entropy": 0.9011576175689697, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 48000, "num_agent_steps_sampled": 48000, "num_steps_trained": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 9600, "training_iteration": 12, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-46", "timestamp": 1628628766, "time_this_iter_s": 3.698706865310669, "time_total_s": 50.328893184661865, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 50.328893184661865, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 37.45, "ram_util_percent": 71.24999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 28.05, "episode_reward_mean": 36.148876382599994, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.643663759999995, 35.58245576, 36.70487176, 36.643663759999995, 35.643663759999995, 35.52124776, 36.05, 34.05, 36.68406376, 36.643663759999995, 36.70487176, 35.66325576, 35.58245576, 36.68406376, 37.76607976, 35.56164776, 36.643663759999995, 36.70406376, 36.70487176, 34.500439760000006, 36.66366376, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 35.56164776, 35.52124776, 36.643663759999995, 35.60204776, 36.643663759999995, 36.72446376, 36.643663759999995, 35.52124776, 35.56164776, 36.66366376, 36.643663759999995, 36.643663759999995, 35.52124776, 35.56164776, 36.643663759999995, 34.52124776, 35.52124776, 37.05, 38.05, 36.643663759999995, 35.60204776, 37.76607976, 36.05, 35.58245576, 36.643663759999995, 34.46003976, 35.52124776, 35.643663759999995, 36.78567176000001, 36.643663759999995, 36.05, 36.643663759999995, 37.05, 36.643663759999995, 34.643663759999995, 35.52124776, 36.72446376, 36.70487176, 36.643663759999995, 35.56164776, 31.210188000000002, 36.68406376, 36.643663759999995, 35.581647759999996, 35.56164776, 36.70487176, 35.60204776, 35.52124776, 36.643663759999995, 36.76607976, 35.62285576, 35.56164776, 35.66325576, 35.68406376, 36.643663759999995, 38.05, 38.05, 36.827287760000004, 36.78607976, 33.05, 36.70487176, 36.643663759999995, 35.60204776, 36.68406376, 35.642447759999996, 35.58245576, 35.52124776, 37.05, 35.56164776, 35.62285576, 37.76607976, 37.76607976, 35.56164776, 36.643663759999995, 36.74527176000001, 35.05, 36.70487176, 36.827287760000004, 37.76607976, 33.291388000000005, 36.643663759999995, 36.643663759999995, 36.70487176, 36.72487176, 36.643663759999995, 35.68406376, 37.76607976, 35.66325576, 36.76607976, 37.76607976, 35.52124776, 36.70487176, 35.60204776, 35.60204776, 35.60204776, 35.68325576, 34.43923176, 36.74527176000001, 34.500439760000006, 35.54124776, 35.56164776, 35.643663759999995, 35.52124776, 35.62285576, 36.74487176, 36.78607976, 35.56164776, 35.52124776, 36.68406376, 36.68406376, 35.52124776, 38.05, 35.58245576, 36.643663759999995, 38.05, 36.70487176, 36.643663759999995, 35.80647976, 36.643663759999995, 36.643663759999995, 37.05, 35.643663759999995, 36.643663759999995, 37.827287760000004, 35.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 35.62285576, 37.05, 36.76607976, 36.68406376, 35.60204776, 37.76607976, 37.76607976, 33.37802376, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.05, 36.72446376, 35.60204776, 35.56164776, 37.827287760000004, 36.68406376, 36.643663759999995, 35.58245576, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 35.54124776, 36.643663759999995, 35.52124776, 36.68406376, 34.05, 33.316815760000004, 35.60204776, 35.56164776, 36.76607976, 34.05, 37.76607976, 33.291388000000005, 35.05, 36.68406376, 36.70487176, 36.74527176000001, 37.827287760000004, 36.70487176, 36.68406376, 35.64285576, 35.58245576, 35.58245576, 34.05, 35.52124776, 36.643663759999995, 37.827287760000004, 36.68406376, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 35.52124776, 35.58245576, 36.70487176, 36.70487176, 35.56164776, 35.05, 35.58245576, 36.05, 36.643663759999995, 37.76607976, 36.70487176, 37.05, 35.52124776, 35.05, 36.70487176, 34.43923176, 36.70487176, 36.70487176, 36.05, 35.60204776, 35.52124776, 35.643663759999995, 37.80647976, 35.52124776, 36.643663759999995, 35.643663759999995, 33.66366376, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 35.05, 35.70487176, 36.76486376, 36.68406376, 36.70487176, 31.049999999999997, 36.643663759999995, 35.56164776, 37.76607976, 35.70487176, 36.74527176000001, 36.643663759999995, 37.05, 36.643663759999995, 35.56164776, 35.56164776, 35.62285576, 36.765271760000005, 37.76607976, 36.72487176, 37.05, 36.70487176, 35.58245576, 36.68406376, 35.58245576, 36.643663759999995, 36.66366376, 36.76607976, 35.52124776, 37.76607976, 36.68406376, 35.62285576, 36.643663759999995, 37.76607976, 36.643663759999995, 36.76607976, 32.41883176, 36.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.80647976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 35.52124776, 37.80647976, 35.64285576, 32.05, 35.56164776, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 35.52124776, 35.58245576, 35.52124776, 33.479631760000004, 32.29600776, 36.643663759999995, 36.68406376, 35.62285576, 37.05, 36.05, 35.52124776, 33.66325576, 33.35721576, 35.56164776, 36.72487176, 36.68406376, 36.70487176, 37.827287760000004, 36.76607976, 36.74527176000001, 35.703655760000004, 37.76607976, 36.643663759999995, 36.68406376, 36.70487176, 36.68406376, 36.643663759999995, 36.68406376, 34.05, 36.68406376, 37.76607976, 36.643663759999995, 36.70487176, 34.643663759999995, 36.68406376, 36.70487176, 36.827287760000004, 35.52124776, 36.643663759999995, 36.05, 35.56164776, 36.643663759999995, 34.581647759999996, 36.643663759999995, 37.80647976, 35.56164776, 36.643663759999995, 36.643663759999995, 30.05, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 35.62285576, 37.80647976, 35.52124776, 36.643663759999995, 36.78607976, 35.52124776, 36.70487176, 36.68406376, 36.643663759999995, 37.05, 34.39883176, 36.643663759999995, 35.827287760000004, 37.76607976, 35.581647759999996, 35.58245576, 36.72487176, 34.46003976, 34.62163976, 36.643663759999995, 36.66366376, 36.643663759999995, 36.643663759999995, 32.270988, 34.662039760000006, 36.68406376, 36.78567176000001, 35.52124776, 36.643663759999995, 36.643663759999995, 35.56164776, 36.70487176, 35.58245576, 37.827287760000004, 36.643663759999995, 35.52124776, 35.62285576, 34.500439760000006, 35.05, 36.66366376, 36.70487176, 36.74527176000001, 36.72446376, 37.76607976, 36.76607976, 35.52124776, 35.56164776, 36.643663759999995, 36.70487176, 33.316815760000004, 35.58245576, 36.66366376, 36.74527176000001, 35.66325576, 35.05, 35.52124776, 36.643663759999995, 35.62285576, 35.05, 36.05, 32.05, 37.05, 35.52124776, 36.643663759999995, 35.56164776, 35.56164776, 35.68406376, 36.643663759999995, 35.76607976, 36.78567176000001, 36.643663759999995, 36.643663759999995, 36.68406376, 37.76607976, 37.05, 36.643663759999995, 36.74527176000001, 36.74527176000001, 35.52124776, 33.43923176, 33.37802376, 35.60204776, 35.68406376, 35.56164776, 35.52124776, 34.05, 36.70487176, 36.643663759999995, 35.68406376, 35.60204776, 35.58245576, 36.643663759999995, 37.76607976, 35.68406376, 35.643663759999995, 35.56164776, 37.05, 36.643663759999995, 36.70487176, 36.68406376, 36.76607976, 31.050000000000004, 35.56164776, 36.70487176, 35.76607976, 32.316815760000004, 35.581647759999996, 37.76607976, 37.76607976, 37.05, 36.70487176, 36.643663759999995, 37.05, 36.72446376, 35.66325576, 37.76607976, 35.56164776, 37.80647976, 35.56164776, 32.050000000000004, 34.05, 35.62285576, 36.643663759999995, 36.72487176, 36.643663759999995, 35.62285576, 36.643663759999995, 36.68406376, 35.56164776, 36.643663759999995, 35.58245576, 36.76607976, 36.643663759999995, 36.72446376, 35.703655760000004, 36.765271760000005, 35.58245576, 36.643663759999995, 36.70487176, 38.05, 37.76607976, 34.479631760000004, 37.78607976, 37.76607976, 35.64285576, 36.643663759999995, 35.52124776, 36.68406376, 37.76607976, 36.74446376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.66366376, 32.35721576, 36.72446376, 36.643663759999995, 33.05, 37.05, 36.643663759999995, 35.58245576, 35.58245576, 35.05, 32.46003976, 35.643663759999995, 35.643663759999995, 35.643663759999995, 36.74527176000001, 38.05, 35.56124776, 36.72446376, 35.643663759999995, 36.643663759999995, 36.643663759999995, 37.05, 35.76607976, 37.76607976, 36.05, 36.68406376, 34.56043176, 38.05, 33.37802376, 36.68406376, 36.68406376, 36.68406376, 36.643663759999995, 33.37802376, 36.70487176, 35.56164776, 35.52124776, 35.66325576, 35.643663759999995, 37.76607976, 35.52124776, 35.54124776, 35.56164776, 34.540839760000004, 36.643663759999995, 36.70487176, 35.56164776, 38.05, 35.60204776, 36.643663759999995, 36.68406376, 35.58245576, 34.46003976, 36.70487176, 32.05, 36.68406376, 34.43923176, 34.52124776, 36.68406376, 33.37802376, 36.643663759999995, 36.643663759999995, 37.76607976, 35.60245576, 35.52124776, 36.643663759999995, 35.05, 36.643663759999995, 35.52124776, 36.76607976, 35.56164776, 36.76607976, 36.05, 35.60204776, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.74527176000001, 36.643663759999995, 37.76607976, 37.827287760000004, 37.05, 36.70487176, 36.68406376, 35.581647759999996, 33.316815760000004, 37.827287760000004, 35.62285576, 35.58245576, 34.62123976, 35.60204776, 35.60204776, 35.52124776, 33.05, 35.58245576, 36.643663759999995, 36.643663759999995, 36.76607976, 36.70487176, 36.643663759999995, 35.60245576, 36.68406376, 36.643663759999995, 34.05, 36.70487176, 28.05, 33.39883176, 37.80647976, 36.05, 35.58245576, 38.05, 36.643663759999995, 35.66325576, 36.643663759999995, 35.80647976, 31.050000000000004, 35.56164776, 37.76607976, 35.68406376, 36.70487176, 36.643663759999995, 34.70487176, 36.66366376, 38.05, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 33.41842376, 34.540839760000004, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 35.58245576, 33.540839760000004, 35.56164776, 36.72446376, 35.52124776, 30.050000000000004, 36.68406376, 36.05, 34.479631760000004, 36.643663759999995, 35.62285576, 36.05, 37.76607976, 35.52124776, 36.643663759999995, 35.52124776, 36.66366376, 35.56164776, 35.56164776, 36.643663759999995, 37.76607976, 35.54124776, 37.76607976, 36.643663759999995, 35.62285576, 36.643663759999995, 35.62285576, 36.70487176, 36.68406376, 37.76607976, 38.05, 34.39883176, 36.05, 36.643663759999995, 35.62285576, 36.643663759999995, 37.76607976, 35.60204776, 36.66366376, 32.43801576, 36.643663759999995, 38.05, 33.827287760000004, 35.642447759999996, 36.05, 35.52124776, 36.66366376, 37.76607976, 34.500439760000006, 36.643663759999995, 35.52124776, 36.70487176, 36.68406376, 35.72446376, 34.56164776, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.05, 37.827287760000004, 35.60204776, 36.643663759999995, 35.60204776, 35.68406376, 37.76607976, 35.58245576, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.05, 35.62285576, 36.70487176, 36.643663759999995, 35.52124776, 37.80647976, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 36.70487176, 35.60204776, 34.39883176, 37.76607976, 35.58245576, 36.70487176, 36.643663759999995, 36.643663759999995, 36.05, 35.58245576, 36.643663759999995, 36.643663759999995, 36.68406376, 36.05, 36.827287760000004, 36.05, 35.52124776, 36.643663759999995, 37.05, 36.643663759999995, 36.70487176, 37.76607976, 35.78607976, 36.643663759999995, 31.05, 35.56164776, 36.05, 35.68406376, 35.56164776, 37.827287760000004, 36.643663759999995, 36.05, 36.70487176, 36.68406376, 36.68406376, 37.76607976, 36.70487176, 35.60204776, 36.76607976, 35.56164776, 32.270988, 34.500439760000006, 36.68406376, 36.74446376, 36.70487176, 36.74527176000001, 36.643663759999995, 36.643663759999995, 37.78607976, 36.643663759999995, 37.76607976, 36.643663759999995, 35.68406376, 36.643663759999995, 36.70487176, 37.76607976, 35.58245576, 36.72487176, 34.52124776, 35.56164776, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.66366376, 34.52124776, 37.76607976, 36.643663759999995, 35.56164776, 33.56164776, 35.74446376, 35.62285576, 36.70487176, 36.68406376, 36.643663759999995, 35.60245576, 35.581647759999996], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954081205564124, "mean_inference_ms": 0.6106999611736265, "mean_action_processing_ms": 0.04717291907564338, "mean_env_wait_ms": 0.05207559768156218, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 52000, "agent_timesteps_total": 52000, "timers": {"sample_time_ms": 1815.823, "sample_throughput": 2202.858, "load_time_ms": 1.096, "load_throughput": 3648886.666, "learn_time_ms": 2419.534, "learn_throughput": 1653.211, "update_time_ms": 1.542}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.7348232865333557, "policy_loss": -0.05653044953942299, "vf_loss": 0.7819394469261169, "vf_explained_var": 0.9933837652206421, "kl": 0.013946657069027424, "entropy": 0.7878205180168152, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 52000, "num_agent_steps_sampled": 52000, "num_steps_trained": 52000, "num_agent_steps_trained": 52000}, "done": false, "episodes_total": 10400, "training_iteration": 13, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-49", "timestamp": 1628628769, "time_this_iter_s": 3.570905923843384, "time_total_s": 53.89979910850525, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 53.89979910850525, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.88000000000001, "ram_util_percent": 71.32}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.050000000000004, "episode_reward_mean": 36.4346908896, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.643663759999995, 35.05, 36.70487176, 36.68366376, 36.643663759999995, 36.70406376, 36.76607976, 36.70487176, 33.62285576, 36.643663759999995, 37.827287760000004, 35.52124776, 37.76607976, 36.74527176000001, 35.62285576, 32.35599976, 36.05, 35.58245576, 36.643663759999995, 35.05, 36.05, 36.643663759999995, 37.80647976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70406376, 36.68406376, 35.52124776, 35.56164776, 36.643663759999995, 36.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 37.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 37.76607976, 38.05, 35.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.68406376, 37.78607976, 37.76607976, 31.050000000000004, 36.68406376, 36.68406376, 36.70487176, 36.72446376, 36.74527176000001, 36.05, 36.70487176, 36.643663759999995, 36.643663759999995, 34.43923176, 37.76607976, 38.05, 34.43923176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 35.643663759999995, 36.70487176, 38.05, 37.76607976, 36.827287760000004, 35.62285576, 36.643663759999995, 36.70487176, 35.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.05, 33.05, 37.05, 37.05, 36.643663759999995, 35.58245576, 36.643663759999995, 36.68406376, 35.58245576, 36.66366376, 35.52124776, 38.05, 36.68406376, 35.60245576, 36.643663759999995, 37.80647976, 37.05, 37.827287760000004, 36.68406376, 36.643663759999995, 36.70487176, 36.68406376, 36.68406376, 35.62285576, 35.62285576, 36.643663759999995, 33.41842376, 36.68406376, 36.68406376, 36.643663759999995, 36.70487176, 36.72487176, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 33.291388000000005, 34.46003976, 35.52124776, 36.05, 36.643663759999995, 36.643663759999995, 35.58245576, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.74527176000001, 37.827287760000004, 36.643663759999995, 36.70487176, 36.643663759999995, 37.05, 35.56164776, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 35.56164776, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.642447759999996, 37.827287760000004, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 36.66366376, 33.291388000000005, 36.643663759999995, 36.68406376, 35.68406376, 36.643663759999995, 38.05, 36.643663759999995, 37.05, 35.58245576, 38.05, 36.68406376, 36.05, 35.56164776, 36.70487176, 36.72446376, 37.76607976, 36.74527176000001, 37.827287760000004, 36.70487176, 37.76607976, 32.050000000000004, 37.05, 36.643663759999995, 37.827287760000004, 36.643663759999995, 35.52124776, 35.703655760000004, 36.70487176, 36.66366376, 35.74527176000001, 36.68406376, 36.643663759999995, 36.68406376, 35.56164776, 36.70487176, 36.643663759999995, 36.70487176, 32.35599976, 36.70487176, 36.70487176, 36.05, 36.643663759999995, 36.68406376, 36.68406376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.76486376, 36.643663759999995, 32.05, 36.68406376, 37.05, 35.52124776, 36.70487176, 37.76607976, 36.68406376, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.05, 36.72446376, 35.62285576, 36.70487176, 33.37802376, 36.643663759999995, 35.58245576, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.68406376, 36.72446376, 37.76607976, 36.80647976, 36.70487176, 33.45882376, 37.76607976, 36.643663759999995, 35.52124776, 35.58245576, 35.52124776, 38.05, 35.60204776, 35.52124776, 36.70487176, 34.500439760000006, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70406376, 36.70487176, 36.70406376, 36.643663759999995, 37.827287760000004, 36.68406376, 36.70487176, 37.827287760000004, 36.70487176, 36.70487176, 35.52124776, 35.56164776, 35.52124776, 36.72446376, 36.05, 36.643663759999995, 33.45882376, 36.70487176, 36.68406376, 36.70487176, 34.56164776, 36.76607976, 31.050000000000004, 35.58245576, 36.70487176, 35.58245576, 36.643663759999995, 35.52124776, 37.76607976, 36.643663759999995, 37.827287760000004, 33.35721576, 36.643663759999995, 36.76607976, 36.68406376, 37.76607976, 36.68406376, 36.68406376, 37.05, 36.05, 35.643663759999995, 36.76486376, 36.643663759999995, 36.72446376, 35.56164776, 36.70487176, 35.56164776, 35.56164776, 36.68406376, 35.52124776, 36.70406376, 36.643663759999995, 36.643663759999995, 36.70487176, 35.56164776, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70406376, 32.56164776, 36.72446376, 37.76607976, 36.643663759999995, 35.58245576, 37.76607976, 36.643663759999995, 36.643663759999995, 35.643663759999995, 36.76607976, 35.52124776, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 36.70487176, 36.643663759999995, 37.827287760000004, 35.52124776, 36.643663759999995, 37.76607976, 36.68406376, 35.62285576, 36.68406376, 36.643663759999995, 36.68406376, 34.05, 36.70487176, 37.76607976, 35.56164776, 36.643663759999995, 35.56164776, 36.643663759999995, 38.05, 35.60204776, 37.827287760000004, 37.76607976, 35.52124776, 37.827287760000004, 36.68406376, 36.72446376, 36.643663759999995, 37.76607976, 35.643663759999995, 36.643663759999995, 35.62285576, 35.58245576, 35.05, 36.70487176, 35.643663759999995, 36.68406376, 35.05, 36.643663759999995, 36.76607976, 36.70487176, 36.72446376, 37.827287760000004, 37.76607976, 36.70487176, 35.52124776, 37.76607976, 37.76607976, 37.76607976, 35.62285576, 36.68406376, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 37.05, 36.827287760000004, 35.56164776, 35.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 35.56164776, 37.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.68406376, 36.70487176, 36.643663759999995, 37.76607976, 36.05, 36.68406376, 36.74527176000001, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.68406376, 35.56164776, 35.60204776, 36.643663759999995, 36.643663759999995, 32.270988, 36.68406376, 36.643663759999995, 36.72446376, 35.52124776, 36.70487176, 36.05, 36.76486376, 36.643663759999995, 36.643663759999995, 35.58245576, 35.72324776, 36.80647976, 36.05, 35.56164776, 36.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 37.05, 36.643663759999995, 35.56164776, 36.643663759999995, 35.52124776, 34.39883176, 36.70487176, 36.643663759999995, 35.643663759999995, 35.52124776, 33.478415760000004, 36.643663759999995, 36.643663759999995, 36.70487176, 32.315599760000005, 36.68406376, 36.643663759999995, 35.52124776, 37.80647976, 37.80647976, 36.643663759999995, 36.68406376, 37.76607976, 36.643663759999995, 36.643663759999995, 35.58245576, 35.52124776, 36.72446376, 36.68406376, 37.05, 36.643663759999995, 36.643663759999995, 37.76607976, 36.72446376, 36.643663759999995, 36.643663759999995, 35.68406376, 37.76607976, 36.643663759999995, 36.68406376, 36.70487176, 34.52124776, 36.643663759999995, 36.643663759999995, 36.68406376, 37.76607976, 36.68406376, 36.70487176, 33.05, 36.643663759999995, 32.39761576, 35.58245576, 36.80647976, 33.56164776, 36.827287760000004, 36.05, 35.58245576, 36.643663759999995, 36.05, 36.643663759999995, 36.68406376, 36.643663759999995, 38.05, 37.80647976, 36.643663759999995, 35.52124776, 36.643663759999995, 36.72487176, 35.58245576, 36.643663759999995, 36.643663759999995, 33.41842376, 35.05, 36.70487176, 36.70487176, 35.52124776, 36.70487176, 36.70487176, 36.68406376, 36.68406376, 36.643663759999995, 36.70487176, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.66366376, 36.76607976, 35.60204776, 36.70487176, 36.72487176, 36.643663759999995, 36.72446376, 36.643663759999995, 35.703655760000004, 35.62285576, 37.76607976, 36.68406376, 33.05, 36.643663759999995, 36.70487176, 37.78607976, 37.827287760000004, 35.643663759999995, 36.68406376, 35.62285576, 36.643663759999995, 37.05, 36.68406376, 35.56164776, 34.05, 36.643663759999995, 36.643663759999995, 34.39883176, 35.62285576, 36.05, 34.68325576, 35.60204776, 36.68406376, 37.76607976, 35.52124776, 36.68406376, 36.68406376, 36.70487176, 36.68406376, 36.66366376, 36.70487176, 37.76607976, 36.643663759999995, 34.479631760000004, 36.68406376, 36.70487176, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 35.62285576, 37.76607976, 36.05, 36.74527176000001, 36.643663759999995, 36.68406376, 35.62285576, 36.05, 37.76607976, 37.827287760000004, 37.76607976, 33.41842376, 38.05, 35.60245576, 34.05, 36.643663759999995, 37.76607976, 36.66366376, 36.68406376, 36.70487176, 36.68406376, 36.643663759999995, 35.72446376, 36.68406376, 35.66325576, 36.70487176, 34.39883176, 36.72446376, 35.58245576, 36.643663759999995, 36.643663759999995, 36.72446376, 36.70487176, 34.05, 36.643663759999995, 36.70487176, 37.76607976, 36.68406376, 36.643663759999995, 36.70487176, 36.05, 36.66366376, 36.70487176, 36.68406376, 36.70487176, 36.68406376, 36.643663759999995, 36.80647976, 36.643663759999995, 34.46003976, 36.76607976, 36.643663759999995, 36.70487176, 35.72324776, 36.05, 36.643663759999995, 36.643663759999995, 35.52124776, 38.05, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 35.52124776, 36.643663759999995, 36.643663759999995, 36.70487176, 35.60204776, 36.70487176, 36.70487176, 36.68406376, 36.68406376, 36.643663759999995, 36.76607976, 36.68406376, 36.68406376, 36.76486376, 35.56164776, 36.643663759999995, 36.76607976, 36.70487176, 36.827287760000004, 36.70487176, 36.68406376, 36.70487176, 36.70487176, 33.43923176, 36.643663759999995, 38.05, 36.66366376, 35.58245576, 36.643663759999995, 35.56164776, 36.643663759999995, 36.68406376, 36.643663759999995, 35.643663759999995, 36.643663759999995, 36.643663759999995, 34.46003976, 36.68406376, 36.70487176, 35.56164776, 36.643663759999995, 36.643663759999995, 38.05, 35.56164776, 36.70487176, 36.68406376, 36.76486376, 36.70487176, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 36.68406376, 36.643663759999995, 35.56164776, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.72446376, 35.60204776, 36.68406376, 36.68406376, 37.05, 36.76607976, 35.52124776, 36.70487176, 35.66325576, 37.76607976, 36.70487176, 37.827287760000004, 36.70406376, 36.643663759999995, 35.52124776, 37.76607976, 35.05, 36.643663759999995, 36.76607976, 36.643663759999995, 33.291388000000005, 36.643663759999995, 36.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 35.58245576, 32.230588000000004, 36.643663759999995, 36.643663759999995, 36.70487176, 38.05, 35.56164776, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 37.05, 35.62285576, 36.68406376, 38.05, 36.66366376, 36.74527176000001, 34.46003976, 37.80647976, 36.643663759999995, 35.05, 33.05, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.74527176000001, 36.643663759999995, 38.05, 35.56164776, 36.70487176, 32.05, 36.76607976, 35.56164776, 38.05, 36.70406376, 35.52124776, 35.62285576, 31.33762376, 36.76607976, 36.643663759999995, 35.56164776, 35.60204776, 35.76607976, 35.52124776, 33.43923176, 35.52124776, 37.80647976, 36.70487176], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1480093658287599, "mean_inference_ms": 0.6042446546403686, "mean_action_processing_ms": 0.04666054922743978, "mean_env_wait_ms": 0.0515386320123468, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 56000, "agent_timesteps_total": 56000, "timers": {"sample_time_ms": 1816.138, "sample_throughput": 2202.476, "load_time_ms": 1.087, "load_throughput": 3678407.367, "learn_time_ms": 2419.736, "learn_throughput": 1653.073, "update_time_ms": 1.542}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.4248877763748169, "policy_loss": -0.052254568785429, "vf_loss": 0.47233596444129944, "vf_explained_var": 0.9960313439369202, "kl": 0.00712052034214139, "entropy": 0.7016302943229675, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 56000, "num_agent_steps_sampled": 56000, "num_steps_trained": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 11200, "training_iteration": 14, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-53", "timestamp": 1628628773, "time_this_iter_s": 3.5634500980377197, "time_total_s": 57.46324920654297, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 57.46324920654297, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 35.86, "ram_util_percent": 71.42}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 36.5806749804, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.643663759999995, 38.05, 36.643663759999995, 35.58245576, 36.643663759999995, 36.68406376, 35.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.74527176000001, 36.643663759999995, 36.05, 36.643663759999995, 36.74527176000001, 36.643663759999995, 35.52124776, 36.68406376, 31.049999999999997, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 36.74527176000001, 38.05, 36.643663759999995, 36.70487176, 36.643663759999995, 36.76607976, 36.76607976, 36.74527176000001, 38.05, 37.76607976, 37.76607976, 35.76607976, 36.643663759999995, 35.58245576, 36.643663759999995, 37.76607976, 35.58245576, 35.56164776, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.68406376, 37.827287760000004, 32.05, 35.64285576, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.05, 38.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.827287760000004, 36.643663759999995, 35.60204776, 36.643663759999995, 36.643663759999995, 35.62285576, 37.76607976, 36.643663759999995, 37.76607976, 35.58245576, 37.76607976, 37.80647976, 36.70487176, 37.827287760000004, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 36.68406376, 37.05, 37.76607976, 36.643663759999995, 37.76607976, 37.05, 36.643663759999995, 34.39883176, 36.70487176, 36.68406376, 36.76607976, 36.643663759999995, 36.765271760000005, 37.80647976, 36.643663759999995, 35.52124776, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.62285576, 36.643663759999995, 36.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.66366376, 36.05, 36.70487176, 37.76607976, 36.643663759999995, 37.05, 36.70487176, 36.643663759999995, 37.76607976, 35.05, 36.05, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 37.827287760000004, 37.76607976, 36.643663759999995, 35.52124776, 36.643663759999995, 36.643663759999995, 36.66366376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.74527176000001, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.72487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 35.643663759999995, 36.643663759999995, 36.643663759999995, 35.58245576, 36.68406376, 36.70487176, 36.68406376, 36.74527176000001, 36.70487176, 36.643663759999995, 36.70487176, 36.66366376, 36.643663759999995, 36.72446376, 37.76607976, 35.60204776, 36.70487176, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 37.827287760000004, 35.56164776, 36.68406376, 36.643663759999995, 35.58245576, 37.05, 36.68406376, 36.643663759999995, 37.05, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.58245576, 36.74527176000001, 36.70487176, 36.68406376, 35.60204776, 36.72446376, 37.76607976, 36.74527176000001, 34.46003976, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 38.05, 37.05, 36.643663759999995, 38.05, 38.05, 36.74527176000001, 36.68406376, 36.05, 32.37802376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 36.643663759999995, 36.66366376, 37.05, 32.230588000000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.66366376, 37.76607976, 36.643663759999995, 37.05, 36.70487176, 37.05, 35.58245576, 35.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 36.76607976, 35.643663759999995, 36.76607976, 36.76607976, 36.70487176, 36.643663759999995, 36.72487176, 35.58245576, 36.70487176, 36.643663759999995, 36.76607976, 36.643663759999995, 36.643663759999995, 32.05, 37.80647976, 36.643663759999995, 37.827287760000004, 34.39883176, 33.39883176, 33.316815760000004, 35.05, 36.70487176, 35.56164776, 36.72446376, 37.80647976, 35.68406376, 36.643663759999995, 35.56164776, 36.643663759999995, 36.643663759999995, 35.56164776, 36.643663759999995, 36.643663759999995, 36.72446376, 36.68406376, 36.68406376, 37.76607976, 37.76607976, 37.827287760000004, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.74527176000001, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 35.60204776, 36.76607976, 36.70487176, 36.643663759999995, 36.76607976, 37.76607976, 36.72487176, 36.76607976, 35.58245576, 36.643663759999995, 38.05, 37.05, 36.643663759999995, 36.72446376, 36.76607976, 36.643663759999995, 35.62285576, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 35.58245576, 37.76607976, 36.72487176, 37.827287760000004, 36.74527176000001, 36.68406376, 35.52124776, 34.56164776, 36.643663759999995, 35.56164776, 31.190188000000003, 36.70487176, 36.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 36.643663759999995, 36.827287760000004, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 35.56164776, 37.76607976, 36.643663759999995, 34.39883176, 35.52124776, 37.76607976, 36.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 35.62285576, 38.05, 36.76607976, 36.76607976, 36.643663759999995, 36.643663759999995, 35.05, 36.643663759999995, 36.643663759999995, 36.72446376, 36.68406376, 36.76607976, 36.76607976, 36.68406376, 36.76607976, 36.643663759999995, 35.58245576, 36.643663759999995, 35.58245576, 37.76607976, 36.66366376, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 36.70487176, 36.70487176, 35.58245576, 37.827287760000004, 36.68406376, 36.70487176, 37.05, 35.05, 34.500439760000006, 36.70487176, 37.05, 34.52124776, 36.68406376, 37.76607976, 36.643663759999995, 36.68406376, 35.60204776, 37.05, 36.643663759999995, 33.33762376, 36.643663759999995, 37.76607976, 36.643663759999995, 35.58245576, 36.68366376, 36.70487176, 35.58245576, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 34.39883176, 34.46003976, 38.05, 36.643663759999995, 36.70487176, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 36.72487176, 36.643663759999995, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.05, 36.70487176, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.827287760000004, 37.827287760000004, 36.68406376, 36.643663759999995, 35.52124776, 35.58245576, 36.643663759999995, 35.643663759999995, 36.72446376, 36.643663759999995, 33.291388000000005, 36.643663759999995, 37.80647976, 36.643663759999995, 36.643663759999995, 35.62245576, 36.643663759999995, 36.72446376, 36.70487176, 35.52124776, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.76607976, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.76607976, 33.316815760000004, 36.643663759999995, 37.76607976, 36.643663759999995, 37.05, 36.643663759999995, 35.62285576, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 35.58245576, 33.316815760000004, 37.76607976, 34.540839760000004, 37.76607976, 37.76607976, 36.76607976, 35.52124776, 33.33762376, 31.210188000000002, 36.68406376, 36.643663759999995, 35.58245576, 35.56164776, 36.643663759999995, 36.643663759999995, 36.70487176, 36.76607976, 36.643663759999995, 36.68406376, 36.05, 36.643663759999995, 36.70487176, 35.56164776, 36.70487176, 37.827287760000004, 36.78607976, 36.643663759999995, 35.52124776, 36.66366376, 36.68406376, 36.643663759999995, 35.643663759999995, 38.05, 36.66366376, 35.643663759999995, 36.68406376, 36.643663759999995, 35.58245576, 36.68406376, 36.70487176, 37.76607976, 35.52124776, 36.68406376, 36.74527176000001, 32.316815760000004, 36.68406376, 33.33762376, 37.76607976, 36.643663759999995, 36.68406376, 36.643663759999995, 38.05, 36.643663759999995, 36.643663759999995, 35.54124776, 37.76607976, 35.70406376, 36.68406376, 35.52124776, 36.643663759999995, 37.05, 36.70487176, 34.540839760000004, 36.66366376, 36.68406376, 36.72487176, 35.52124776, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.66366376, 36.68406376, 37.827287760000004, 36.643663759999995, 36.70487176, 37.05, 35.05, 37.76607976, 36.68406376, 35.62285576, 36.74527176000001, 36.76607976, 36.643663759999995, 36.765271760000005, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.74527176000001, 36.74527176000001, 36.643663759999995, 37.05, 36.68406376, 35.56164776, 36.68406376, 36.643663759999995, 36.70487176, 37.76607976, 36.72487176, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 35.05, 35.76607976, 37.827287760000004, 35.52124776, 36.643663759999995, 35.58245576, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 31.31681576, 36.643663759999995, 36.643663759999995, 35.56164776, 37.76607976, 36.70487176, 35.58245576, 36.643663759999995, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.76607976, 32.05, 35.58245576, 37.76607976, 36.70487176, 37.76607976, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 33.35721576, 36.643663759999995, 37.76607976, 36.05, 37.76607976, 36.643663759999995, 36.70487176, 35.52124776, 38.05, 38.05, 34.05, 36.643663759999995, 36.05, 36.70487176, 35.52124776, 36.70487176, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.70487176, 36.70487176, 36.72446376, 36.76607976, 36.72487176, 38.05, 36.74527176000001, 36.643663759999995, 36.643663759999995, 35.56164776, 36.643663759999995, 36.643663759999995, 36.72446376, 37.76607976, 37.827287760000004, 36.05, 36.70487176, 36.68406376, 36.70487176, 36.643663759999995, 36.70487176, 35.52124776, 36.643663759999995, 37.80647976, 36.643663759999995, 35.58245576, 36.643663759999995, 36.70487176, 37.76607976, 36.70487176, 34.39883176, 36.70406376, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.76607976, 34.52124776, 36.643663759999995, 35.58245576, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 36.74527176000001, 35.58245576, 35.66325576, 33.05, 36.643663759999995, 33.43721576, 36.643663759999995, 36.643663759999995, 35.52124776, 37.76607976, 36.643663759999995, 33.41883176, 36.68406376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.68406376, 36.643663759999995, 35.52124776, 37.76607976, 37.76607976, 36.70487176, 36.70487176, 36.68406376, 36.68406376, 38.05, 36.68366376, 37.76607976, 35.642447759999996, 36.70487176, 35.62285576, 35.52124776, 35.60204776, 36.643663759999995, 36.643663759999995, 36.70487176, 36.74527176000001, 36.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 35.56164776, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 35.60204776, 36.76607976, 37.05, 34.05, 36.643663759999995, 35.643663759999995, 36.68406376, 37.76607976, 36.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 35.58245576, 35.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 35.60204776, 37.76607976, 35.70487176, 35.60204776, 35.62285576, 38.05, 36.68406376, 36.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.72446376, 35.56164776, 36.643663759999995, 36.68406376, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14668228443390266, "mean_inference_ms": 0.5985856163498164, "mean_action_processing_ms": 0.04622251692384382, "mean_env_wait_ms": 0.05108386070536541, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 60000, "agent_timesteps_total": 60000, "timers": {"sample_time_ms": 1814.203, "sample_throughput": 2204.824, "load_time_ms": 1.089, "load_throughput": 3672529.387, "learn_time_ms": 2539.618, "learn_throughput": 1575.04, "update_time_ms": 1.658}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.31913435459136963, "policy_loss": -0.051984868943691254, "vf_loss": 0.3670870065689087, "vf_explained_var": 0.9969430565834045, "kl": 0.005973586812615395, "entropy": 0.6517837643623352, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 60000, "num_steps_trained": 60000, "num_agent_steps_trained": 60000}, "done": false, "episodes_total": 12000, "training_iteration": 15, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-52-58", "timestamp": 1628628778, "time_this_iter_s": 4.773051977157593, "time_total_s": 62.23630118370056, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 62.23630118370056, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 40.614285714285714, "ram_util_percent": 71.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.296007760000002, "episode_reward_mean": 36.758780037099996, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 36.643663759999995, 35.74405576, 36.68406376, 36.68406376, 36.643663759999995, 36.74527176000001, 36.70487176, 36.643663759999995, 35.62285576, 36.643663759999995, 37.76607976, 33.316815760000004, 37.76607976, 36.76607976, 36.68406376, 36.68406376, 36.643663759999995, 37.05, 37.76607976, 36.643663759999995, 35.56164776, 36.74527176000001, 36.70487176, 36.643663759999995, 35.52124776, 36.70487176, 36.643663759999995, 37.76607976, 36.68406376, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.70487176, 36.76607976, 36.70487176, 35.56164776, 36.643663759999995, 38.05, 34.43923176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.66366376, 37.05, 36.70487176, 37.827287760000004, 37.76607976, 36.72487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.52124776, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 36.68406376, 36.70487176, 37.76607976, 36.643663759999995, 35.52124776, 37.76607976, 36.643663759999995, 38.05, 36.70487176, 37.76607976, 36.70487176, 36.76607976, 37.76607976, 37.05, 36.70487176, 36.66366376, 36.72487176, 36.643663759999995, 36.70487176, 31.296007760000002, 36.68406376, 37.76607976, 37.05, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 35.56164776, 38.05, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 38.05, 36.643663759999995, 36.643663759999995, 35.62285576, 36.643663759999995, 36.70487176, 36.72446376, 36.70487176, 36.68406376, 35.52124776, 37.76607976, 36.68406376, 36.643663759999995, 36.68406376, 37.78607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.643663759999995, 36.643663759999995, 35.56164776, 36.643663759999995, 38.05, 37.76607976, 33.316815760000004, 37.76607976, 37.76607976, 36.70487176, 36.70487176, 37.80647976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 35.58245576, 36.643663759999995, 35.52124776, 36.70487176, 36.68406376, 37.827287760000004, 37.05, 36.643663759999995, 36.70487176, 35.58245576, 37.76607976, 36.68406376, 36.643663759999995, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 35.62285576, 36.70487176, 36.643663759999995, 37.76607976, 36.68406376, 36.68406376, 35.52124776, 36.643663759999995, 37.76607976, 36.643663759999995, 35.58245576, 36.643663759999995, 36.72446376, 36.70487176, 36.643663759999995, 36.74527176000001, 36.68406376, 36.643663759999995, 36.643663759999995, 38.05, 36.72446376, 36.70487176, 36.643663759999995, 37.76607976, 35.703655760000004, 38.05, 36.68406376, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 36.70487176, 35.58245576, 37.827287760000004, 36.643663759999995, 35.58245576, 37.76607976, 37.76607976, 34.540839760000004, 36.74527176000001, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.68406376, 35.05, 34.43923176, 36.643663759999995, 36.643663759999995, 38.05, 37.76607976, 35.58245576, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 34.500439760000006, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 38.05, 36.643663759999995, 36.70406376, 36.643663759999995, 36.643663759999995, 36.70487176, 38.05, 38.05, 36.70487176, 37.76607976, 37.76607976, 36.68406376, 36.72487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 36.68406376, 36.05, 38.05, 36.70487176, 38.05, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.60204776, 36.643663759999995, 37.827287760000004, 36.72487176, 37.76607976, 36.70487176, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 37.05, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.74527176000001, 36.643663759999995, 35.52124776, 36.76607976, 36.643663759999995, 37.78607976, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.80647976, 35.581647759999996, 36.643663759999995, 35.52124776, 37.76607976, 36.74527176000001, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 34.39883176, 36.643663759999995, 36.68406376, 36.643663759999995, 35.52124776, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 36.643663759999995, 36.70487176, 34.52124776, 36.643663759999995, 36.643663759999995, 38.05, 37.80647976, 35.62285576, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 35.52124776, 36.76486376, 37.76607976, 36.05, 36.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.76607976, 36.72446376, 37.76607976, 36.68406376, 33.316815760000004, 36.643663759999995, 36.76607976, 37.827287760000004, 36.70487176, 36.70487176, 37.76607976, 36.80647976, 37.76607976, 33.33762376, 35.56164776, 32.05, 38.05, 36.643663759999995, 36.76607976, 35.58245576, 36.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 38.05, 37.76607976, 35.58245576, 36.643663759999995, 35.58245576, 36.643663759999995, 36.643663759999995, 36.05, 36.70487176, 36.643663759999995, 37.827287760000004, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.66366376, 36.70487176, 35.642447759999996, 36.74527176000001, 36.643663759999995, 36.643663759999995, 35.52124776, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.80647976, 36.643663759999995, 36.643663759999995, 36.68406376, 37.76607976, 36.68406376, 34.540839760000004, 36.68406376, 38.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.827287760000004, 36.70487176, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.76607976, 36.643663759999995, 37.76607976, 36.827287760000004, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 35.54124776, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 35.52124776, 37.76607976, 36.70487176, 36.70487176, 36.72446376, 36.643663759999995, 36.643663759999995, 37.05, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 31.662039760000006, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 35.56164776, 36.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 32.291388000000005, 35.56164776, 36.643663759999995, 37.76607976, 36.643663759999995, 34.05, 35.62285576, 37.827287760000004, 36.70487176, 37.76607976, 36.68406376, 36.68406376, 36.643663759999995, 38.05, 36.70406376, 36.70487176, 35.68406376, 36.643663759999995, 36.70487176, 36.643663759999995, 36.68406376, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 35.56164776, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 36.68406376, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.68406376, 37.78607976, 35.56164776, 36.643663759999995, 36.68406376, 36.70487176, 37.76607976, 35.56164776, 36.643663759999995, 36.643663759999995, 36.72446376, 37.76607976, 36.70487176, 36.68406376, 35.60245576, 36.643663759999995, 36.643663759999995, 36.68406376, 36.68406376, 37.76607976, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 36.76607976, 35.58245576, 38.05, 34.52124776, 37.76607976, 36.643663759999995, 35.52124776, 36.70487176, 36.70487176, 36.68406376, 37.76607976, 35.52124776, 38.05, 36.643663759999995, 35.52124776, 37.827287760000004, 37.76607976, 36.70487176, 36.68406376, 37.76607976, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 37.827287760000004, 36.70487176, 35.68406376, 37.76607976, 36.76607976, 35.56164776, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 35.58245576, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 35.58245576, 36.643663759999995, 36.70406376, 36.70487176, 36.643663759999995, 35.70487176, 36.643663759999995, 37.827287760000004, 36.05, 36.68406376, 35.58245576, 36.70487176, 36.70487176, 36.66366376, 36.643663759999995, 36.68406376, 34.46003976, 36.68406376, 37.76607976, 36.70487176, 36.643663759999995, 38.05, 36.68406376, 36.70487176, 36.68406376, 35.58245576, 35.54124776, 36.643663759999995, 36.68406376, 36.643663759999995, 36.70487176, 37.827287760000004, 37.05, 36.70487176, 36.76607976, 36.643663759999995, 35.52124776, 36.643663759999995, 36.05, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 34.05, 37.76607976, 33.33762376, 35.60204776, 35.56164776, 38.05, 35.66325576, 36.72446376, 32.25058800000001, 35.52124776, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76486376, 36.70487176, 36.68406376, 36.70487176, 36.66366376, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 35.52124776, 36.68406376, 37.76607976, 36.643663759999995, 36.76607976, 36.68406376, 37.76607976, 36.68406376, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 38.05, 36.76607976, 37.76607976, 35.56164776, 33.39883176, 35.52124776, 38.05, 36.70487176, 36.70487176, 36.68406376, 37.76607976, 35.52124776, 36.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 36.72446376, 36.643663759999995, 36.70487176, 36.643663759999995, 38.05, 32.35721576, 37.76607976, 36.05, 36.643663759999995, 36.68406376, 36.643663759999995, 35.52124776, 36.643663759999995, 36.70487176, 36.70487176, 35.643663759999995, 37.76607976, 36.68406376, 36.70487176, 36.70487176, 37.76607976, 36.643663759999995, 35.60204776, 36.70487176, 36.72487176, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 35.62285576, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 35.05, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.05, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 34.500439760000006, 36.70487176, 35.52124776, 36.70487176, 36.643663759999995, 36.74527176000001, 37.76607976, 35.56164776, 35.52124776], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15328338431483532, "mean_inference_ms": 0.6263399343185734, "mean_action_processing_ms": 0.04839751128945357, "mean_env_wait_ms": 0.05344128870210819, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 64000, "agent_timesteps_total": 64000, "timers": {"sample_time_ms": 1962.498, "sample_throughput": 2038.219, "load_time_ms": 1.166, "load_throughput": 3431555.092, "learn_time_ms": 2742.288, "learn_throughput": 1458.636, "update_time_ms": 1.769}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.13698028028011322, "policy_loss": -0.06444701552391052, "vf_loss": 0.19725778698921204, "vf_explained_var": 0.9983361959457397, "kl": 0.006177057977765799, "entropy": 0.5989345908164978, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 64000, "num_agent_steps_sampled": 64000, "num_steps_trained": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 12800, "training_iteration": 16, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-05", "timestamp": 1628628785, "time_this_iter_s": 7.086802959442139, "time_total_s": 69.3231041431427, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 69.3231041431427, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 40.150000000000006, "ram_util_percent": 71.78999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.460039760000004, "episode_reward_mean": 36.9379866279, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 36.72446376, 37.76607976, 36.643663759999995, 36.643663759999995, 35.52124776, 35.58245576, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 36.70487176, 37.76607976, 36.643663759999995, 36.70487176, 35.52124776, 36.68406376, 38.05, 36.643663759999995, 38.05, 35.52124776, 37.76607976, 37.76607976, 36.643663759999995, 35.70487176, 36.643663759999995, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 36.70487176, 37.05, 36.643663759999995, 36.643663759999995, 36.68406376, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 35.52124776, 32.39761576, 36.643663759999995, 35.68406376, 34.480039760000004, 37.80647976, 36.643663759999995, 36.643663759999995, 36.70487176, 37.827287760000004, 36.643663759999995, 38.05, 37.76607976, 36.68406376, 36.643663759999995, 36.70487176, 37.76607976, 38.05, 37.76607976, 36.66366376, 37.80647976, 36.70487176, 37.76607976, 36.643663759999995, 38.05, 36.76607976, 36.68406376, 36.643663759999995, 36.70487176, 38.05, 36.643663759999995, 36.66366376, 36.643663759999995, 38.05, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 38.05, 37.76607976, 36.70487176, 36.72446376, 37.76607976, 36.70487176, 36.643663759999995, 37.827287760000004, 37.827287760000004, 36.66366376, 36.68406376, 36.643663759999995, 36.76607976, 36.68406376, 37.76607976, 35.62285576, 36.643663759999995, 36.643663759999995, 37.05, 36.643663759999995, 37.76607976, 36.70487176, 36.74527176000001, 36.70487176, 37.827287760000004, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 32.33762376, 36.643663759999995, 36.76607976, 36.74527176000001, 36.643663759999995, 36.68406376, 38.05, 37.76607976, 36.643663759999995, 36.68406376, 36.68406376, 37.80647976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.05, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 32.05, 32.33762376, 31.49922376, 36.68406376, 35.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 35.64285576, 36.68406376, 36.68406376, 38.05, 38.05, 34.46003976, 36.70487176, 36.70487176, 37.80647976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.827287760000004, 37.05, 36.643663759999995, 38.05, 36.05, 38.05, 37.827287760000004, 37.827287760000004, 36.70487176, 36.76607976, 37.76607976, 37.78607976, 37.05, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 37.05, 37.76607976, 35.58245576, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 38.05, 35.52124776, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 37.05, 36.70487176, 37.80647976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 37.827287760000004, 36.68406376, 36.68406376, 36.70487176, 35.56164776, 36.76607976, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.68406376, 36.643663759999995, 35.52124776, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 38.05, 38.05, 31.460039760000004, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 35.68325576, 37.827287760000004, 35.58245576, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 36.70487176, 35.58245576, 37.76607976, 38.05, 37.80647976, 37.76607976, 38.05, 37.76607976, 36.72446376, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.80647976, 37.76607976, 35.56164776, 37.827287760000004, 37.76607976, 36.643663759999995, 36.70487176, 38.05, 36.643663759999995, 36.68406376, 36.643663759999995, 36.70487176, 36.643663759999995, 36.66366376, 36.70487176, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 36.70487176, 36.70487176, 36.68406376, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 35.58245576, 36.68406376, 36.643663759999995, 36.74527176000001, 36.643663759999995, 36.643663759999995, 36.72487176, 36.68406376, 36.70487176, 36.68406376, 36.643663759999995, 37.827287760000004, 35.52124776, 36.643663759999995, 36.76607976, 37.05, 36.643663759999995, 37.827287760000004, 37.76607976, 35.52124776, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.70487176, 35.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.05, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.80647976, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 33.500439760000006, 36.643663759999995, 35.52124776, 35.703655760000004, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 36.76607976, 37.80647976, 36.05, 36.68406376, 37.76607976, 36.643663759999995, 36.68406376, 36.74527176000001, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.70487176, 36.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.643663759999995, 36.70487176, 38.05, 36.05, 35.58245576, 36.643663759999995, 35.56164776, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 36.70487176, 33.33762376, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 37.76607976, 38.05, 37.76607976, 38.05, 36.70487176, 36.68406376, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 34.39883176, 38.05, 36.643663759999995, 36.70487176, 36.76607976, 35.05, 36.643663759999995, 36.68406376, 36.05, 36.643663759999995, 36.70487176, 37.76607976, 35.52124776, 36.643663759999995, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 37.827287760000004, 37.80647976, 36.76486376, 36.68406376, 36.70487176, 35.643663759999995, 36.70487176, 37.76607976, 38.05, 36.68406376, 37.76607976, 36.68406376, 36.70487176, 37.76607976, 36.68406376, 36.643663759999995, 36.68406376, 37.76607976, 32.52124776, 37.76607976, 37.76607976, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 35.643663759999995, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 37.827287760000004, 36.76607976, 38.05, 38.05, 36.643663759999995, 37.05, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 35.58245576, 37.76607976, 36.643663759999995, 36.643663759999995, 37.827287760000004, 36.70487176, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 36.05, 36.643663759999995, 37.76607976, 36.78567176000001, 36.643663759999995, 36.72487176, 34.46003976, 36.643663759999995, 35.56164776, 36.643663759999995, 36.70487176, 37.827287760000004, 36.74527176000001, 36.70487176, 37.76607976, 37.05, 36.70487176, 36.72446376, 35.58245576, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 36.68406376, 35.52124776, 38.05, 37.76607976, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 38.05, 35.62285576, 35.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 35.60204776, 37.05, 37.827287760000004, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 33.56164776, 35.52124776, 37.05, 36.643663759999995, 36.643663759999995, 38.05, 37.827287760000004, 36.643663759999995, 36.76607976, 37.76607976, 36.643663759999995, 37.827287760000004, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 35.58245576, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 35.60204776, 37.80647976, 36.70487176, 36.643663759999995, 36.643663759999995, 37.76607976, 37.05, 36.76607976, 35.68406376, 37.76607976, 36.643663759999995, 36.70487176, 37.827287760000004, 36.72446376, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 35.52124776, 34.43923176, 37.76607976, 37.76607976, 35.643663759999995, 36.68406376, 37.05, 37.76607976, 37.76607976, 38.05, 35.52124776, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 37.827287760000004, 37.80647976, 38.05, 37.76607976, 36.68406376, 37.76607976, 36.643663759999995, 35.62285576, 36.643663759999995, 36.05, 36.76607976, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 38.05, 36.70487176, 36.643663759999995, 37.05, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 36.70487176, 37.827287760000004, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 37.76607976, 36.05, 33.05, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 36.68406376, 37.80647976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 36.68406376, 38.05, 35.60204776, 36.643663759999995, 37.05, 37.76607976, 36.74527176000001, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 36.68406376, 35.52124776, 36.643663759999995, 35.58245576, 37.827287760000004, 37.05, 36.643663759999995, 36.68406376, 36.643663759999995, 37.05, 38.05, 36.76607976, 37.76607976, 35.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 37.05, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 35.58245576, 36.643663759999995, 38.05, 36.70487176, 37.76607976, 36.68406376, 33.46003976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 37.827287760000004, 37.76607976, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.68406376, 36.74527176000001, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 35.56164776, 36.643663759999995, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15779792664699746, "mean_inference_ms": 0.6448591264892067, "mean_action_processing_ms": 0.04985928097204868, "mean_env_wait_ms": 0.0550484033911471, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 68000, "agent_timesteps_total": 68000, "timers": {"sample_time_ms": 2083.77, "sample_throughput": 1919.598, "load_time_ms": 1.162, "load_throughput": 3440986.115, "learn_time_ms": 2748.352, "learn_throughput": 1455.418, "update_time_ms": 1.783}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.19058704376220703, "policy_loss": -0.06473636627197266, "vf_loss": 0.25065329670906067, "vf_explained_var": 0.997918963432312, "kl": 0.006918721366673708, "entropy": 0.5428050756454468, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 68000, "num_agent_steps_sampled": 68000, "num_steps_trained": 68000, "num_agent_steps_trained": 68000}, "done": false, "episodes_total": 13600, "training_iteration": 17, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-10", "timestamp": 1628628790, "time_this_iter_s": 4.827944993972778, "time_total_s": 74.15104913711548, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 74.15104913711548, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 32.25714285714286, "ram_util_percent": 71.74285714285715}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.25058800000001, "episode_reward_mean": 37.13976057, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 35.56164776, 37.76607976, 35.62285576, 36.643663759999995, 38.05, 37.05, 36.72487176, 37.76607976, 37.76607976, 36.70487176, 36.643663759999995, 37.827287760000004, 36.70487176, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.05, 37.76607976, 35.58245576, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 38.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 38.05, 37.76607976, 37.76607976, 37.80647976, 36.68406376, 37.827287760000004, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 37.827287760000004, 36.643663759999995, 37.827287760000004, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.68406376, 36.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 36.68406376, 38.05, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.827287760000004, 37.76607976, 35.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.72446376, 36.643663759999995, 36.72446376, 36.643663759999995, 36.643663759999995, 37.05, 37.05, 38.05, 36.643663759999995, 36.76607976, 35.58245576, 34.52124776, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.05, 36.643663759999995, 37.76607976, 37.76607976, 37.827287760000004, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 34.46003976, 37.05, 37.76607976, 35.58245576, 38.05, 36.643663759999995, 36.643663759999995, 38.05, 36.643663759999995, 36.643663759999995, 36.72446376, 37.76607976, 36.643663759999995, 32.25058800000001, 38.05, 38.05, 38.05, 38.05, 36.66366376, 36.74527176000001, 36.643663759999995, 35.643663759999995, 37.827287760000004, 36.68406376, 37.76607976, 36.68406376, 38.05, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 37.05, 37.76607976, 36.68406376, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 35.58245576, 37.76607976, 37.76607976, 36.643663759999995, 37.05, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.80647976, 37.76607976, 37.76607976, 37.05, 37.76607976, 36.70487176, 36.70487176, 37.76607976, 37.827287760000004, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.68406376, 37.827287760000004, 36.68406376, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 36.70487176, 36.643663759999995, 38.05, 38.05, 37.80647976, 35.58245576, 37.76607976, 37.80647976, 37.76607976, 36.643663759999995, 38.05, 38.05, 38.05, 36.643663759999995, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 36.643663759999995, 37.76607976, 37.80647976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 37.78607976, 37.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.72487176, 37.76607976, 37.827287760000004, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.05, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 35.52124776, 36.72446376, 36.68406376, 38.05, 37.76607976, 38.05, 36.68406376, 38.05, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.05, 36.643663759999995, 36.70487176, 37.80647976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.80647976, 36.643663759999995, 37.827287760000004, 36.76607976, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 35.52124776, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 35.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 35.52124776, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.643663759999995, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 35.52124776, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 36.76607976, 38.05, 36.643663759999995, 37.05, 36.643663759999995, 36.643663759999995, 37.76607976, 33.643663759999995, 37.76607976, 38.05, 35.643663759999995, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 38.05, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 36.68406376, 36.643663759999995, 37.827287760000004, 36.70487176, 37.76607976, 36.643663759999995, 36.68406376, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 35.05, 36.643663759999995, 36.643663759999995, 37.76607976, 36.643663759999995, 37.80647976, 35.52124776, 37.76607976, 36.68406376, 36.643663759999995, 36.643663759999995, 38.05, 37.76607976, 36.643663759999995, 34.56164776, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.05, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.72446376, 36.643663759999995, 38.05, 36.74527176000001, 37.827287760000004, 36.643663759999995, 38.05, 37.827287760000004, 36.68406376, 37.827287760000004, 36.643663759999995, 37.76607976, 36.74527176000001, 37.827287760000004, 37.76607976, 36.643663759999995, 37.05, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 36.70487176, 38.05, 37.76607976, 37.827287760000004, 37.05, 36.70487176, 36.70487176, 37.827287760000004, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 35.58245576, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.74527176000001, 35.58245576, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 36.643663759999995, 36.05, 36.68406376, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 38.05, 36.78567176000001, 32.270988, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.72446376, 37.76607976, 36.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 36.70487176, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 36.68406376, 36.643663759999995, 36.643663759999995, 37.827287760000004, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 36.643663759999995, 35.62285576, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 37.80647976, 37.827287760000004, 38.05, 36.68406376, 36.643663759999995, 35.52124776, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 38.05, 36.70487176, 37.76607976, 36.68406376, 36.68406376, 38.05, 36.68406376, 35.52124776, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 35.62285576, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.76607976, 37.827287760000004, 36.643663759999995, 36.643663759999995, 38.05, 37.76607976, 37.827287760000004, 35.52124776, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.76607976, 37.05, 37.76607976, 35.52124776, 37.76607976, 37.76607976, 35.58245576, 36.05, 36.643663759999995, 36.643663759999995, 37.76607976, 34.46003976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 35.52124776, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.66366376, 37.76607976, 37.76607976, 36.70487176, 36.80647976, 36.70487176, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 37.76607976, 38.05, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.56164776, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.74527176000001, 36.643663759999995, 35.62285576, 36.643663759999995, 36.70487176, 36.76486376, 36.74527176000001, 37.827287760000004, 38.05, 36.68406376, 37.827287760000004, 36.70487176, 36.68406376, 38.05, 36.68406376, 36.68406376, 37.76607976, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 38.05, 36.643663759999995, 38.05, 37.827287760000004, 36.643663759999995, 36.74487176, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.80647976, 36.68406376, 35.66325576, 37.76607976, 34.46003976, 36.74527176000001, 36.70487176, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 37.80647976, 36.643663759999995, 38.05, 37.76607976, 36.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 36.70487176, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.72446376, 36.76607976, 36.72446376, 38.05, 37.827287760000004, 38.05, 36.68406376, 36.643663759999995, 36.643663759999995, 37.76607976, 36.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.52124776, 36.643663759999995, 35.58245576, 36.643663759999995, 36.643663759999995, 37.76607976, 36.74527176000001, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 36.68406376, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 38.05, 34.56164776, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1562831766131666, "mean_inference_ms": 0.6383581262956557, "mean_action_processing_ms": 0.049369987032585064, "mean_env_wait_ms": 0.05451472500079785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 72000, "agent_timesteps_total": 72000, "timers": {"sample_time_ms": 2082.119, "sample_throughput": 1921.12, "load_time_ms": 1.167, "load_throughput": 3428609.732, "learn_time_ms": 2746.475, "learn_throughput": 1456.412, "update_time_ms": 1.806}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08057384192943573, "policy_loss": -0.08960755914449692, "vf_loss": 0.16246815025806427, "vf_explained_var": 0.9986361265182495, "kl": 0.011427070014178753, "entropy": 0.4990968406200409, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 72000, "num_agent_steps_sampled": 72000, "num_steps_trained": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 14400, "training_iteration": 18, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-13", "timestamp": 1628628793, "time_this_iter_s": 3.6014840602874756, "time_total_s": 77.75253319740295, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 77.75253319740295, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 36.980000000000004, "ram_util_percent": 71.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.33762376, "episode_reward_mean": 37.2962652984, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 36.70487176, 38.05, 35.827287760000004, 36.70487176, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 33.43923176, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.80647976, 36.68406376, 35.58245576, 37.76607976, 37.76607976, 37.76607976, 36.72446376, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 38.05, 37.827287760000004, 36.76607976, 36.643663759999995, 37.827287760000004, 36.643663759999995, 37.76607976, 37.827287760000004, 37.76607976, 36.76607976, 37.76607976, 37.05, 37.76607976, 36.643663759999995, 33.39761576, 38.05, 37.76607976, 37.76607976, 37.05, 37.827287760000004, 37.76607976, 36.68406376, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 36.68406376, 35.58245576, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 38.05, 37.76607976, 38.05, 36.643663759999995, 36.72446376, 37.827287760000004, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 35.52124776, 36.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.827287760000004, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.70487176, 38.05, 37.05, 37.76607976, 37.76607976, 35.52124776, 37.76607976, 36.643663759999995, 36.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.05, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 38.05, 36.76607976, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.66366376, 38.05, 37.76607976, 35.05, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.68406376, 37.80647976, 37.05, 38.05, 34.52124776, 36.70487176, 37.76607976, 36.643663759999995, 34.56164776, 37.76607976, 36.68406376, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 35.643663759999995, 37.76607976, 38.05, 37.76607976, 36.72446376, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 38.05, 36.70487176, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 38.05, 36.05, 37.76607976, 37.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.80647976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 35.68406376, 38.05, 37.05, 37.76607976, 37.78607976, 36.72446376, 37.76607976, 36.643663759999995, 37.80647976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 36.74527176000001, 36.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 35.62285576, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 36.68406376, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.05, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 38.05, 38.05, 38.05, 36.70487176, 37.76607976, 37.76607976, 36.70487176, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 35.60204776, 37.76607976, 36.68406376, 36.643663759999995, 35.62285576, 38.05, 37.76607976, 38.05, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 36.05, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 36.68406376, 36.68406376, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.05, 37.76607976, 35.52124776, 36.643663759999995, 38.05, 38.05, 37.76607976, 37.76607976, 36.70487176, 38.05, 37.76607976, 36.643663759999995, 35.58245576, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 36.74527176000001, 36.74527176000001, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 37.05, 35.56164776, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 37.827287760000004, 37.76607976, 36.72446376, 37.76607976, 36.643663759999995, 38.05, 36.70487176, 35.643663759999995, 37.76607976, 38.05, 37.76607976, 36.70487176, 36.74527176000001, 37.76607976, 35.703655760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 33.33762376, 36.68406376, 37.76607976, 38.05, 34.500439760000006, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 38.05, 36.76486376, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.66366376, 38.05, 37.76607976, 37.05, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.68406376, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 37.05, 37.827287760000004, 36.643663759999995, 36.70487176, 36.643663759999995, 37.76607976, 38.05, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70406376, 36.70487176, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 38.05, 38.05, 36.643663759999995, 37.76607976, 36.70487176, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 38.05, 36.74527176000001, 35.52124776, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.80647976, 37.76607976, 36.70487176, 36.643663759999995, 36.76607976, 37.80647976, 38.05, 37.76607976, 37.827287760000004, 36.70487176, 38.05, 38.05, 37.76607976, 37.80647976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 37.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 38.05, 35.05, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.643663759999995, 36.68406376, 36.70487176, 35.58245576, 37.76607976, 37.76607976, 36.70487176, 36.68406376, 37.76607976, 38.05, 36.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 36.70487176, 36.643663759999995, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.72446376, 37.76607976, 37.05, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 35.05, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 37.05, 36.70487176, 37.76607976, 37.80647976, 36.68406376, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 37.05, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 34.46003976, 37.76607976, 37.80647976, 38.05, 37.827287760000004, 37.76607976, 36.68406376, 37.80647976, 38.05, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.76486376, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.76607976, 36.70487176, 37.827287760000004, 36.643663759999995, 37.827287760000004, 36.643663759999995, 38.05, 37.76607976, 36.76607976, 36.76607976, 36.643663759999995, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 36.76607976, 37.76607976, 38.05, 38.05, 36.643663759999995, 35.643663759999995, 36.76607976, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 36.70487176, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.72446376, 37.76607976, 36.68406376, 37.76607976, 36.68406376, 36.70487176, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 35.62285576, 36.643663759999995, 37.76607976, 37.827287760000004, 36.70487176, 38.05, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 36.68406376, 36.68406376, 38.05, 36.68406376, 36.643663759999995, 38.05, 36.68406376, 35.62285576, 37.76607976, 38.05, 37.76607976, 38.05, 36.68406376, 37.76607976, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 37.76607976, 37.827287760000004, 36.643663759999995, 37.76607976, 36.70487176, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.827287760000004, 36.643663759999995, 37.76607976, 38.05, 38.05, 36.68366376, 38.05, 37.827287760000004, 37.827287760000004, 37.80647976, 36.70487176, 37.76607976, 36.70487176, 36.68406376, 37.76607976, 36.70487176, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 36.68406376, 37.76607976, 37.76607976, 37.80647976, 36.70487176, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 36.05, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 35.56164776, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 37.05, 38.05, 36.643663759999995, 36.643663759999995, 36.74527176000001, 37.76607976, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1548185388915354, "mean_inference_ms": 0.632018413183824, "mean_action_processing_ms": 0.0488808875253196, "mean_env_wait_ms": 0.05399366136707853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 76000, "agent_timesteps_total": 76000, "timers": {"sample_time_ms": 2073.323, "sample_throughput": 1929.27, "load_time_ms": 1.168, "load_throughput": 3423292.865, "learn_time_ms": 2739.557, "learn_throughput": 1460.09, "update_time_ms": 1.807}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08427178114652634, "policy_loss": -0.09139007329940796, "vf_loss": 0.16276630759239197, "vf_explained_var": 0.9986214637756348, "kl": 0.019104506820440292, "entropy": 0.42188510298728943, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 76000, "num_agent_steps_sampled": 76000, "num_steps_trained": 76000, "num_agent_steps_trained": 76000}, "done": false, "episodes_total": 15200, "training_iteration": 19, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-17", "timestamp": 1628628797, "time_this_iter_s": 3.555448055267334, "time_total_s": 81.30798125267029, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 81.30798125267029, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 36.60000000000001, "ram_util_percent": 71.85999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.5149423696, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.643663759999995, 38.05, 37.76607976, 37.05, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 38.05, 37.76607976, 37.76607976, 38.05, 36.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 36.68406376, 36.643663759999995, 36.70487176, 35.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.74527176000001, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 36.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.05, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 35.52124776, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 36.70487176, 37.76607976, 38.05, 37.76607976, 36.76607976, 37.05, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.68406376, 33.33762376, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.78607976, 37.76607976, 38.05, 37.76607976, 37.05, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 34.43923176, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.827287760000004, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 38.05, 36.70487176, 36.643663759999995, 37.76607976, 35.56164776, 37.76607976, 37.05, 37.80647976, 35.58245576, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 36.643663759999995, 38.05, 38.05, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.72446376, 37.76607976, 36.74527176000001, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.05, 36.70487176, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 36.70487176, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 38.05, 35.52124776, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.80647976, 37.76607976, 37.76607976, 36.643663759999995, 36.68406376, 38.05, 35.52124776, 36.643663759999995, 37.76607976, 35.58245576, 37.76607976, 38.05, 36.643663759999995, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.80647976, 36.643663759999995, 36.643663759999995, 38.05, 37.827287760000004, 37.76607976, 32.05, 37.76607976, 36.72446376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 35.56164776, 38.05, 36.70487176, 37.76607976, 38.05, 38.05, 36.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 36.70487176, 34.46003976, 36.70487176, 37.76607976, 35.66325576, 38.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.68406376, 36.70487176, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.72446376, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 36.68406376, 38.05, 37.76607976, 35.62285576, 38.05, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 36.70487176, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 35.60204776, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.80647976, 37.76607976, 36.643663759999995, 36.70487176, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 36.70487176, 37.80647976, 36.643663759999995, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 36.74527176000001, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.643663759999995, 37.827287760000004, 37.76607976, 37.76607976, 35.52124776, 37.76607976, 36.643663759999995, 37.76607976, 36.76607976, 37.78607976, 36.643663759999995, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.05, 38.05, 37.76607976, 29.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 35.58245576, 38.05, 37.76607976, 37.76607976, 36.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.78607976, 36.68406376, 37.827287760000004, 36.643663759999995, 37.76607976, 32.56164776, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 36.643663759999995, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 33.33762376, 36.74527176000001, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 36.70487176, 35.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 36.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 36.70487176, 37.76607976, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15346666463705685, "mean_inference_ms": 0.6263576708168738, "mean_action_processing_ms": 0.048437385790819104, "mean_env_wait_ms": 0.05352124879128998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 80000, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 1920.277, "sample_throughput": 2083.032, "load_time_ms": 1.09, "load_throughput": 3669798.106, "learn_time_ms": 2535.76, "learn_throughput": 1577.436, "update_time_ms": 1.65}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.22146020829677582, "policy_loss": -0.04120560362935066, "vf_loss": 0.25556397438049316, "vf_explained_var": 0.997856080532074, "kl": 0.010521232150495052, "entropy": 0.33416247367858887, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 80000, "num_steps_trained": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 16000, "training_iteration": 20, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-21", "timestamp": 1628628801, "time_this_iter_s": 3.5650758743286133, "time_total_s": 84.8730571269989, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 84.8730571269989, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 36.38, "ram_util_percent": 71.88000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.050000000000004, "episode_reward_mean": 37.697812412800005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.05, 37.76607976, 35.62285576, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.80647976, 37.80647976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 34.43923176, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 36.68406376, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.827287760000004, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 38.05, 37.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 38.05, 36.68406376, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.78607976, 38.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.76607976, 35.62285576, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.827287760000004, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.80647976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.80647976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.80647976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 38.05, 36.643663759999995, 36.643663759999995, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 36.643663759999995, 37.827287760000004, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 35.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.05, 37.76607976, 38.05, 37.76607976, 38.05, 36.643663759999995, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 33.37802376, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.80647976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 34.500439760000006, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.827287760000004, 37.05, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.68406376, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 36.643663759999995, 36.70487176, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 38.05, 37.80647976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 36.74527176000001, 38.05, 37.76607976, 38.05, 38.05, 36.68406376, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 36.643663759999995, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 30.050000000000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.80647976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15235903978273982, "mean_inference_ms": 0.6217001387086448, "mean_action_processing_ms": 0.04807293056031103, "mean_env_wait_ms": 0.05312807596693981, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 84000, "agent_timesteps_total": 84000, "timers": {"sample_time_ms": 1775.328, "sample_throughput": 2253.105, "load_time_ms": 1.014, "load_throughput": 3946001.835, "learn_time_ms": 2387.945, "learn_throughput": 1675.081, "update_time_ms": 1.612}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 0.1300584226846695, "policy_loss": -0.028412241488695145, "vf_loss": 0.15513545274734497, "vf_explained_var": 0.9986545443534851, "kl": 0.004941062070429325, "entropy": 0.26667654514312744, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 84000, "num_agent_steps_sampled": 84000, "num_steps_trained": 84000, "num_agent_steps_trained": 84000}, "done": false, "episodes_total": 16800, "training_iteration": 21, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-24", "timestamp": 1628628804, "time_this_iter_s": 3.60862398147583, "time_total_s": 88.48168110847473, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 88.48168110847473, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 37.660000000000004, "ram_util_percent": 71.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 37.7531351087, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.74527176000001, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 35.58245576, 37.76607976, 37.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 36.643663759999995, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 36.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.78607976, 38.05, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 36.05, 37.76607976, 37.76607976, 37.80647976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 34.05, 38.05, 37.76607976, 37.76607976, 34.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 35.52124776, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 35.66285576, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.68406376, 38.05, 38.05, 38.05, 37.827287760000004, 36.70487176, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.80647976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 36.72446376, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 36.70487176, 38.05, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.74527176000001, 38.05, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 36.76607976, 37.76607976, 38.05, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 35.58245576, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 36.643663759999995, 36.70487176, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 35.05, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 35.52124776, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.643663759999995, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.80647976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1512652313039264, "mean_inference_ms": 0.6171541699918627, "mean_action_processing_ms": 0.04771841306290419, "mean_env_wait_ms": 0.05273938880709391, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 88000, "agent_timesteps_total": 88000, "timers": {"sample_time_ms": 1767.511, "sample_throughput": 2263.07, "load_time_ms": 1.009, "load_throughput": 3963902.185, "learn_time_ms": 2385.723, "learn_throughput": 1676.64, "update_time_ms": 1.621}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.3375000059604645, "cur_lr": 4.999999873689376e-05, "total_loss": 0.1268606036901474, "policy_loss": -0.024625081568956375, "vf_loss": 0.1500254124403, "vf_explained_var": 0.9987266063690186, "kl": 0.004326705355197191, "entropy": 0.25272268056869507, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 88000, "num_agent_steps_sampled": 88000, "num_steps_trained": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 17600, "training_iteration": 22, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-28", "timestamp": 1628628808, "time_this_iter_s": 3.59936261177063, "time_total_s": 92.08104372024536, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 92.08104372024536, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 37.31666666666666, "ram_util_percent": 72.10000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 34.46003976, "episode_reward_mean": 37.8023986516, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 35.62285576, 37.827287760000004, 37.76607976, 36.643663759999995, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 35.62285576, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.80647976, 37.80647976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 36.70487176, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.80647976, 38.05, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 35.66325576, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 35.70487176, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 38.05, 36.68406376, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 34.46003976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.80647976, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 38.05, 38.05, 38.05, 36.643663759999995, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 35.05, 37.76607976, 37.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.827287760000004, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 36.70487176, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.05, 37.76607976, 38.05, 37.76607976, 38.05, 36.05, 37.76607976, 36.68406376, 36.68406376, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 36.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 35.56164776, 37.76607976, 38.05, 37.05, 38.05, 37.76607976, 37.05, 37.827287760000004, 37.80647976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.80647976, 37.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 36.70487176, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15052025303789118, "mean_inference_ms": 0.6139646967878363, "mean_action_processing_ms": 0.047469395134377014, "mean_env_wait_ms": 0.05246391996285524, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 92000, "agent_timesteps_total": 92000, "timers": {"sample_time_ms": 1773.315, "sample_throughput": 2255.662, "load_time_ms": 1.015, "load_throughput": 3940070.924, "learn_time_ms": 2402.442, "learn_throughput": 1664.972, "update_time_ms": 1.662}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.16875000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 0.05306444317102432, "policy_loss": -0.02749815210700035, "vf_loss": 0.07880931347608566, "vf_explained_var": 0.9993245005607605, "kl": 0.010389796458184719, "entropy": 0.22938185930252075, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 92000, "num_agent_steps_sampled": 92000, "num_steps_trained": 92000, "num_agent_steps_trained": 92000}, "done": false, "episodes_total": 18400, "training_iteration": 23, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-32", "timestamp": 1628628812, "time_this_iter_s": 3.7972240447998047, "time_total_s": 95.87826776504517, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 95.87826776504517, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 35.519999999999996, "ram_util_percent": 72.05999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 34.05, "episode_reward_mean": 37.862952533699996, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.80647976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.80647976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.05, 38.05, 38.05, 37.80647976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 36.74527176000001, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.80647976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 36.70487176, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 36.05, 37.76607976, 38.05, 37.76607976, 36.643663759999995, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 36.70487176, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 34.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 36.70487176, 37.76607976, 37.76607976, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 35.62285576, 38.05, 38.05, 37.76607976, 36.68406376, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 36.643663759999995, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 36.68406376, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.80647976, 37.76607976, 36.74527176000001, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 36.70487176, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.76607976, 36.70487176, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.80647976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14976078449558494, "mean_inference_ms": 0.6107982304023654, "mean_action_processing_ms": 0.04723003955113981, "mean_env_wait_ms": 0.0521892140436708, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 96000, "agent_timesteps_total": 96000, "timers": {"sample_time_ms": 1778.422, "sample_throughput": 2249.185, "load_time_ms": 1.014, "load_throughput": 3943682.949, "learn_time_ms": 2406.256, "learn_throughput": 1662.333, "update_time_ms": 1.692}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.16875000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 0.03965415433049202, "policy_loss": -0.0306874867528677, "vf_loss": 0.0686485543847084, "vf_explained_var": 0.9994106888771057, "kl": 0.01003315020352602, "entropy": 0.20603878796100616, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 96000, "num_agent_steps_sampled": 96000, "num_steps_trained": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 19200, "training_iteration": 24, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-35", "timestamp": 1628628815, "time_this_iter_s": 3.65354323387146, "time_total_s": 99.53181099891663, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 99.53181099891663, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 36.720000000000006, "ram_util_percent": 71.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.643663759999995, "episode_reward_mean": 37.9234536897, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 36.643663759999995, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 36.643663759999995, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 36.74527176000001, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 36.68406376, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 36.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 36.643663759999995, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 36.70487176, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 36.70487176, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.76607976, 37.76607976, 37.76607976, 38.05, 37.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 36.70487176, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 36.643663759999995, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14894712100264834, "mean_inference_ms": 0.6071750966218162, "mean_action_processing_ms": 0.046951976152127345, "mean_env_wait_ms": 0.051887747607291514, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 100000, "agent_timesteps_total": 100000, "timers": {"sample_time_ms": 1778.697, "sample_throughput": 2248.838, "load_time_ms": 1.012, "load_throughput": 3950647.797, "learn_time_ms": 2286.837, "learn_throughput": 1749.141, "update_time_ms": 1.576}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.16875000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": -0.010079873725771904, "policy_loss": -0.04860334098339081, "vf_loss": 0.03523470461368561, "vf_explained_var": 0.9996974468231201, "kl": 0.019488949328660965, "entropy": 0.16019554436206818, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 100000, "num_steps_trained": 100000, "num_agent_steps_trained": 100000}, "done": false, "episodes_total": 20000, "training_iteration": 25, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-39", "timestamp": 1628628819, "time_this_iter_s": 3.5664279460906982, "time_total_s": 103.09823894500732, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 103.09823894500732, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 36.66, "ram_util_percent": 72.1}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.316815760000004, "episode_reward_mean": 37.95346066290001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.62285576, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 33.316815760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 36.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.80647976, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.05, 38.05, 37.76607976, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 36.643663759999995, 36.68406376, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.80647976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 36.05, 38.05, 38.05, 38.05, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14813218982661538, "mean_inference_ms": 0.6038002622959461, "mean_action_processing_ms": 0.04668397029196605, "mean_env_wait_ms": 0.05160036028533007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 104000, "agent_timesteps_total": 104000, "timers": {"sample_time_ms": 1629.9, "sample_throughput": 2454.138, "load_time_ms": 0.939, "load_throughput": 4259690.245, "learn_time_ms": 2099.449, "learn_throughput": 1905.262, "update_time_ms": 1.522}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.16875000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 0.04187038913369179, "policy_loss": -0.030066927894949913, "vf_loss": 0.0669742301106453, "vf_explained_var": 0.9994245171546936, "kl": 0.02941087819635868, "entropy": 0.07846436649560928, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 104000, "num_agent_steps_sampled": 104000, "num_steps_trained": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 20800, "training_iteration": 26, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-43", "timestamp": 1628628823, "time_this_iter_s": 3.712167263031006, "time_total_s": 106.81040620803833, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 106.81040620803833, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 37.4, "ram_util_percent": 72.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.70487176, "episode_reward_mean": 38.02248703800001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14788445158204852, "mean_inference_ms": 0.60241699563126, "mean_action_processing_ms": 0.0465917546661564, "mean_env_wait_ms": 0.051476216285759116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 108000, "agent_timesteps_total": 108000, "timers": {"sample_time_ms": 1523.473, "sample_throughput": 2625.579, "load_time_ms": 0.941, "load_throughput": 4250301.725, "learn_time_ms": 2095.929, "learn_throughput": 1908.462, "update_time_ms": 1.509}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.25312501192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 0.004227759316563606, "policy_loss": -0.013753951527178288, "vf_loss": 0.017545215785503387, "vf_explained_var": 0.9998477101325989, "kl": 0.001724440255202353, "entropy": 0.038616590201854706, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 108000, "num_agent_steps_sampled": 108000, "num_steps_trained": 108000, "num_agent_steps_trained": 108000}, "done": false, "episodes_total": 21600, "training_iteration": 27, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-47", "timestamp": 1628628827, "time_this_iter_s": 3.7290868759155273, "time_total_s": 110.53949308395386, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 110.53949308395386, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 30.439999999999998, "ram_util_percent": 72.14}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.050000000000004, "episode_reward_mean": 38.02652662370001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14729270002518005, "mean_inference_ms": 0.5998617176396434, "mean_action_processing_ms": 0.04639649135304661, "mean_env_wait_ms": 0.051259888071870895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 112000, "agent_timesteps_total": 112000, "timers": {"sample_time_ms": 1524.753, "sample_throughput": 2623.375, "load_time_ms": 0.94, "load_throughput": 4254289.482, "learn_time_ms": 2106.407, "learn_throughput": 1898.969, "update_time_ms": 1.505}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.12656250596046448, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08386608958244324, "policy_loss": -0.0053065004758536816, "vf_loss": 0.08907955139875412, "vf_explained_var": 0.9992145299911499, "kl": 0.0007350664818659425, "entropy": 0.02574833296239376, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 112000, "num_agent_steps_sampled": 112000, "num_steps_trained": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 22400, "training_iteration": 28, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-50", "timestamp": 1628628830, "time_this_iter_s": 3.717674970626831, "time_total_s": 114.25716805458069, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 114.25716805458069, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 36.220000000000006, "ram_util_percent": 72.5}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.70487176, "episode_reward_mean": 38.03924508520001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1468849055522602, "mean_inference_ms": 0.5981512220643171, "mean_action_processing_ms": 0.04625261653072043, "mean_env_wait_ms": 0.05112307472180992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 116000, "agent_timesteps_total": 116000, "timers": {"sample_time_ms": 1534.26, "sample_throughput": 2607.12, "load_time_ms": 0.941, "load_throughput": 4248902.396, "learn_time_ms": 2111.346, "learn_throughput": 1894.526, "update_time_ms": 1.519}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.06328125298023224, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0023316394072026014, "policy_loss": -0.007597831077873707, "vf_loss": 0.005225544795393944, "vf_explained_var": 0.9999567270278931, "kl": 0.0006422934238798916, "entropy": 0.016806934028863907, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 116000, "num_agent_steps_sampled": 116000, "num_steps_trained": 116000, "num_agent_steps_trained": 116000}, "done": false, "episodes_total": 23200, "training_iteration": 29, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-54", "timestamp": 1628628834, "time_this_iter_s": 3.6984009742736816, "time_total_s": 117.95556902885437, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 117.95556902885437, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 38.03333333333333, "ram_util_percent": 72.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.0489352991, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1465179123852015, "mean_inference_ms": 0.596707694635906, "mean_action_processing_ms": 0.04613410234272483, "mean_env_wait_ms": 0.050997921225289546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 120000, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 1545.145, "sample_throughput": 2588.753, "load_time_ms": 0.935, "load_throughput": 4279356.205, "learn_time_ms": 2119.666, "learn_throughput": 1887.09, "update_time_ms": 1.537}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.03164062649011612, "cur_lr": 4.999999873689376e-05, "total_loss": -0.004613886121660471, "policy_loss": -0.0050739711150527, "vf_loss": 0.0003465218178462237, "vf_explained_var": 0.9999971985816956, "kl": 0.003589081345126033, "entropy": 0.007287034764885902, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 120000, "num_steps_trained": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 24000, "training_iteration": 30, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-53-58", "timestamp": 1628628838, "time_this_iter_s": 3.756056070327759, "time_total_s": 121.71162509918213, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 121.71162509918213, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 36.31999999999999, "ram_util_percent": 72.34}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.70487176, "episode_reward_mean": 38.04671368940001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14624730077236459, "mean_inference_ms": 0.5952778140340448, "mean_action_processing_ms": 0.04603855033199321, "mean_env_wait_ms": 0.05087721196107849, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 124000, "agent_timesteps_total": 124000, "timers": {"sample_time_ms": 1553.345, "sample_throughput": 2575.088, "load_time_ms": 0.931, "load_throughput": 4294582.501, "learn_time_ms": 2136.014, "learn_throughput": 1872.647, "update_time_ms": 1.58}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.01582031324505806, "cur_lr": 4.999999873689376e-05, "total_loss": -0.002857500920072198, "policy_loss": -0.004527048673480749, "vf_loss": 0.0016610666643828154, "vf_explained_var": 0.9999861717224121, "kl": 0.0005361154326237738, "entropy": 0.0028307868633419275, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 124000, "num_agent_steps_sampled": 124000, "num_steps_trained": 124000, "num_agent_steps_trained": 124000}, "done": false, "episodes_total": 24800, "training_iteration": 31, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-02", "timestamp": 1628628842, "time_this_iter_s": 3.853173017501831, "time_total_s": 125.56479811668396, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 125.56479811668396, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 36.449999999999996, "ram_util_percent": 72.34999999999998}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.04964509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14589990135826222, "mean_inference_ms": 0.5935481040880562, "mean_action_processing_ms": 0.04590903574059814, "mean_env_wait_ms": 0.05072647421712535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 128000, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 1559.708, "sample_throughput": 2564.582, "load_time_ms": 0.935, "load_throughput": 4279465.361, "learn_time_ms": 2133.617, "learn_throughput": 1874.75, "update_time_ms": 1.582}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00791015662252903, "cur_lr": 4.999999873689376e-05, "total_loss": -0.023758701980113983, "policy_loss": -0.024562006816267967, "vf_loss": 0.00016043393407016993, "vf_explained_var": 0.9999988675117493, "kl": 0.08127177506685257, "entropy": 0.15812888741493225, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 25600, "training_iteration": 32, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-05", "timestamp": 1628628845, "time_this_iter_s": 3.6380438804626465, "time_total_s": 129.2028419971466, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 129.2028419971466, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 36.67999999999999, "ram_util_percent": 72.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 37.63222160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 36.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 36.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 32.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 35.05, 38.05, 38.05, 36.05, 38.05, 37.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 31.049999999999997, 38.05, 38.05, 37.05, 38.05, 36.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 36.05, 37.05, 37.05, 36.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 31.049999999999997, 32.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 34.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 37.05, 38.05, 38.05, 37.05, 38.05, 35.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 31.049999999999997, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 36.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14549304773564742, "mean_inference_ms": 0.5918054573030299, "mean_action_processing_ms": 0.045774994495267174, "mean_env_wait_ms": 0.05058791897112349, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 132000, "agent_timesteps_total": 132000, "timers": {"sample_time_ms": 1557.8, "sample_throughput": 2567.724, "load_time_ms": 0.929, "load_throughput": 4307483.119, "learn_time_ms": 2139.697, "learn_throughput": 1869.423, "update_time_ms": 1.566}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.01186523400247097, "cur_lr": 4.999999873689376e-05, "total_loss": 0.4554063081741333, "policy_loss": -0.04322363808751106, "vf_loss": 0.4983152151107788, "vf_explained_var": 0.9954564571380615, "kl": 0.026530258357524872, "entropy": 0.09452240914106369, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 132000, "num_agent_steps_sampled": 132000, "num_steps_trained": 132000, "num_agent_steps_trained": 132000}, "done": false, "episodes_total": 26400, "training_iteration": 33, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-09", "timestamp": 1628628849, "time_this_iter_s": 3.840420961380005, "time_total_s": 133.0432629585266, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 133.0432629585266, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 37.38000000000001, "ram_util_percent": 72.66000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 37.88250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 37.05, 38.05, 38.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14560346496387258, "mean_inference_ms": 0.5923096368359153, "mean_action_processing_ms": 0.045820649281205286, "mean_env_wait_ms": 0.050626758813798425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 136000, "agent_timesteps_total": 136000, "timers": {"sample_time_ms": 1579.069, "sample_throughput": 2533.138, "load_time_ms": 0.938, "load_throughput": 4264237.495, "learn_time_ms": 2165.234, "learn_throughput": 1847.376, "update_time_ms": 1.569}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.01779785193502903, "cur_lr": 4.999999873689376e-05, "total_loss": 0.2056225836277008, "policy_loss": -0.02761963941156864, "vf_loss": 0.23204047977924347, "vf_explained_var": 0.9979413151741028, "kl": 0.06752176582813263, "entropy": 0.008466632105410099, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 136000, "num_agent_steps_sampled": 136000, "num_steps_trained": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 27200, "training_iteration": 34, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-13", "timestamp": 1628628853, "time_this_iter_s": 4.122567176818848, "time_total_s": 137.16583013534546, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 137.16583013534546, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 40.6, "ram_util_percent": 73.38333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14551315707337253, "mean_inference_ms": 0.5920882058214119, "mean_action_processing_ms": 0.04579441351314348, "mean_env_wait_ms": 0.05060358814909735, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 140000, "agent_timesteps_total": 140000, "timers": {"sample_time_ms": 1597.995, "sample_throughput": 2503.137, "load_time_ms": 0.943, "load_throughput": 4242563.156, "learn_time_ms": 2187.867, "learn_throughput": 1828.264, "update_time_ms": 1.609}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.02669677697122097, "cur_lr": 4.999999873689376e-05, "total_loss": 0.002002541907131672, "policy_loss": -0.0007823595078662038, "vf_loss": 0.002775792730972171, "vf_explained_var": 0.9999753832817078, "kl": 0.00034170501749031246, "entropy": 0.004580159205943346, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 140000, "num_steps_trained": 140000, "num_agent_steps_trained": 140000}, "done": false, "episodes_total": 28000, "training_iteration": 35, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-17", "timestamp": 1628628857, "time_this_iter_s": 3.9835808277130127, "time_total_s": 141.14941096305847, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 141.14941096305847, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 39.78333333333333, "ram_util_percent": 73.13333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.70487176, "episode_reward_mean": 38.04456858970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1454467771848065, "mean_inference_ms": 0.5919157956216426, "mean_action_processing_ms": 0.04578661407702972, "mean_env_wait_ms": 0.05058838035316576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 144000, "agent_timesteps_total": 144000, "timers": {"sample_time_ms": 1617.724, "sample_throughput": 2472.61, "load_time_ms": 0.944, "load_throughput": 4235494.181, "learn_time_ms": 2176.984, "learn_throughput": 1837.404, "update_time_ms": 1.589}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.013348388485610485, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0016377209685742855, "policy_loss": -0.005116317421197891, "vf_loss": 0.003466889262199402, "vf_explained_var": 0.9999687075614929, "kl": 0.00087715097470209, "entropy": 0.0013970911968499422, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 144000, "num_agent_steps_sampled": 144000, "num_steps_trained": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 28800, "training_iteration": 36, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-21", "timestamp": 1628628861, "time_this_iter_s": 3.799100875854492, "time_total_s": 144.94851183891296, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 144.94851183891296, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 39.05, "ram_util_percent": 73.25000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14538029635545846, "mean_inference_ms": 0.591676461790219, "mean_action_processing_ms": 0.045777865338055834, "mean_env_wait_ms": 0.05057265914096533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 148000, "agent_timesteps_total": 148000, "timers": {"sample_time_ms": 1621.617, "sample_throughput": 2466.673, "load_time_ms": 0.957, "load_throughput": 4179050.466, "learn_time_ms": 2565.074, "learn_throughput": 1559.409, "update_time_ms": 5.654}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0066741942428052425, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0005632064421661198, "policy_loss": -0.0005633992259390652, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 2.9066673960187472e-05, "entropy": 0.0008019946981221437, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 148000, "num_agent_steps_sampled": 148000, "num_steps_trained": 148000, "num_agent_steps_trained": 148000}, "done": false, "episodes_total": 29600, "training_iteration": 37, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-29", "timestamp": 1628628869, "time_this_iter_s": 7.767152309417725, "time_total_s": 152.7156641483307, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 152.7156641483307, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 58.589999999999996, "ram_util_percent": 79.53}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1465850838786563, "mean_inference_ms": 0.5971963771921911, "mean_action_processing_ms": 0.04753043978743264, "mean_env_wait_ms": 0.050995274940021214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 152000, "agent_timesteps_total": 152000, "timers": {"sample_time_ms": 1708.599, "sample_throughput": 2341.1, "load_time_ms": 1.043, "load_throughput": 3835318.215, "learn_time_ms": 2588.699, "learn_throughput": 1545.178, "update_time_ms": 5.676}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0033370971214026213, "cur_lr": 4.999999873689376e-05, "total_loss": -1.6474084986839443e-05, "policy_loss": -1.6474443327751942e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.6309566319705482e-07, "entropy": 0.000834039703477174, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 152000, "num_agent_steps_sampled": 152000, "num_steps_trained": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 30400, "training_iteration": 38, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-35", "timestamp": 1628628875, "time_this_iter_s": 4.82526421546936, "time_total_s": 157.54092836380005, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 157.54092836380005, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 53.425, "ram_util_percent": 81.7125}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.05, "episode_reward_mean": 38.04750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1473446961902697, "mean_inference_ms": 0.5992855671557051, "mean_action_processing_ms": 0.047627613285599876, "mean_env_wait_ms": 0.051144462318228216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 156000, "agent_timesteps_total": 156000, "timers": {"sample_time_ms": 1747.146, "sample_throughput": 2289.448, "load_time_ms": 1.05, "load_throughput": 3809367.422, "learn_time_ms": 2597.276, "learn_throughput": 1540.075, "update_time_ms": 5.685}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0016685485607013106, "cur_lr": 4.999999873689376e-05, "total_loss": 0.003481346881017089, "policy_loss": -0.0018952366663143039, "vf_loss": 0.005376547109335661, "vf_explained_var": 0.9999574422836304, "kl": 2.0808771296287887e-05, "entropy": 0.0005132497171871364, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 156000, "num_agent_steps_sampled": 156000, "num_steps_trained": 156000, "num_agent_steps_trained": 156000}, "done": false, "episodes_total": 31200, "training_iteration": 39, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-39", "timestamp": 1628628879, "time_this_iter_s": 4.169990062713623, "time_total_s": 161.71091842651367, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 161.71091842651367, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 44.65, "ram_util_percent": 75.81666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14722378700578587, "mean_inference_ms": 0.5990182311398895, "mean_action_processing_ms": 0.047575226292127556, "mean_env_wait_ms": 0.05111708521665635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 160000, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 1756.563, "sample_throughput": 2277.175, "load_time_ms": 1.056, "load_throughput": 3787352.928, "learn_time_ms": 2602.306, "learn_throughput": 1537.099, "update_time_ms": 5.7}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0008342742803506553, "cur_lr": 4.999999873689376e-05, "total_loss": 0.0005072400672361255, "policy_loss": -0.0008736714371480048, "vf_loss": 0.0013808170333504677, "vf_explained_var": 0.9999882578849792, "kl": 0.00011712817649822682, "entropy": 0.001675889827311039, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 160000, "num_steps_trained": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 32000, "training_iteration": 40, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-43", "timestamp": 1628628883, "time_this_iter_s": 3.9012279510498047, "time_total_s": 165.61214637756348, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 165.61214637756348, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 40.62, "ram_util_percent": 74.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.52124776, "episode_reward_mean": 38.04683905970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.52124776, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14704181293724758, "mean_inference_ms": 0.5983961388677538, "mean_action_processing_ms": 0.04749673542235721, "mean_env_wait_ms": 0.0510692139956761, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 164000, "agent_timesteps_total": 164000, "timers": {"sample_time_ms": 1761.467, "sample_throughput": 2270.835, "load_time_ms": 1.069, "load_throughput": 3741323.283, "learn_time_ms": 2599.607, "learn_throughput": 1538.694, "update_time_ms": 5.674}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00041713714017532766, "cur_lr": 4.999999873689376e-05, "total_loss": 0.00016167598369065672, "policy_loss": -0.0028276245575398207, "vf_loss": 0.002989070722833276, "vf_explained_var": 0.9999740123748779, "kl": 0.0005444107810035348, "entropy": 0.003598085604608059, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 164000, "num_agent_steps_sampled": 164000, "num_steps_trained": 164000, "num_agent_steps_trained": 164000}, "done": false, "episodes_total": 32800, "training_iteration": 41, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-47", "timestamp": 1628628887, "time_this_iter_s": 3.875433921813965, "time_total_s": 169.48758029937744, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 169.48758029937744, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 40.36666666666667, "ram_util_percent": 74.66666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14673366306625682, "mean_inference_ms": 0.5972121275912705, "mean_action_processing_ms": 0.0473809420208856, "mean_env_wait_ms": 0.05096890875527443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 168000, "agent_timesteps_total": 168000, "timers": {"sample_time_ms": 1762.967, "sample_throughput": 2268.902, "load_time_ms": 1.076, "load_throughput": 3716295.492, "learn_time_ms": 2610.593, "learn_throughput": 1532.219, "update_time_ms": 5.678}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00020856857008766383, "cur_lr": 4.999999873689376e-05, "total_loss": -0.14406979084014893, "policy_loss": -0.14416314661502838, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 0.44758090376853943, "entropy": 0.49422314763069153, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 168000, "num_agent_steps_sampled": 168000, "num_steps_trained": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 33600, "training_iteration": 42, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-50", "timestamp": 1628628890, "time_this_iter_s": 3.7631962299346924, "time_total_s": 173.25077652931213, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 173.25077652931213, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 38.160000000000004, "ram_util_percent": 74.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 34.049955855300006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.049999999999997, 32.05, 37.827287760000004, 38.05, 35.05, 37.827287760000004, 38.05, 33.05, 37.827287760000004, 38.05, 38.05, 33.05, 38.05, 36.05, 33.05, 37.05, 37.827287760000004, 33.05, 37.827287760000004, 32.05, 33.05, 31.049999999999997, 32.05, 36.05, 32.05, 33.05, 32.05, 32.05, 37.05, 36.05, 34.05, 38.05, 33.05, 33.05, 36.05, 32.05, 35.05, 33.05, 33.05, 38.05, 32.05, 33.05, 37.05, 38.05, 33.05, 35.05, 33.05, 32.05, 35.05, 32.05, 30.049999999999997, 33.05, 33.05, 38.05, 32.05, 33.05, 32.05, 37.05, 38.05, 37.827287760000004, 38.05, 33.05, 32.05, 32.05, 38.05, 32.05, 33.05, 32.05, 33.05, 33.05, 32.05, 31.049999999999997, 33.05, 30.049999999999997, 38.05, 31.049999999999997, 37.827287760000004, 33.05, 32.05, 37.05, 33.05, 32.05, 32.05, 33.05, 37.827287760000004, 33.05, 36.05, 32.05, 31.049999999999997, 38.05, 33.05, 37.05, 35.05, 32.05, 30.049999999999997, 36.05, 31.049999999999997, 38.05, 32.05, 31.049999999999997, 33.05, 32.05, 36.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 35.05, 33.05, 29.049999999999997, 33.05, 33.05, 37.827287760000004, 33.05, 37.05, 32.05, 33.05, 33.05, 32.05, 33.05, 38.05, 32.05, 32.05, 33.05, 37.827287760000004, 33.05, 36.05, 33.05, 31.049999999999997, 33.05, 33.05, 33.05, 33.05, 32.05, 33.05, 31.049999999999997, 33.05, 38.05, 33.05, 32.05, 32.05, 37.827287760000004, 33.05, 35.05, 32.05, 33.05, 33.05, 33.05, 33.05, 37.05, 37.827287760000004, 37.05, 33.05, 35.05, 33.05, 36.05, 32.05, 37.05, 38.05, 37.05, 33.05, 37.827287760000004, 36.05, 32.05, 36.05, 32.05, 30.049999999999997, 36.05, 32.05, 38.05, 32.05, 33.05, 32.05, 33.05, 35.05, 37.05, 37.827287760000004, 36.05, 32.05, 38.05, 33.05, 33.05, 32.05, 38.05, 35.05, 33.05, 33.05, 33.05, 32.05, 33.05, 33.05, 36.05, 37.05, 36.05, 33.05, 33.05, 31.049999999999997, 33.05, 32.05, 32.05, 33.05, 32.05, 35.05, 38.05, 37.827287760000004, 32.05, 38.05, 32.05, 33.05, 37.827287760000004, 37.827287760000004, 33.05, 38.05, 33.05, 33.05, 37.827287760000004, 35.05, 32.05, 33.05, 38.05, 31.049999999999997, 35.05, 33.05, 33.05, 38.05, 31.049999999999997, 37.05, 33.05, 33.05, 37.05, 37.827287760000004, 35.05, 38.05, 32.05, 38.05, 33.05, 32.05, 32.05, 32.05, 32.05, 33.05, 33.05, 33.05, 38.05, 32.05, 32.05, 36.05, 37.827287760000004, 32.05, 35.05, 33.05, 32.05, 32.05, 33.05, 32.05, 32.05, 38.05, 32.05, 33.05, 32.05, 36.05, 38.05, 33.05, 32.05, 32.05, 32.05, 35.05, 32.05, 32.05, 33.05, 38.05, 33.05, 32.05, 37.05, 33.05, 38.05, 33.05, 35.05, 32.05, 30.049999999999997, 33.05, 37.05, 38.05, 36.05, 32.05, 31.049999999999997, 38.05, 33.05, 29.049999999999997, 37.05, 33.05, 33.05, 35.05, 32.05, 38.05, 32.05, 32.05, 33.05, 33.05, 37.827287760000004, 32.05, 38.05, 38.05, 33.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 33.05, 33.05, 38.05, 32.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 37.05, 32.05, 33.05, 32.05, 32.05, 37.827287760000004, 33.05, 33.05, 37.05, 33.05, 36.05, 33.05, 33.05, 38.05, 38.05, 37.05, 32.05, 33.05, 32.05, 33.05, 37.827287760000004, 38.05, 33.05, 33.05, 33.05, 33.05, 37.827287760000004, 36.05, 32.05, 33.05, 33.05, 33.05, 32.05, 37.76607976, 38.05, 33.05, 37.05, 32.05, 33.05, 33.05, 32.05, 32.05, 29.049999999999997, 32.05, 33.05, 32.05, 32.05, 33.05, 33.05, 33.05, 32.05, 37.827287760000004, 32.05, 33.05, 36.05, 32.05, 37.827287760000004, 37.827287760000004, 29.049999999999997, 33.05, 32.05, 33.05, 33.05, 32.05, 33.05, 32.05, 33.05, 33.05, 32.05, 33.05, 32.05, 33.05, 33.05, 33.05, 38.05, 32.05, 32.05, 32.05, 33.05, 32.05, 32.05, 32.05, 32.05, 33.05, 33.05, 32.05, 35.05, 32.05, 31.049999999999997, 36.05, 32.05, 33.05, 34.05, 35.05, 37.827287760000004, 31.049999999999997, 35.05, 33.05, 38.05, 37.05, 36.05, 38.05, 32.05, 33.05, 35.05, 32.05, 35.05, 38.05, 31.049999999999997, 32.05, 32.05, 37.827287760000004, 33.05, 35.05, 33.05, 35.05, 32.05, 32.05, 30.049999999999997, 38.05, 37.05, 38.05, 32.05, 32.05, 33.05, 33.05, 37.827287760000004, 33.05, 37.827287760000004, 32.05, 32.05, 36.05, 33.05, 37.05, 32.05, 33.05, 38.05, 33.05, 32.05, 29.049999999999997, 37.05, 33.05, 32.05, 32.05, 38.05, 33.05, 33.05, 33.05, 31.049999999999997, 35.05, 33.05, 32.05, 33.05, 38.05, 33.05, 36.05, 32.05, 36.05, 33.05, 32.05, 38.05, 33.05, 37.827287760000004, 33.05, 37.05, 33.05, 33.05, 38.05, 34.05, 33.05, 33.05, 35.05, 33.05, 38.05, 33.05, 32.05, 31.049999999999997, 33.05, 33.05, 33.05, 33.05, 32.05, 29.049999999999997, 38.05, 32.05, 33.05, 32.05, 32.05, 38.05, 35.05, 32.05, 33.05, 33.05, 33.05, 38.05, 38.05, 37.05, 37.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 37.05, 33.05, 29.049999999999997, 33.05, 33.05, 32.05, 32.05, 33.05, 32.05, 33.05, 32.05, 35.05, 33.05, 32.05, 32.05, 38.05, 36.05, 38.05, 36.05, 32.05, 32.05, 37.05, 32.05, 38.05, 33.05, 38.05, 38.05, 32.05, 34.05, 38.05, 37.05, 33.05, 33.05, 37.05, 37.827287760000004, 33.05, 32.05, 31.049999999999997, 33.05, 36.05, 38.05, 33.05, 32.05, 32.05, 38.05, 33.05, 32.05, 37.827287760000004, 33.05, 32.05, 32.05, 30.049999999999997, 32.05, 38.05, 31.049999999999997, 32.05, 32.05, 31.049999999999997, 29.049999999999997, 33.05, 33.05, 37.05, 33.05, 33.05, 31.049999999999997, 38.05, 32.05, 38.05, 38.05, 37.827287760000004, 38.05, 32.05, 33.05, 36.05, 36.05, 37.827287760000004, 38.05, 32.05, 33.05, 37.05, 33.05, 33.05, 33.05, 37.05, 33.05, 37.05, 32.05, 33.05, 32.05, 37.827287760000004, 32.05, 32.05, 33.05, 30.049999999999997, 37.05, 38.05, 33.05, 37.05, 33.05, 35.05, 33.05, 36.05, 37.827287760000004, 33.05, 33.05, 32.05, 32.05, 33.05, 33.05, 33.05, 33.05, 37.05, 37.05, 30.049999999999997, 32.05, 33.05, 33.05, 32.05, 33.05, 33.05, 33.05, 32.05, 37.827287760000004, 37.827287760000004, 33.05, 33.05, 38.05, 32.05, 32.05, 36.05, 35.05, 31.049999999999997, 31.049999999999997, 33.05, 37.827287760000004, 33.05, 37.05, 32.05, 32.05, 32.05, 33.05, 35.05, 36.05, 37.05, 32.05, 32.05, 33.05, 32.05, 33.05, 36.05, 36.05, 33.05, 33.05, 32.05, 36.05, 32.05, 38.05, 33.05, 32.05, 32.05, 32.05, 32.05, 32.05, 33.05, 37.05, 33.05, 32.05, 32.05, 32.05, 32.05, 32.05, 33.05, 31.049999999999997, 33.05, 33.05, 33.05, 33.05, 32.05, 37.05, 33.05, 33.05, 33.05, 32.05, 36.05, 33.05, 35.05, 32.05, 33.05, 32.05, 32.05, 33.05, 32.05, 35.05, 32.05, 33.05, 37.05, 35.05, 32.05, 35.05, 32.05, 37.05, 33.05, 33.05, 37.827287760000004, 35.05, 34.05, 32.05, 32.05, 32.05, 33.05, 37.76607976, 33.05, 33.05, 32.05, 33.05, 32.05, 32.05, 38.05, 36.05, 33.05, 33.05, 37.827287760000004, 36.05, 35.05, 36.05, 36.05, 30.049999999999997, 38.05, 32.05, 32.05, 38.05, 38.05, 30.049999999999997, 33.05, 32.05, 36.05, 38.05, 38.05, 33.05, 37.05, 35.05, 33.05, 32.05, 37.827287760000004, 33.05, 38.05, 32.05, 33.05, 32.05, 33.05, 33.05, 31.049999999999997, 31.049999999999997, 32.05, 35.05, 32.05, 36.05, 32.05, 37.827287760000004, 38.05, 38.05, 33.05, 33.05, 35.05, 35.05, 33.05, 33.05, 32.05, 38.05, 33.05, 30.049999999999997], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146459923795644, "mean_inference_ms": 0.5961377055623838, "mean_action_processing_ms": 0.04727911172088522, "mean_env_wait_ms": 0.05088638307615745, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 172000, "agent_timesteps_total": 172000, "timers": {"sample_time_ms": 1767.233, "sample_throughput": 2263.425, "load_time_ms": 1.091, "load_throughput": 3667952.777, "learn_time_ms": 2601.756, "learn_throughput": 1537.423, "update_time_ms": 5.668}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00031285284785553813, "cur_lr": 4.999999873689376e-05, "total_loss": 3.8400485515594482, "policy_loss": -0.06931442767381668, "vf_loss": 3.909294605255127, "vf_explained_var": 0.9531447291374207, "kl": 0.21906167268753052, "entropy": 0.39197370409965515, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 172000, "num_agent_steps_sampled": 172000, "num_steps_trained": 172000, "num_agent_steps_trained": 172000}, "done": false, "episodes_total": 34400, "training_iteration": 43, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-54", "timestamp": 1628628894, "time_this_iter_s": 3.792978048324585, "time_total_s": 177.04375457763672, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 177.04375457763672, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 38.0, "ram_util_percent": 74.85999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 36.9311334362, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.827287760000004, 37.827287760000004, 38.05, 38.05, 33.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 36.05, 38.05, 35.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 36.05, 34.05, 37.05, 35.05, 37.827287760000004, 37.05, 37.05, 37.05, 33.05, 35.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 33.05, 37.827287760000004, 37.05, 37.05, 36.05, 38.05, 37.827287760000004, 33.05, 37.827287760000004, 34.05, 37.05, 37.827287760000004, 35.05, 38.05, 33.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 36.05, 38.05, 38.05, 38.05, 37.05, 37.05, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 33.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 32.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 36.05, 32.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 36.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 33.05, 37.827287760000004, 38.05, 36.05, 38.05, 37.05, 38.05, 35.05, 37.827287760000004, 37.05, 38.05, 37.05, 32.05, 37.05, 38.05, 33.05, 37.827287760000004, 38.05, 29.049999999999997, 37.827287760000004, 37.76607976, 38.05, 37.05, 38.05, 36.05, 33.05, 37.05, 38.05, 31.049999999999997, 38.05, 31.049999999999997, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 35.05, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 36.05, 37.827287760000004, 35.05, 38.05, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 36.05, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 35.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 35.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 35.05, 36.05, 37.827287760000004, 37.05, 37.827287760000004, 36.05, 38.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 32.05, 37.827287760000004, 37.05, 37.05, 33.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 33.05, 33.05, 37.827287760000004, 35.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 36.05, 36.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 35.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 33.05, 37.827287760000004, 38.05, 38.05, 36.05, 37.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 34.05, 38.05, 36.05, 37.827287760000004, 36.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.049999999999997, 37.827287760000004, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 33.05, 38.05, 38.05, 37.827287760000004, 36.05, 37.827287760000004, 33.05, 37.05, 37.05, 37.827287760000004, 31.049999999999997, 37.827287760000004, 37.827287760000004, 38.05, 36.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 31.049999999999997, 36.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 36.05, 35.05, 35.05, 38.05, 37.05, 36.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 35.05, 35.05, 33.05, 35.05, 38.05, 37.05, 37.827287760000004, 35.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 38.05, 33.05, 37.827287760000004, 37.05, 37.05, 37.05, 33.05, 37.827287760000004, 38.05, 33.05, 37.827287760000004, 38.05, 37.05, 35.05, 37.05, 37.05, 38.05, 32.05, 38.05, 37.827287760000004, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 33.05, 37.05, 32.05, 38.05, 38.05, 32.05, 38.05, 33.05, 38.05, 36.05, 36.05, 38.05, 35.05, 37.05, 37.827287760000004, 37.827287760000004, 36.05, 35.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 36.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 32.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 33.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 36.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 36.05, 33.05, 38.05, 38.05, 38.05, 36.05, 37.827287760000004, 37.827287760000004, 33.05, 36.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 36.05, 38.05, 37.05, 37.05, 37.827287760000004, 38.05, 35.05, 37.827287760000004, 32.05, 37.05, 37.827287760000004, 35.05, 37.05, 33.05, 37.827287760000004, 35.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 33.05, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 35.05, 35.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 38.05, 33.05, 37.827287760000004, 38.05, 37.827287760000004, 32.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 35.05, 32.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 35.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 36.05, 36.05, 37.827287760000004, 32.05, 36.05, 37.05, 37.827287760000004, 37.05, 36.05, 32.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 35.05, 37.05, 37.05, 38.05, 37.827287760000004, 35.05, 38.05, 37.05, 35.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 33.05, 37.827287760000004, 37.05, 33.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 33.05, 37.827287760000004, 33.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 33.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.827287760000004, 33.05, 37.05, 38.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 32.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 36.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 33.05, 37.827287760000004, 38.05, 38.05, 35.05, 36.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 35.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 33.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 36.05, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 33.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 35.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 36.05, 36.05, 36.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 30.049999999999997, 37.05, 37.05, 37.827287760000004, 36.05, 38.05, 32.05, 37.827287760000004, 38.05, 35.05, 35.05, 38.05, 37.827287760000004, 37.827287760000004, 36.05, 37.827287760000004, 37.05, 36.05, 37.827287760000004, 37.05, 38.05, 32.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 37.05, 32.05, 37.827287760000004, 35.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 33.05, 37.827287760000004, 38.05, 37.827287760000004, 36.05, 37.05, 36.05, 37.827287760000004, 32.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 36.05, 37.827287760000004, 37.05, 37.05, 33.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14618803789108434, "mean_inference_ms": 0.5951880679897439, "mean_action_processing_ms": 0.04718080599025356, "mean_env_wait_ms": 0.050805640236084935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 176000, "agent_timesteps_total": 176000, "timers": {"sample_time_ms": 1750.429, "sample_throughput": 2285.154, "load_time_ms": 1.088, "load_throughput": 3676956.255, "learn_time_ms": 2583.158, "learn_throughput": 1548.492, "update_time_ms": 5.666}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00046927930088713765, "cur_lr": 4.999999873689376e-05, "total_loss": 1.6686674356460571, "policy_loss": -0.10692456364631653, "vf_loss": 1.7754333019256592, "vf_explained_var": 0.9828435778617859, "kl": 0.3379600942134857, "entropy": 0.42278245091438293, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 176000, "num_agent_steps_sampled": 176000, "num_steps_trained": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 35200, "training_iteration": 44, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-54-58", "timestamp": 1628628898, "time_this_iter_s": 3.7678658962249756, "time_total_s": 180.8116204738617, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 180.8116204738617, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 38.96666666666667, "ram_util_percent": 74.93333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 36.627905512800005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 37.05, 37.827287760000004, 37.05, 35.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 35.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 35.05, 37.05, 37.05, 36.05, 36.05, 36.05, 35.05, 37.05, 37.05, 37.05, 38.05, 37.05, 35.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 35.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.80647976, 37.05, 36.05, 35.05, 37.05, 36.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 35.05, 36.05, 37.05, 33.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 38.05, 36.05, 38.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 38.05, 37.05, 35.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 38.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 35.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.80647976, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 34.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 36.05, 36.05, 35.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 35.05, 37.05, 37.05, 37.05, 38.05, 35.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 35.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 35.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 35.05, 36.05, 36.05, 35.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.05, 36.05, 36.05, 37.05, 35.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 35.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 38.05, 36.05, 37.05, 38.05, 37.80647976, 37.05, 37.05, 35.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 38.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 34.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 35.05, 36.05, 37.05, 35.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.80647976, 37.05, 37.05, 36.05, 35.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 35.05, 36.05, 36.05, 37.05, 36.05, 37.05, 35.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 35.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.80647976, 36.05, 37.05, 36.05, 37.05, 36.05, 35.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 35.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.05, 36.05, 35.05, 36.05, 38.05, 36.05, 33.05, 37.05, 37.05, 35.05, 36.05, 36.05, 38.05, 33.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 35.05, 38.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 35.68406376, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 35.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 36.05, 35.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.80647976, 37.05, 36.05, 35.05, 36.05, 36.05, 38.05, 38.05, 36.05, 36.05, 35.05, 37.05, 37.80647976, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.827287760000004, 36.05, 37.80647976, 35.05, 37.05, 36.05, 38.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.80647976, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 35.05, 36.05, 36.05, 37.05, 37.05, 37.827287760000004, 34.05, 35.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 38.05, 36.05, 38.05, 37.05, 36.05, 38.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 35.05, 36.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 35.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14590966439382494, "mean_inference_ms": 0.5942109563578737, "mean_action_processing_ms": 0.04707790359115774, "mean_env_wait_ms": 0.05071948440091796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 180000, "agent_timesteps_total": 180000, "timers": {"sample_time_ms": 1739.78, "sample_throughput": 2299.141, "load_time_ms": 1.089, "load_throughput": 3672690.178, "learn_time_ms": 2572.751, "learn_throughput": 1554.756, "update_time_ms": 5.639}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.000703918922226876, "cur_lr": 4.999999873689376e-05, "total_loss": 0.477260947227478, "policy_loss": -0.08625033497810364, "vf_loss": 0.5633648037910461, "vf_explained_var": 0.9944042563438416, "kl": 0.20805184543132782, "entropy": 0.3521939516067505, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 180000, "num_steps_trained": 180000, "num_agent_steps_trained": 180000}, "done": false, "episodes_total": 36000, "training_iteration": 45, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-02", "timestamp": 1628628902, "time_this_iter_s": 3.77200984954834, "time_total_s": 184.58363032341003, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 184.58363032341003, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 37.61999999999999, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 37.4444891283, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 36.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 35.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.80647976, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.76607976, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 36.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.80647976, 38.05, 38.05, 36.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 35.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 36.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 36.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 30.049999999999997, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.80647976, 37.05, 38.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 36.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.80647976, 38.05, 37.05, 37.05, 37.80647976, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 35.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 29.049999999999997, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.80647976, 37.827287760000004, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 36.05, 36.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 36.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 36.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14560503749279566, "mean_inference_ms": 0.5930166275811891, "mean_action_processing_ms": 0.046969558869733384, "mean_env_wait_ms": 0.05062369592508463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 184000, "agent_timesteps_total": 184000, "timers": {"sample_time_ms": 1725.705, "sample_throughput": 2317.894, "load_time_ms": 1.086, "load_throughput": 3682525.077, "learn_time_ms": 2576.285, "learn_throughput": 1552.623, "update_time_ms": 5.632}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0010558783542364836, "cur_lr": 4.999999873689376e-05, "total_loss": 0.3399932086467743, "policy_loss": -0.06320195645093918, "vf_loss": 0.40311968326568604, "vf_explained_var": 0.9962383508682251, "kl": 0.07153181731700897, "entropy": 0.30879533290863037, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 184000, "num_agent_steps_sampled": 184000, "num_steps_trained": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 36800, "training_iteration": 46, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-06", "timestamp": 1628628906, "time_this_iter_s": 3.6941471099853516, "time_total_s": 188.27777743339539, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 188.27777743339539, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 39.050000000000004, "ram_util_percent": 74.89999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 37.77498412970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.76607976, 38.05, 37.05, 37.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.80647976, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.80647976, 38.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.76607976, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.80647976, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.80647976, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.80647976, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.80647976, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.76607976, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.80647976, 38.05, 38.05, 37.05, 37.827287760000004, 37.80647976, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.05, 37.80647976, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.80647976, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 37.80647976, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.80647976, 37.80647976, 37.76607976, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.80647976, 38.05, 37.80647976, 37.05, 38.05, 37.80647976, 38.05, 38.05, 37.80647976, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 38.05, 37.80647976, 37.05, 37.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 37.80647976, 38.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.76607976, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.80647976, 38.05, 38.05, 38.05, 37.80647976, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.80647976, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.76607976, 38.05, 38.05, 37.05, 37.05, 37.80647976, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.80647976, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 37.05, 38.05, 37.80647976, 37.827287760000004, 37.05, 38.05, 38.05, 37.80647976, 37.05, 37.05, 38.05, 37.05, 37.05, 37.76607976, 38.05, 37.05, 37.827287760000004, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.76607976, 38.05, 37.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 38.05, 37.80647976, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.80647976, 38.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.80647976, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.76607976, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.80647976, 37.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.05, 38.05, 38.05, 37.80647976, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 38.05, 37.80647976, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.76607976, 37.80647976, 37.827287760000004, 37.80647976, 38.05, 38.05, 38.05, 37.80647976, 38.05, 37.80647976, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.05, 37.80647976, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14543147167296272, "mean_inference_ms": 0.592474196776701, "mean_action_processing_ms": 0.04690640216251582, "mean_env_wait_ms": 0.05058236158198115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 188000, "agent_timesteps_total": 188000, "timers": {"sample_time_ms": 1721.236, "sample_throughput": 2323.911, "load_time_ms": 1.078, "load_throughput": 3711362.902, "learn_time_ms": 2195.975, "learn_throughput": 1821.515, "update_time_ms": 1.567}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0015838176477700472, "cur_lr": 4.999999873689376e-05, "total_loss": 0.11707396060228348, "policy_loss": -0.04806598648428917, "vf_loss": 0.1650087684392929, "vf_explained_var": 0.9985551238059998, "kl": 0.0828263983130455, "entropy": 0.1864706575870514, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 188000, "num_agent_steps_sampled": 188000, "num_steps_trained": 188000, "num_agent_steps_trained": 188000}, "done": false, "episodes_total": 37600, "training_iteration": 47, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-09", "timestamp": 1628628909, "time_this_iter_s": 3.801032066345215, "time_total_s": 192.0788094997406, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 192.0788094997406, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 38.14, "ram_util_percent": 75.02000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 37.9631460753, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 36.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.80647976, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.80647976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 36.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.80647976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.80647976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.80647976, 35.703655760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 37.80647976, 37.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.80647976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.76607976, 38.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.80647976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.80647976, 38.05, 37.76607976, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1451346930389018, "mean_inference_ms": 0.5913756827280134, "mean_action_processing_ms": 0.04680129066397588, "mean_env_wait_ms": 0.05048626846383572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 192000, "agent_timesteps_total": 192000, "timers": {"sample_time_ms": 1636.276, "sample_throughput": 2444.576, "load_time_ms": 0.992, "load_throughput": 4030659.235, "learn_time_ms": 2165.323, "learn_throughput": 1847.299, "update_time_ms": 1.528}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.002375726355239749, "cur_lr": 4.999999873689376e-05, "total_loss": 0.012306715361773968, "policy_loss": -0.042900823056697845, "vf_loss": 0.05488105118274689, "vf_explained_var": 0.9995131492614746, "kl": 0.13742686808109283, "entropy": 0.07081294804811478, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 192000, "num_agent_steps_sampled": 192000, "num_steps_trained": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 38400, "training_iteration": 48, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-13", "timestamp": 1628628913, "time_this_iter_s": 3.66629695892334, "time_total_s": 195.74510645866394, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 195.74510645866394, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 37.6, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 38.03222160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14488428663540134, "mean_inference_ms": 0.5903729767124563, "mean_action_processing_ms": 0.0467053313733164, "mean_env_wait_ms": 0.0504067907007279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 196000, "agent_timesteps_total": 196000, "timers": {"sample_time_ms": 1595.423, "sample_throughput": 2507.172, "load_time_ms": 0.987, "load_throughput": 4051880.404, "learn_time_ms": 2163.276, "learn_throughput": 1849.047, "update_time_ms": 1.514}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0035635896492749453, "cur_lr": 4.999999873689376e-05, "total_loss": 0.05031078681349754, "policy_loss": -0.0053881146013736725, "vf_loss": 0.05569319427013397, "vf_explained_var": 0.9995276927947998, "kl": 0.0016048421384766698, "entropy": 0.004439207725226879, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 196000, "num_agent_steps_sampled": 196000, "num_steps_trained": 196000, "num_agent_steps_trained": 196000}, "done": false, "episodes_total": 39200, "training_iteration": 49, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-17", "timestamp": 1628628917, "time_this_iter_s": 3.7402679920196533, "time_total_s": 199.4853744506836, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 199.4853744506836, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 38.21666666666667, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04839509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14462905259558245, "mean_inference_ms": 0.5895036970193044, "mean_action_processing_ms": 0.046615375234950046, "mean_env_wait_ms": 0.05033016180992366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 200000, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 1582.82, "sample_throughput": 2527.136, "load_time_ms": 0.984, "load_throughput": 4067105.282, "learn_time_ms": 2156.703, "learn_throughput": 1854.683, "update_time_ms": 1.481}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0017817948246374726, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0018269516294822097, "policy_loss": -0.0030706357210874557, "vf_loss": 0.0012435598764568567, "vf_explained_var": 0.9999893307685852, "kl": 6.547501834575087e-05, "entropy": 0.003003104589879513, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 200000, "num_steps_trained": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 40000, "training_iteration": 50, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-21", "timestamp": 1628628921, "time_this_iter_s": 3.707766056060791, "time_total_s": 203.19314050674438, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 203.19314050674438, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 37.06, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 38.04339509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1443210119682252, "mean_inference_ms": 0.5882878690182878, "mean_action_processing_ms": 0.046508064295824575, "mean_env_wait_ms": 0.05022849832424596, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 204000, "agent_timesteps_total": 204000, "timers": {"sample_time_ms": 1569.289, "sample_throughput": 2548.924, "load_time_ms": 0.975, "load_throughput": 4102410.016, "learn_time_ms": 2148.958, "learn_throughput": 1861.367, "update_time_ms": 1.488}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0008908974123187363, "cur_lr": 4.999999873689376e-05, "total_loss": 0.027301549911499023, "policy_loss": -0.0021631564013659954, "vf_loss": 0.029464654624462128, "vf_explained_var": 0.999747097492218, "kl": 5.757524922955781e-05, "entropy": 0.0017537071835249662, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 204000, "num_agent_steps_sampled": 204000, "num_steps_trained": 204000, "num_agent_steps_trained": 204000}, "done": false, "episodes_total": 40800, "training_iteration": 51, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-24", "timestamp": 1628628924, "time_this_iter_s": 3.6624808311462402, "time_total_s": 206.85562133789062, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 206.85562133789062, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 37.62, "ram_util_percent": 74.5}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14409558273123083, "mean_inference_ms": 0.5874686813761634, "mean_action_processing_ms": 0.04642223920046465, "mean_env_wait_ms": 0.0501570555477447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 208000, "agent_timesteps_total": 208000, "timers": {"sample_time_ms": 1568.321, "sample_throughput": 2550.498, "load_time_ms": 0.968, "load_throughput": 4133744.641, "learn_time_ms": 2145.248, "learn_throughput": 1864.586, "update_time_ms": 1.486}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00044544870615936816, "cur_lr": 4.999999873689376e-05, "total_loss": 0.00047645214363001287, "policy_loss": 0.000476404296932742, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 0.00010954567551380023, "entropy": 0.0006720756064169109, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 208000, "num_agent_steps_sampled": 208000, "num_steps_trained": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 41600, "training_iteration": 52, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-28", "timestamp": 1628628928, "time_this_iter_s": 3.71628999710083, "time_total_s": 210.57191133499146, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 210.57191133499146, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 37.81666666666666, "ram_util_percent": 74.33333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1438607148503993, "mean_inference_ms": 0.586480208441257, "mean_action_processing_ms": 0.04633141614796063, "mean_env_wait_ms": 0.05008183772057343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 212000, "agent_timesteps_total": 212000, "timers": {"sample_time_ms": 1563.478, "sample_throughput": 2558.398, "load_time_ms": 0.951, "load_throughput": 4204183.832, "learn_time_ms": 2132.807, "learn_throughput": 1875.463, "update_time_ms": 1.47}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00022272435307968408, "cur_lr": 4.999999873689376e-05, "total_loss": 3.6064716368855443e-07, "policy_loss": 3.6064716368855443e-07, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": -2.1150682982806757e-08, "entropy": 0.0006625988753512502, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 212000, "num_agent_steps_sampled": 212000, "num_steps_trained": 212000, "num_agent_steps_trained": 212000}, "done": false, "episodes_total": 42400, "training_iteration": 53, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-32", "timestamp": 1628628932, "time_this_iter_s": 3.6189911365509033, "time_total_s": 214.19090247154236, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 214.19090247154236, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 37.5, "ram_util_percent": 74.53999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1435555835217057, "mean_inference_ms": 0.5852503065318936, "mean_action_processing_ms": 0.0462206395391771, "mean_env_wait_ms": 0.04997797117673816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 216000, "agent_timesteps_total": 216000, "timers": {"sample_time_ms": 1553.63, "sample_throughput": 2574.616, "load_time_ms": 0.948, "load_throughput": 4220683.27, "learn_time_ms": 2125.674, "learn_throughput": 1881.756, "update_time_ms": 1.442}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00011136217653984204, "cur_lr": 4.999999873689376e-05, "total_loss": 2.482351010257844e-05, "policy_loss": 2.482351010257844e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 2.1191828736277785e-08, "entropy": 0.0006626924150623381, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 216000, "num_agent_steps_sampled": 216000, "num_steps_trained": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 43200, "training_iteration": 54, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-35", "timestamp": 1628628935, "time_this_iter_s": 3.5973329544067383, "time_total_s": 217.7882354259491, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 217.7882354259491, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 36.36, "ram_util_percent": 74.7}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14337429056306228, "mean_inference_ms": 0.5844529100479248, "mean_action_processing_ms": 0.04614307221917157, "mean_env_wait_ms": 0.04991961310552916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 220000, "agent_timesteps_total": 220000, "timers": {"sample_time_ms": 1551.588, "sample_throughput": 2578.004, "load_time_ms": 0.949, "load_throughput": 4215274.993, "learn_time_ms": 2114.11, "learn_throughput": 1892.049, "update_time_ms": 1.431}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.568108826992102e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 2.479394652254996e-06, "policy_loss": 2.479394652254996e-06, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": -3.777170576313438e-08, "entropy": 0.0006634963792748749, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 220000, "num_agent_steps_sampled": 220000, "num_steps_trained": 220000, "num_agent_steps_trained": 220000}, "done": false, "episodes_total": 44000, "training_iteration": 55, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-39", "timestamp": 1628628939, "time_this_iter_s": 3.6357152462005615, "time_total_s": 221.42395067214966, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 221.42395067214966, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 36.42, "ram_util_percent": 74.7}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 38.04375000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14317181492252862, "mean_inference_ms": 0.5836839012850144, "mean_action_processing_ms": 0.04606548651487838, "mean_env_wait_ms": 0.049854264506397426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 224000, "agent_timesteps_total": 224000, "timers": {"sample_time_ms": 1551.999, "sample_throughput": 2577.321, "load_time_ms": 0.956, "load_throughput": 4183427.09, "learn_time_ms": 2110.156, "learn_throughput": 1895.594, "update_time_ms": 1.409}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.784054413496051e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.02857729233801365, "policy_loss": -0.001961789093911648, "vf_loss": 0.03053908236324787, "vf_explained_var": 0.9997496008872986, "kl": 9.566031621943694e-06, "entropy": 0.00053745525656268, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 224000, "num_agent_steps_sampled": 224000, "num_steps_trained": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 44800, "training_iteration": 56, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-43", "timestamp": 1628628943, "time_this_iter_s": 3.6576590538024902, "time_total_s": 225.08160972595215, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 225.08160972595215, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 36.8, "ram_util_percent": 74.86}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1429682914573336, "mean_inference_ms": 0.5827896346190612, "mean_action_processing_ms": 0.045983013632552645, "mean_env_wait_ms": 0.04978298868006038, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 228000, "agent_timesteps_total": 228000, "timers": {"sample_time_ms": 1542.229, "sample_throughput": 2593.649, "load_time_ms": 0.956, "load_throughput": 4184261.772, "learn_time_ms": 2103.428, "learn_throughput": 1901.658, "update_time_ms": 1.402}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.3920272067480255e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.10636038333177567, "policy_loss": -0.10636375099420547, "vf_loss": 6.876220242073988e-14, "vf_explained_var": 1.0, "kl": 0.24106384813785553, "entropy": 0.12259889394044876, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 228000, "num_agent_steps_sampled": 228000, "num_steps_trained": 228000, "num_agent_steps_trained": 228000}, "done": false, "episodes_total": 45600, "training_iteration": 57, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-46", "timestamp": 1628628946, "time_this_iter_s": 3.6350269317626953, "time_total_s": 228.71663665771484, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 228.71663665771484, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 36.833333333333336, "ram_util_percent": 74.98333333333333}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 37.8538166441, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14270449497363885, "mean_inference_ms": 0.5816389968256068, "mean_action_processing_ms": 0.0458817329038097, "mean_env_wait_ms": 0.04969114184429934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 232000, "agent_timesteps_total": 232000, "timers": {"sample_time_ms": 1536.284, "sample_throughput": 2603.686, "load_time_ms": 0.953, "load_throughput": 4198292.378, "learn_time_ms": 2101.283, "learn_throughput": 1903.599, "update_time_ms": 1.421}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.0880408555967733e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.026528816670179367, "policy_loss": -0.0376618355512619, "vf_loss": 0.011129896156489849, "vf_explained_var": 0.999907374382019, "kl": 0.1491493582725525, "entropy": 0.24037137627601624, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 232000, "num_agent_steps_sampled": 232000, "num_steps_trained": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 46400, "training_iteration": 58, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-50", "timestamp": 1628628950, "time_this_iter_s": 3.5861430168151855, "time_total_s": 232.30277967453003, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 232.30277967453003, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 36.56, "ram_util_percent": 74.82000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 37.4388749128, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 31.049999999999997, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 30.049999999999997, 38.05, 31.049999999999997, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 30.049999999999997, 38.05, 38.05, 31.049999999999997, 31.049999999999997, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 31.049999999999997, 38.05, 37.76607976, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 37.76607976, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 30.049999999999997, 31.049999999999997, 38.05, 31.049999999999997, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 30.049999999999997, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 37.76607976, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 30.049999999999997, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 37.827287760000004, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 31.049999999999997, 37.76607976, 31.049999999999997, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 31.049999999999997, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 31.049999999999997, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 31.049999999999997, 38.05, 38.05, 31.049999999999997, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 37.76607976, 30.049999999999997, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 31.049999999999997, 38.05, 37.76607976, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 31.049999999999997, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14258295088250508, "mean_inference_ms": 0.5811221945020205, "mean_action_processing_ms": 0.04583022811471586, "mean_env_wait_ms": 0.049654001373403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 236000, "agent_timesteps_total": 236000, "timers": {"sample_time_ms": 1539.011, "sample_throughput": 2599.072, "load_time_ms": 0.952, "load_throughput": 4200079.109, "learn_time_ms": 2090.231, "learn_throughput": 1913.664, "update_time_ms": 1.428}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.1320611014962196e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 2.106619119644165, "policy_loss": -0.052329353988170624, "vf_loss": 2.158945083618164, "vf_explained_var": 0.9804169535636902, "kl": 0.10012073814868927, "entropy": 0.04315410181879997, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 236000, "num_agent_steps_sampled": 236000, "num_steps_trained": 236000, "num_agent_steps_trained": 236000}, "done": false, "episodes_total": 47200, "training_iteration": 59, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-54", "timestamp": 1628628954, "time_this_iter_s": 3.656956911087036, "time_total_s": 235.95973658561707, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 235.95973658561707, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 36.8, "ram_util_percent": 74.8}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 38.02117172340001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14239419451447408, "mean_inference_ms": 0.580366800755672, "mean_action_processing_ms": 0.04576124064812124, "mean_env_wait_ms": 0.04959149062278374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 240000, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 1536.259, "sample_throughput": 2603.727, "load_time_ms": 0.951, "load_throughput": 4204499.912, "learn_time_ms": 2087.244, "learn_throughput": 1916.402, "update_time_ms": 1.43}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.6980916522443295e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.10526615381240845, "policy_loss": -0.006272843107581139, "vf_loss": 0.11153876036405563, "vf_explained_var": 0.999006986618042, "kl": 0.004777309950441122, "entropy": 0.005745780188590288, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 240000, "num_agent_steps_sampled": 240000, "num_steps_trained": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 48000, "training_iteration": 60, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-55-57", "timestamp": 1628628957, "time_this_iter_s": 3.6508278846740723, "time_total_s": 239.61056447029114, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 239.61056447029114, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 36.44, "ram_util_percent": 74.83999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14219086308614975, "mean_inference_ms": 0.5794545452936416, "mean_action_processing_ms": 0.04568021982081851, "mean_env_wait_ms": 0.04952250110824677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 244000, "agent_timesteps_total": 244000, "timers": {"sample_time_ms": 1536.305, "sample_throughput": 2603.65, "load_time_ms": 0.946, "load_throughput": 4229088.251, "learn_time_ms": 2079.478, "learn_throughput": 1923.56, "update_time_ms": 1.413}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.3490458261221647e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0556761771440506, "policy_loss": -0.05567863583564758, "vf_loss": 2.2003903419384047e-14, "vf_explained_var": 1.0, "kl": 0.10511177778244019, "entropy": 0.18274083733558655, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 244000, "num_agent_steps_sampled": 244000, "num_steps_trained": 244000, "num_agent_steps_trained": 244000}, "done": false, "episodes_total": 48800, "training_iteration": 61, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-01", "timestamp": 1628628961, "time_this_iter_s": 3.584852933883667, "time_total_s": 243.1954174041748, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 243.1954174041748, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 36.32, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 36.24875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 36.05, 36.05, 29.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 34.05, 38.05, 36.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 35.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 36.05, 38.05, 36.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 35.05, 36.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 36.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 36.05, 36.05, 34.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 33.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 34.05, 30.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 30.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 36.05, 34.05, 36.05, 34.05, 36.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 36.05, 38.05, 34.05, 38.05, 36.05, 34.05, 38.05, 34.05, 34.05, 36.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 36.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 36.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 30.05, 38.05, 34.05, 34.05, 38.05, 37.05, 34.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 36.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 35.05, 34.05, 38.05, 38.05, 38.05, 34.05, 35.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 36.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 35.05, 38.05, 36.05, 34.05, 35.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 36.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 29.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 36.05, 34.05, 34.05, 29.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 36.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 36.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 36.05, 34.05, 38.05, 34.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14202685278500912, "mean_inference_ms": 0.5787949963112644, "mean_action_processing_ms": 0.04561532442697074, "mean_env_wait_ms": 0.049469663268507436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 248000, "agent_timesteps_total": 248000, "timers": {"sample_time_ms": 1534.57, "sample_throughput": 2606.594, "load_time_ms": 0.954, "load_throughput": 4192731.726, "learn_time_ms": 2074.838, "learn_throughput": 1927.861, "update_time_ms": 1.402}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.523568739183247e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 4.118625640869141, "policy_loss": -0.05799335986375809, "vf_loss": 4.176609039306641, "vf_explained_var": 0.9648695588111877, "kl": 0.270069420337677, "entropy": 0.01843377575278282, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 248000, "num_agent_steps_sampled": 248000, "num_steps_trained": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 49600, "training_iteration": 62, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-05", "timestamp": 1628628965, "time_this_iter_s": 3.65256404876709, "time_total_s": 246.8479814529419, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 246.8479814529419, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 37.4, "ram_util_percent": 75.10000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.01500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14186441231819935, "mean_inference_ms": 0.5781665614553456, "mean_action_processing_ms": 0.04555247405043837, "mean_env_wait_ms": 0.04941601173125436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 252000, "agent_timesteps_total": 252000, "timers": {"sample_time_ms": 1535.331, "sample_throughput": 2605.301, "load_time_ms": 0.955, "load_throughput": 4188649.323, "learn_time_ms": 2074.829, "learn_throughput": 1927.87, "update_time_ms": 1.407}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.2853531087748706e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.268690288066864, "policy_loss": -0.006487985607236624, "vf_loss": 0.27517804503440857, "vf_explained_var": 0.9975436329841614, "kl": 0.005137929692864418, "entropy": 0.0030136085115373135, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 252000, "num_agent_steps_sampled": 252000, "num_steps_trained": 252000, "num_agent_steps_trained": 252000}, "done": false, "episodes_total": 50400, "training_iteration": 63, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-08", "timestamp": 1628628968, "time_this_iter_s": 3.626944065093994, "time_total_s": 250.4749255180359, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 250.4749255180359, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 36.160000000000004, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 36.05, "episode_reward_mean": 38.04750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14170449534108556, "mean_inference_ms": 0.5775029133581007, "mean_action_processing_ms": 0.04548895676710955, "mean_env_wait_ms": 0.04936273201870853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 256000, "agent_timesteps_total": 256000, "timers": {"sample_time_ms": 1540.23, "sample_throughput": 2597.014, "load_time_ms": 0.958, "load_throughput": 4174682.99, "learn_time_ms": 2080.99, "learn_throughput": 1922.162, "update_time_ms": 1.432}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.2853531087748706e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.0030380813404917717, "policy_loss": -0.0018534597475081682, "vf_loss": 0.004891532007604837, "vf_explained_var": 0.9999570250511169, "kl": 0.0001806339860195294, "entropy": 0.0012985178036615252, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 256000, "num_agent_steps_sampled": 256000, "num_steps_trained": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 51200, "training_iteration": 64, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-12", "timestamp": 1628628972, "time_this_iter_s": 3.7080018520355225, "time_total_s": 254.1829273700714, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 254.1829273700714, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 27.96, "ram_util_percent": 74.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.04964509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14152457146080424, "mean_inference_ms": 0.5768085043059554, "mean_action_processing_ms": 0.04541972874833993, "mean_env_wait_ms": 0.04930483231277577, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 260000, "agent_timesteps_total": 260000, "timers": {"sample_time_ms": 1537.048, "sample_throughput": 2602.391, "load_time_ms": 0.952, "load_throughput": 4203551.814, "learn_time_ms": 2079.696, "learn_throughput": 1923.358, "update_time_ms": 1.435}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.6426765543874353e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.003506433917209506, "policy_loss": -0.0037817717529833317, "vf_loss": 0.0002753337612375617, "vf_explained_var": 0.999997615814209, "kl": 0.0003241038357373327, "entropy": 0.00048715583398006856, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 260000, "num_agent_steps_sampled": 260000, "num_steps_trained": 260000, "num_agent_steps_trained": 260000}, "done": false, "episodes_total": 52000, "training_iteration": 65, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-16", "timestamp": 1628628976, "time_this_iter_s": 3.590683937072754, "time_total_s": 257.77361130714417, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 257.77361130714417, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 37.04, "ram_util_percent": 74.96000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14136928329729595, "mean_inference_ms": 0.5761423074549172, "mean_action_processing_ms": 0.04535785995712163, "mean_env_wait_ms": 0.0492496417002801, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 264000, "agent_timesteps_total": 264000, "timers": {"sample_time_ms": 1535.123, "sample_throughput": 2605.654, "load_time_ms": 0.947, "load_throughput": 4222701.669, "learn_time_ms": 2083.622, "learn_throughput": 1919.734, "update_time_ms": 1.43}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.3213382771937177e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0016055350424721837, "policy_loss": -0.0016055350424721837, "vf_loss": 8.251463782269017e-15, "vf_explained_var": 1.0, "kl": 8.740850034882897e-07, "entropy": 0.0004600436659529805, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 264000, "num_agent_steps_sampled": 264000, "num_steps_trained": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 52800, "training_iteration": 66, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-19", "timestamp": 1628628979, "time_this_iter_s": 3.677489757537842, "time_total_s": 261.451101064682, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 261.451101064682, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 37.416666666666664, "ram_util_percent": 74.94999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.141188915649041, "mean_inference_ms": 0.5753435880997059, "mean_action_processing_ms": 0.04528695710156334, "mean_env_wait_ms": 0.049187700591568906, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 268000, "agent_timesteps_total": 268000, "timers": {"sample_time_ms": 1532.52, "sample_throughput": 2610.08, "load_time_ms": 0.943, "load_throughput": 4242026.802, "learn_time_ms": 2080.469, "learn_throughput": 1922.644, "update_time_ms": 1.442}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.606691385968588e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -5.11158259541844e-06, "policy_loss": -5.11158259541844e-06, "vf_loss": 1.1918781018833025e-14, "vf_explained_var": 1.0, "kl": 6.872758362419518e-09, "entropy": 0.00046067891526035964, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 268000, "num_agent_steps_sampled": 268000, "num_steps_trained": 268000, "num_agent_steps_trained": 268000}, "done": false, "episodes_total": 53600, "training_iteration": 67, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-23", "timestamp": 1628628983, "time_this_iter_s": 3.5785231590270996, "time_total_s": 265.0296242237091, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 265.0296242237091, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 36.6, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14104869681050983, "mean_inference_ms": 0.5748442988680703, "mean_action_processing_ms": 0.045235159239331864, "mean_env_wait_ms": 0.04914544149195125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 272000, "agent_timesteps_total": 272000, "timers": {"sample_time_ms": 1538.915, "sample_throughput": 2599.234, "load_time_ms": 0.945, "load_throughput": 4233143.088, "learn_time_ms": 2081.874, "learn_throughput": 1921.346, "update_time_ms": 1.436}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.303345692984294e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -2.026645597652532e-05, "policy_loss": -2.026645597652532e-05, "vf_loss": 1.2835610327974027e-14, "vf_explained_var": 1.0, "kl": 3.435943529694896e-09, "entropy": 0.00045672341366298497, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 272000, "num_agent_steps_sampled": 272000, "num_steps_trained": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 54400, "training_iteration": 68, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-27", "timestamp": 1628628987, "time_this_iter_s": 3.6631927490234375, "time_total_s": 268.69281697273254, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 268.69281697273254, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 36.779999999999994, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14089262062832536, "mean_inference_ms": 0.5742360819583432, "mean_action_processing_ms": 0.045176096615095515, "mean_env_wait_ms": 0.049094337628238977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 276000, "agent_timesteps_total": 276000, "timers": {"sample_time_ms": 1533.259, "sample_throughput": 2608.822, "load_time_ms": 0.955, "load_throughput": 4190532.521, "learn_time_ms": 2082.856, "learn_throughput": 1920.44, "update_time_ms": 1.448}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.651672846492147e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -1.2823947145079728e-05, "policy_loss": -1.2823947145079728e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.8283685676578898e-08, "entropy": 0.00045236037112772465, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 276000, "num_agent_steps_sampled": 276000, "num_steps_trained": 276000, "num_agent_steps_trained": 276000}, "done": false, "episodes_total": 55200, "training_iteration": 69, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-30", "timestamp": 1628628990, "time_this_iter_s": 3.610189914703369, "time_total_s": 272.3030068874359, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 272.3030068874359, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 36.199999999999996, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14075783766821184, "mean_inference_ms": 0.5736783058622684, "mean_action_processing_ms": 0.04512308110523297, "mean_env_wait_ms": 0.0490480921564628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 280000, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 1533.528, "sample_throughput": 2608.364, "load_time_ms": 0.955, "load_throughput": 4188753.901, "learn_time_ms": 2079.564, "learn_throughput": 1923.48, "update_time_ms": 1.45}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.258364232460735e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 5.627864993584808e-06, "policy_loss": 5.627864993584808e-06, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.6471936703510437e-08, "entropy": 0.0004484089440666139, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 280000, "num_agent_steps_sampled": 280000, "num_steps_trained": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 56000, "training_iteration": 70, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-34", "timestamp": 1628628994, "time_this_iter_s": 3.620718002319336, "time_total_s": 275.92372488975525, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 275.92372488975525, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 36.339999999999996, "ram_util_percent": 75.03999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1406344454664292, "mean_inference_ms": 0.57319316453265, "mean_action_processing_ms": 0.045075558339047354, "mean_env_wait_ms": 0.04901073589135965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 284000, "agent_timesteps_total": 284000, "timers": {"sample_time_ms": 1537.11, "sample_throughput": 2602.285, "load_time_ms": 0.965, "load_throughput": 4146617.894, "learn_time_ms": 2085.153, "learn_throughput": 1918.324, "update_time_ms": 1.449}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.1291821162303677e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 4.438848191057332e-05, "policy_loss": 4.438848191057332e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": -1.3701847434433034e-09, "entropy": 0.0004415308649186045, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 284000, "num_agent_steps_sampled": 284000, "num_steps_trained": 284000, "num_agent_steps_trained": 284000}, "done": false, "episodes_total": 56800, "training_iteration": 71, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-38", "timestamp": 1628628998, "time_this_iter_s": 3.676826238632202, "time_total_s": 279.60055112838745, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 279.60055112838745, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 37.5, "ram_util_percent": 75.06666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14048023072084845, "mean_inference_ms": 0.5725761046703554, "mean_action_processing_ms": 0.045018360315613036, "mean_env_wait_ms": 0.04895718173632492, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 288000, "agent_timesteps_total": 288000, "timers": {"sample_time_ms": 1534.068, "sample_throughput": 2607.446, "load_time_ms": 0.967, "load_throughput": 4136394.477, "learn_time_ms": 2082.308, "learn_throughput": 1920.945, "update_time_ms": 1.456}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.0645910581151838e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 3.2043131795944646e-05, "policy_loss": 3.2043131795944646e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.0174252906836045e-07, "entropy": 0.00043463462498039007, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 288000, "num_agent_steps_sampled": 288000, "num_steps_trained": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 57600, "training_iteration": 72, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-41", "timestamp": 1628629001, "time_this_iter_s": 3.5934841632843018, "time_total_s": 283.19403529167175, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 283.19403529167175, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 36.72, "ram_util_percent": 75.16}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1403683689398124, "mean_inference_ms": 0.5720582214347526, "mean_action_processing_ms": 0.04497090656193434, "mean_env_wait_ms": 0.048920678458479416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 292000, "agent_timesteps_total": 292000, "timers": {"sample_time_ms": 1533.329, "sample_throughput": 2608.703, "load_time_ms": 0.971, "load_throughput": 4118523.174, "learn_time_ms": 2088.711, "learn_throughput": 1915.057, "update_time_ms": 1.477}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.0322955290575919e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 3.2567786547588184e-06, "policy_loss": 3.2567786547588184e-06, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 2.0572859682488343e-07, "entropy": 0.00042954672244377434, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 292000, "num_agent_steps_sampled": 292000, "num_steps_trained": 292000, "num_agent_steps_trained": 292000}, "done": false, "episodes_total": 58400, "training_iteration": 73, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-45", "timestamp": 1628629005, "time_this_iter_s": 3.6836998462677, "time_total_s": 286.87773513793945, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 286.87773513793945, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 35.980000000000004, "ram_util_percent": 75.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14024519802590465, "mean_inference_ms": 0.5715789361969548, "mean_action_processing_ms": 0.0449250905425372, "mean_env_wait_ms": 0.048882096157893226, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 296000, "agent_timesteps_total": 296000, "timers": {"sample_time_ms": 1533.473, "sample_throughput": 2608.459, "load_time_ms": 0.974, "load_throughput": 4106225.464, "learn_time_ms": 2081.237, "learn_throughput": 1921.934, "update_time_ms": 1.446}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.1614776452879596e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 2.1088674202474067e-06, "policy_loss": 2.1088674202474067e-06, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 3.282616205524391e-07, "entropy": 0.0004322280874475837, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 296000, "num_agent_steps_sampled": 296000, "num_steps_trained": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 59200, "training_iteration": 74, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-49", "timestamp": 1628629009, "time_this_iter_s": 3.633882761001587, "time_total_s": 290.51161789894104, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 290.51161789894104, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 36.34, "ram_util_percent": 75.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14007308163788065, "mean_inference_ms": 0.5708491948206246, "mean_action_processing_ms": 0.044861526230368744, "mean_env_wait_ms": 0.048823621620954716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 300000, "agent_timesteps_total": 300000, "timers": {"sample_time_ms": 1529.252, "sample_throughput": 2615.658, "load_time_ms": 0.973, "load_throughput": 4110853.67, "learn_time_ms": 2088.03, "learn_throughput": 1915.681, "update_time_ms": 1.463}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.5807388226439798e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 1.3032975402893499e-05, "policy_loss": 1.3032975402893499e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 8.718766366655473e-07, "entropy": 0.00046854407992213964, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 300000, "num_agent_steps_sampled": 300000, "num_steps_trained": 300000, "num_agent_steps_trained": 300000}, "done": false, "episodes_total": 60000, "training_iteration": 75, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-52", "timestamp": 1628629012, "time_this_iter_s": 3.6175568103790283, "time_total_s": 294.12917470932007, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 294.12917470932007, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 36.44, "ram_util_percent": 75.2}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13998402869141188, "mean_inference_ms": 0.5704685179522372, "mean_action_processing_ms": 0.044822988539557504, "mean_env_wait_ms": 0.04879471556156771, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 304000, "agent_timesteps_total": 304000, "timers": {"sample_time_ms": 1532.035, "sample_throughput": 2610.906, "load_time_ms": 0.98, "load_throughput": 4080161.483, "learn_time_ms": 2081.708, "learn_throughput": 1921.499, "update_time_ms": 1.467}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.2903694113219899e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -1.2146440894866828e-05, "policy_loss": -1.2146440894866828e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 7.975326298037544e-06, "entropy": 0.0006943855551071465, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 304000, "num_agent_steps_sampled": 304000, "num_steps_trained": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 60800, "training_iteration": 76, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-56-56", "timestamp": 1628629016, "time_this_iter_s": 3.642716884613037, "time_total_s": 297.7718915939331, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 297.7718915939331, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 37.050000000000004, "ram_util_percent": 75.10000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1398818288423578, "mean_inference_ms": 0.5700567620274971, "mean_action_processing_ms": 0.04478407086024417, "mean_env_wait_ms": 0.04876360253951272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 308000, "agent_timesteps_total": 308000, "timers": {"sample_time_ms": 1536.357, "sample_throughput": 2603.562, "load_time_ms": 0.979, "load_throughput": 4083935.639, "learn_time_ms": 2082.218, "learn_throughput": 1921.029, "update_time_ms": 1.46}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.4518470566099495e-09, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0018293343018740416, "policy_loss": -0.0018293352331966162, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 0.18473942577838898, "entropy": 0.2864830791950226, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 308000, "num_agent_steps_sampled": 308000, "num_steps_trained": 308000, "num_agent_steps_trained": 308000}, "done": false, "episodes_total": 61600, "training_iteration": 77, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-00", "timestamp": 1628629020, "time_this_iter_s": 3.6265008449554443, "time_total_s": 301.39839243888855, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 301.39839243888855, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 38.5, "ram_util_percent": 75.17999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 36.19250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 29.049999999999997, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 32.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 32.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 32.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 32.05, 35.05, 35.05, 38.05, 35.05, 32.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 32.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 32.05, 35.05, 35.05, 34.05, 35.05, 35.05, 35.05, 38.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 32.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 32.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 34.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 32.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 38.05, 38.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 32.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13976494361702896, "mean_inference_ms": 0.5695667069142948, "mean_action_processing_ms": 0.04473979709651237, "mean_env_wait_ms": 0.048723690231688765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 312000, "agent_timesteps_total": 312000, "timers": {"sample_time_ms": 1534.158, "sample_throughput": 2607.293, "load_time_ms": 0.98, "load_throughput": 4081451.856, "learn_time_ms": 2084.387, "learn_throughput": 1919.029, "update_time_ms": 1.44}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 9.677770584914924e-09, "cur_lr": 4.999999873689376e-05, "total_loss": 2.41412353515625, "policy_loss": -0.07730554044246674, "vf_loss": 2.491429328918457, "vf_explained_var": 0.976349413394928, "kl": 0.05629638954997063, "entropy": 0.20022772252559662, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 312000, "num_agent_steps_sampled": 312000, "num_steps_trained": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 62400, "training_iteration": 78, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-03", "timestamp": 1628629023, "time_this_iter_s": 3.6625561714172363, "time_total_s": 305.0609486103058, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 305.0609486103058, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 35.68, "ram_util_percent": 75.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 27.05, "episode_reward_mean": 36.96875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 32.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 27.050000000000004, 30.05, 27.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 32.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 30.049999999999997, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 32.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 30.049999999999997, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 30.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 30.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 30.049999999999997, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 29.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 35.05, 38.05, 38.05, 35.05, 38.05, 30.049999999999997, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 35.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 30.049999999999997, 35.05, 38.05, 35.05, 30.049999999999997, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 30.05, 35.05, 38.05, 30.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 30.049999999999997, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 32.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 30.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 27.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 35.05, 38.05, 38.05, 30.049999999999997, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13961050092588123, "mean_inference_ms": 0.5688673152162217, "mean_action_processing_ms": 0.04468169482657979, "mean_env_wait_ms": 0.04867102354226425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 316000, "agent_timesteps_total": 316000, "timers": {"sample_time_ms": 1529.429, "sample_throughput": 2615.355, "load_time_ms": 0.967, "load_throughput": 4135476.842, "learn_time_ms": 2087.215, "learn_throughput": 1916.429, "update_time_ms": 1.419}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.4516656321461596e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 4.020369529724121, "policy_loss": -0.04373893514275551, "vf_loss": 4.064108848571777, "vf_explained_var": 0.9636242389678955, "kl": 0.2405351996421814, "entropy": 0.006797614507377148, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 316000, "num_agent_steps_sampled": 316000, "num_steps_trained": 316000, "num_agent_steps_trained": 316000}, "done": false, "episodes_total": 63200, "training_iteration": 79, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-07", "timestamp": 1628629027, "time_this_iter_s": 3.5919151306152344, "time_total_s": 308.652863740921, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 308.652863740921, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 75.25999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.04125000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13957597103110908, "mean_inference_ms": 0.5687510683910828, "mean_action_processing_ms": 0.044665172190501715, "mean_env_wait_ms": 0.04866375757665476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 320000, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 1536.204, "sample_throughput": 2603.821, "load_time_ms": 0.963, "load_throughput": 4154833.086, "learn_time_ms": 2086.689, "learn_throughput": 1916.912, "update_time_ms": 1.422}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.1774983594013975e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -0.05735421180725098, "policy_loss": -0.07908523827791214, "vf_loss": 0.02173100970685482, "vf_explained_var": 0.999809980392456, "kl": 0.2456594556570053, "entropy": 0.27973294258117676, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 320000, "num_agent_steps_sampled": 320000, "num_steps_trained": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 64000, "training_iteration": 80, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-11", "timestamp": 1628629031, "time_this_iter_s": 3.682889938354492, "time_total_s": 312.3357536792755, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 312.3357536792755, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 37.483333333333334, "ram_util_percent": 75.2}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 35.114775951, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 31.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 31.05, 37.76607976, 30.05, 30.05, 37.76607976, 38.05, 30.05, 37.76607976, 38.05, 30.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 31.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 30.05, 38.05, 38.05, 38.05, 31.05, 37.76607976, 38.05, 30.05, 38.05, 31.05, 38.05, 38.05, 31.05, 37.76607976, 37.76607976, 38.05, 31.05, 30.05, 31.05, 38.05, 30.05, 37.76607976, 38.05, 37.76607976, 31.05, 30.05, 38.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 30.05, 38.05, 38.05, 31.05, 31.05, 30.05, 38.05, 30.05, 31.05, 37.76607976, 38.05, 31.05, 31.05, 37.76607976, 38.05, 38.05, 31.05, 37.76607976, 31.05, 31.05, 38.05, 31.05, 37.76607976, 38.05, 31.05, 37.76607976, 37.76607976, 38.05, 38.05, 30.05, 37.76607976, 37.76607976, 37.76607976, 31.05, 37.76607976, 38.05, 31.05, 37.76607976, 38.05, 30.05, 38.05, 37.76607976, 37.76607976, 38.05, 31.05, 37.76607976, 38.05, 31.05, 31.05, 38.05, 30.05, 38.05, 30.05, 37.76607976, 31.05, 31.05, 38.05, 30.05, 38.05, 37.76607976, 31.050000000000004, 38.05, 38.05, 30.05, 31.05, 36.05, 31.05, 38.05, 38.05, 31.05, 30.05, 38.05, 38.05, 31.05, 38.05, 31.05, 38.05, 30.05, 37.76607976, 30.05, 38.05, 38.05, 37.76607976, 31.05, 37.76607976, 31.05, 31.05, 37.76607976, 31.05, 37.76607976, 37.76607976, 31.05, 31.05, 30.05, 37.76607976, 38.05, 31.05, 31.05, 30.05, 30.05, 31.05, 31.05, 31.05, 30.05, 38.05, 30.05, 38.05, 37.76607976, 37.76607976, 31.05, 38.05, 37.76607976, 30.05, 38.05, 31.05, 31.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 31.05, 31.05, 31.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 30.05, 37.76607976, 37.76607976, 30.05, 37.76607976, 31.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 31.05, 38.05, 30.05, 30.05, 31.05, 31.05, 31.05, 38.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 31.05, 37.76607976, 37.76607976, 38.05, 31.05, 37.76607976, 30.05, 30.05, 38.05, 38.05, 31.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 38.05, 30.05, 31.05, 31.05, 37.76607976, 30.05, 37.76607976, 37.76607976, 31.05, 38.05, 37.76607976, 38.05, 30.05, 38.05, 38.05, 37.76607976, 30.05, 37.76607976, 30.05, 31.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 30.05, 37.76607976, 31.05, 31.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 31.05, 31.05, 31.05, 30.05, 38.05, 38.05, 30.05, 38.05, 37.76607976, 31.05, 37.76607976, 38.05, 31.05, 37.76607976, 31.05, 37.76607976, 31.05, 31.05, 31.05, 37.76607976, 38.05, 38.05, 38.05, 30.05, 37.76607976, 31.05, 31.050000000000004, 38.05, 37.76607976, 31.05, 37.76607976, 37.76607976, 38.05, 38.05, 31.05, 38.05, 37.76607976, 38.05, 30.05, 38.05, 38.05, 31.05, 38.05, 30.05, 31.05, 37.76607976, 31.05, 31.05, 38.05, 31.05, 37.76607976, 38.05, 37.76607976, 31.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 30.05, 38.05, 38.05, 38.05, 31.05, 38.05, 37.76607976, 38.05, 31.05, 31.05, 38.05, 38.05, 35.05, 31.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 31.05, 38.05, 38.05, 37.76607976, 30.05, 31.05, 30.05, 31.05, 38.05, 31.05, 31.05, 37.76607976, 31.05, 38.05, 37.76607976, 31.05, 30.05, 31.05, 31.05, 30.05, 38.05, 38.05, 31.05, 38.05, 31.05, 37.76607976, 31.05, 31.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 31.05, 31.05, 38.05, 38.05, 37.76607976, 38.05, 31.05, 37.76607976, 31.05, 37.76607976, 38.05, 31.05, 38.05, 31.050000000000004, 37.76607976, 38.05, 31.05, 38.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 31.05, 37.76607976, 38.05, 31.05, 38.05, 31.05, 38.05, 37.76607976, 31.05, 38.05, 31.05, 38.05, 30.05, 37.76607976, 31.05, 37.76607976, 31.05, 31.05, 38.05, 31.05, 30.05, 31.05, 31.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 31.05, 30.05, 30.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 31.05, 31.05, 37.76607976, 30.05, 30.05, 37.76607976, 31.05, 37.76607976, 31.05, 38.05, 38.05, 37.76607976, 30.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 30.05, 31.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 31.05, 38.05, 37.76607976, 30.05, 31.05, 37.76607976, 31.05, 37.76607976, 38.05, 38.05, 38.05, 31.05, 37.76607976, 37.76607976, 38.05, 30.05, 38.05, 38.05, 31.05, 38.05, 38.05, 38.05, 37.76607976, 31.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 31.05, 37.76607976, 30.05, 38.05, 31.05, 31.05, 38.05, 37.76607976, 31.05, 31.05, 37.76607976, 30.05, 30.05, 30.05, 31.05, 31.05, 31.05, 37.76607976, 38.05, 30.05, 38.05, 31.05, 30.05, 38.05, 30.05, 37.76607976, 30.05, 37.76607976, 31.05, 31.05, 37.76607976, 37.76607976, 30.050000000000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 30.05, 37.76607976, 31.05, 31.05, 37.76607976, 31.050000000000004, 37.76607976, 38.05, 38.05, 37.76607976, 30.05, 31.05, 37.76607976, 38.05, 31.05, 37.76607976, 30.05, 31.05, 38.05, 37.76607976, 37.76607976, 31.05, 38.05, 31.05, 38.05, 31.05, 38.05, 31.05, 38.05, 38.05, 38.05, 38.05, 31.05, 31.05, 38.05, 38.05, 30.05, 38.05, 31.05, 30.05, 38.05, 37.76607976, 30.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 31.05, 37.76607976, 37.76607976, 31.05, 31.05, 37.76607976, 37.76607976, 37.76607976, 30.05, 37.76607976, 37.76607976, 30.05, 38.05, 38.05, 38.05, 30.05, 31.05, 31.05, 37.76607976, 38.05, 31.05, 31.05, 38.05, 38.05, 38.05, 38.05, 30.05, 37.76607976, 37.76607976, 31.05, 31.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 31.05, 37.76607976, 30.05, 31.05, 31.05, 37.76607976, 38.05, 31.05, 31.05, 38.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 30.05, 30.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 30.05, 38.05, 37.76607976, 37.76607976, 38.05, 30.05, 30.05, 31.05, 30.05, 37.76607976, 30.05, 38.05, 38.05, 37.76607976, 37.76607976, 31.05, 31.05, 30.05, 38.05, 37.76607976, 31.05, 31.05, 38.05, 31.050000000000004, 30.05, 37.76607976, 31.05, 37.76607976, 31.05, 38.05, 31.05, 38.05, 31.05, 38.05, 37.76607976, 31.05, 31.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 30.05, 37.76607976, 38.05, 38.05, 37.76607976, 31.05, 30.05, 31.05, 31.05, 31.05, 37.76607976, 31.05, 38.05, 31.05, 38.05, 37.76607976, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 31.05, 37.76607976, 31.05, 37.76607976, 30.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 31.05, 31.05, 37.76607976, 38.05, 30.05, 31.05, 37.76607976, 37.76607976, 30.05, 37.76607976, 38.05, 30.05, 37.76607976, 30.050000000000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 31.05, 31.05, 31.05, 31.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 31.05, 37.76607976, 38.05, 31.05, 38.05, 37.76607976, 31.05, 38.05, 37.76607976, 38.05, 31.05, 38.05, 31.05, 31.05, 37.76607976, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13947843767247226, "mean_inference_ms": 0.5683561418403237, "mean_action_processing_ms": 0.04462742042987726, "mean_env_wait_ms": 0.04863135391594119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 324000, "agent_timesteps_total": 324000, "timers": {"sample_time_ms": 1535.534, "sample_throughput": 2604.957, "load_time_ms": 0.959, "load_throughput": 4171257.801, "learn_time_ms": 2090.635, "learn_throughput": 1913.294, "update_time_ms": 1.415}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.26624771673778e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 11.602255821228027, "policy_loss": -0.06814692914485931, "vf_loss": 11.670402526855469, "vf_explained_var": 0.909586489200592, "kl": 0.10702783614397049, "entropy": 0.20044149458408356, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 324000, "num_agent_steps_sampled": 324000, "num_steps_trained": 324000, "num_agent_steps_trained": 324000}, "done": false, "episodes_total": 64800, "training_iteration": 81, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-14", "timestamp": 1628629034, "time_this_iter_s": 3.709601879119873, "time_total_s": 316.0453555583954, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 316.0453555583954, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 36.16, "ram_util_percent": 75.24}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 37.477896619400006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 31.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 30.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 31.05, 30.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 30.05, 37.76607976, 38.05, 38.05, 37.76607976, 31.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 30.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 30.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 30.05, 37.76607976, 37.76607976, 38.05, 31.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 31.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.05, 37.76607976, 38.05, 30.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 31.05, 34.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 30.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 30.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 31.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 30.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 31.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 31.05, 31.05, 37.76607976, 31.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 31.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 30.05, 38.05, 38.05, 35.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 31.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 31.05, 38.05, 31.05, 38.05, 31.050000000000004, 38.05, 38.05, 37.76607976, 31.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 30.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 34.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 31.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 34.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 30.05, 38.05, 37.76607976, 38.05, 30.050000000000004, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 31.049999999999997, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 31.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 30.05, 37.76607976, 38.05, 38.05, 38.05, 31.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 34.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 31.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 31.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 31.05, 38.05, 38.05, 38.05, 31.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13935767149279907, "mean_inference_ms": 0.567872980263302, "mean_action_processing_ms": 0.044581678598228223, "mean_env_wait_ms": 0.04859046412215287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 328000, "agent_timesteps_total": 328000, "timers": {"sample_time_ms": 1535.685, "sample_throughput": 2604.701, "load_time_ms": 0.947, "load_throughput": 4224083.791, "learn_time_ms": 2092.719, "learn_throughput": 1911.389, "update_time_ms": 1.42}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.89937157510667e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 2.844256639480591, "policy_loss": -0.028190938755869865, "vf_loss": 2.8724477291107178, "vf_explained_var": 0.9757584929466248, "kl": 0.04912019893527031, "entropy": 0.12828968465328217, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 328000, "num_agent_steps_sampled": 328000, "num_steps_trained": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 65600, "training_iteration": 82, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-18", "timestamp": 1628629038, "time_this_iter_s": 3.6162240505218506, "time_total_s": 319.66157960891724, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 319.66157960891724, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 36.559999999999995, "ram_util_percent": 75.22}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 37.96943763190001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1392728045008541, "mean_inference_ms": 0.5675443232010285, "mean_action_processing_ms": 0.044546997197207866, "mean_env_wait_ms": 0.04856331924455113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 332000, "agent_timesteps_total": 332000, "timers": {"sample_time_ms": 1536.946, "sample_throughput": 2602.563, "load_time_ms": 0.947, "load_throughput": 4222701.669, "learn_time_ms": 2091.711, "learn_throughput": 1912.31, "update_time_ms": 1.401}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.349057540295689e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -0.03886928781867027, "policy_loss": -0.049115534871816635, "vf_loss": 0.010246244259178638, "vf_explained_var": 0.9999110102653503, "kl": 0.04826224222779274, "entropy": 0.05333147570490837, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 332000, "num_agent_steps_sampled": 332000, "num_steps_trained": 332000, "num_agent_steps_trained": 332000}, "done": false, "episodes_total": 66400, "training_iteration": 83, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-22", "timestamp": 1628629042, "time_this_iter_s": 3.686699867248535, "time_total_s": 323.34827947616577, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 323.34827947616577, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 36.38, "ram_util_percent": 75.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.032609885300005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13915515703951775, "mean_inference_ms": 0.567089898178367, "mean_action_processing_ms": 0.044504117165581614, "mean_env_wait_ms": 0.048521832319504604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 336000, "agent_timesteps_total": 336000, "timers": {"sample_time_ms": 1534.7, "sample_throughput": 2606.372, "load_time_ms": 0.941, "load_throughput": 4251809.727, "learn_time_ms": 2090.5, "learn_throughput": 1913.418, "update_time_ms": 1.406}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.1023585955172166e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.02139454148709774, "policy_loss": -0.024081464856863022, "vf_loss": 0.002686921041458845, "vf_explained_var": 0.9999763369560242, "kl": 0.04403695464134216, "entropy": 0.004348100628703833, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 336000, "num_agent_steps_sampled": 336000, "num_steps_trained": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 67200, "training_iteration": 84, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-25", "timestamp": 1628629045, "time_this_iter_s": 3.600085973739624, "time_total_s": 326.9483654499054, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 326.9483654499054, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 37.48333333333333, "ram_util_percent": 75.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.050000000000004, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1390912849887217, "mean_inference_ms": 0.5668228290680447, "mean_action_processing_ms": 0.04447701180667243, "mean_env_wait_ms": 0.04850264796810938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 340000, "agent_timesteps_total": 340000, "timers": {"sample_time_ms": 1542.723, "sample_throughput": 2592.819, "load_time_ms": 0.958, "load_throughput": 4174682.99, "learn_time_ms": 2092.371, "learn_throughput": 1911.707, "update_time_ms": 1.408}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.6535378222215513e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08006899803876877, "policy_loss": -0.0017624854808673263, "vf_loss": 0.08183145523071289, "vf_explained_var": 0.999320387840271, "kl": 5.895114372833632e-05, "entropy": 0.0030105251353234053, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 340000, "num_agent_steps_sampled": 340000, "num_steps_trained": 340000, "num_agent_steps_trained": 340000}, "done": false, "episodes_total": 68000, "training_iteration": 85, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-29", "timestamp": 1628629049, "time_this_iter_s": 3.7156360149383545, "time_total_s": 330.66400146484375, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 330.66400146484375, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 36.12, "ram_util_percent": 74.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.0489352991, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.138990206819384, "mean_inference_ms": 0.5663937224517648, "mean_action_processing_ms": 0.04443848009928045, "mean_env_wait_ms": 0.04846891858774685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 344000, "agent_timesteps_total": 344000, "timers": {"sample_time_ms": 1539.094, "sample_throughput": 2598.931, "load_time_ms": 0.945, "load_throughput": 4232715.897, "learn_time_ms": 2092.856, "learn_throughput": 1911.264, "update_time_ms": 1.406}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.267689111107757e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -0.13877318799495697, "policy_loss": -0.13894996047019958, "vf_loss": 0.00017677134019322693, "vf_explained_var": 0.9999983906745911, "kl": 0.19039708375930786, "entropy": 0.27154549956321716, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 344000, "num_agent_steps_sampled": 344000, "num_steps_trained": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 68800, "training_iteration": 86, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-33", "timestamp": 1628629053, "time_this_iter_s": 3.6109437942504883, "time_total_s": 334.27494525909424, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 334.27494525909424, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 36.959999999999994, "ram_util_percent": 73.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.050000000000004, "episode_reward_mean": 32.27250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 38.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 22.050000000000004, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 34.05, 30.05, 30.05, 38.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 38.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.05, 22.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 36.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 34.05, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 22.050000000000004, 30.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 38.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 35.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 35.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13893145361062906, "mean_inference_ms": 0.5662263276585889, "mean_action_processing_ms": 0.04441517825680242, "mean_env_wait_ms": 0.04845255034445932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 348000, "agent_timesteps_total": 348000, "timers": {"sample_time_ms": 1542.387, "sample_throughput": 2593.383, "load_time_ms": 0.948, "load_throughput": 4218878.97, "learn_time_ms": 2097.122, "learn_throughput": 1907.376, "update_time_ms": 1.427}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.240153437720437e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 25.045671463012695, "policy_loss": -0.0781169906258583, "vf_loss": 25.12378692626953, "vf_explained_var": 0.793835461139679, "kl": 0.06880641728639603, "entropy": 0.17154750227928162, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 348000, "num_agent_steps_sampled": 348000, "num_steps_trained": 348000, "num_agent_steps_trained": 348000}, "done": false, "episodes_total": 69600, "training_iteration": 87, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-36", "timestamp": 1628629056, "time_this_iter_s": 3.702324151992798, "time_total_s": 337.97726941108704, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 337.97726941108704, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 36.059999999999995, "ram_util_percent": 74.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.05, "episode_reward_mean": 35.58000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 34.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 34.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 27.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 22.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 34.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 34.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.05, 35.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 22.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 35.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 30.050000000000004, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13885331642489473, "mean_inference_ms": 0.5658771863566932, "mean_action_processing_ms": 0.04438377217943941, "mean_env_wait_ms": 0.04842667536817057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 352000, "agent_timesteps_total": 352000, "timers": {"sample_time_ms": 1543.588, "sample_throughput": 2591.365, "load_time_ms": 0.946, "load_throughput": 4226850.751, "learn_time_ms": 2094.025, "learn_throughput": 1910.196, "update_time_ms": 1.436}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.8602301565806556e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 14.391758918762207, "policy_loss": -0.047324132174253464, "vf_loss": 14.43908405303955, "vf_explained_var": 0.8810824155807495, "kl": 0.25376349687576294, "entropy": 0.004533977713435888, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 352000, "num_agent_steps_sampled": 352000, "num_steps_trained": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 70400, "training_iteration": 88, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-40", "timestamp": 1628629060, "time_this_iter_s": 3.644041061401367, "time_total_s": 341.6213104724884, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 341.6213104724884, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 37.01666666666666, "ram_util_percent": 74.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1387934796702367, "mean_inference_ms": 0.5656625728114376, "mean_action_processing_ms": 0.04435881194861766, "mean_env_wait_ms": 0.04840833881023345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 356000, "agent_timesteps_total": 356000, "timers": {"sample_time_ms": 1552.583, "sample_throughput": 2576.352, "load_time_ms": 0.949, "load_throughput": 4213475.313, "learn_time_ms": 2097.845, "learn_throughput": 1906.719, "update_time_ms": 1.441}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.790345092762436e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.00013409314851742238, "policy_loss": -0.07769818603992462, "vf_loss": 0.0775640532374382, "vf_explained_var": 0.9993192553520203, "kl": 0.14749431610107422, "entropy": 0.14910583198070526, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 356000, "num_agent_steps_sampled": 356000, "num_steps_trained": 356000, "num_agent_steps_trained": 356000}, "done": false, "episodes_total": 71200, "training_iteration": 89, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-44", "timestamp": 1628629064, "time_this_iter_s": 3.7195680141448975, "time_total_s": 345.3408784866333, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 345.3408784866333, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 36.89999999999999, "ram_util_percent": 74.28}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 35.81500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 35.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 35.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 29.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 35.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 34.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13870571153174413, "mean_inference_ms": 0.5653603934005108, "mean_action_processing_ms": 0.044325624022030656, "mean_env_wait_ms": 0.04837803123769504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 360000, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 1546.186, "sample_throughput": 2587.011, "load_time_ms": 0.953, "load_throughput": 4197137.068, "learn_time_ms": 2102.296, "learn_throughput": 1902.682, "update_time_ms": 1.451}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.1855176391436544e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 3.7827892303466797, "policy_loss": -0.06002381071448326, "vf_loss": 3.84281325340271, "vf_explained_var": 0.9672302007675171, "kl": 0.23090548813343048, "entropy": 0.030453089624643326, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 360000, "num_agent_steps_sampled": 360000, "num_steps_trained": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 72000, "training_iteration": 90, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-48", "timestamp": 1628629068, "time_this_iter_s": 3.6634769439697266, "time_total_s": 349.004355430603, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 349.004355430603, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 36.260000000000005, "ram_util_percent": 74.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 34.05, "episode_reward_mean": 37.931250000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13862914442652532, "mean_inference_ms": 0.5650307085349522, "mean_action_processing_ms": 0.04429351526240957, "mean_env_wait_ms": 0.048353009424077505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 364000, "agent_timesteps_total": 364000, "timers": {"sample_time_ms": 1545.938, "sample_throughput": 2587.427, "load_time_ms": 0.948, "load_throughput": 4218985.063, "learn_time_ms": 2097.583, "learn_throughput": 1906.956, "update_time_ms": 1.457}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.278276600824029e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.4357714056968689, "policy_loss": -0.01053294725716114, "vf_loss": 0.4463043510913849, "vf_explained_var": 0.9960436224937439, "kl": 0.019167179241776466, "entropy": 0.0038462267257273197, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 364000, "num_agent_steps_sampled": 364000, "num_steps_trained": 364000, "num_agent_steps_trained": 364000}, "done": false, "episodes_total": 72800, "training_iteration": 91, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-51", "timestamp": 1628629071, "time_this_iter_s": 3.6604599952697754, "time_total_s": 352.6648154258728, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 352.6648154258728, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 35.54, "ram_util_percent": 74.22}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 34.05, "episode_reward_mean": 38.04429019940001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13854375922855675, "mean_inference_ms": 0.5655549581809882, "mean_action_processing_ms": 0.04426077637575063, "mean_env_wait_ms": 0.04832529672982204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 368000, "agent_timesteps_total": 368000, "timers": {"sample_time_ms": 1579.308, "sample_throughput": 2532.755, "load_time_ms": 0.95, "load_throughput": 4208402.147, "learn_time_ms": 2093.495, "learn_throughput": 1910.68, "update_time_ms": 1.448}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.278276600824029e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.01755819469690323, "policy_loss": -0.002199512906372547, "vf_loss": 0.0197577066719532, "vf_explained_var": 0.9998229742050171, "kl": 0.0006057802820578218, "entropy": 0.0007450513658113778, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 368000, "num_agent_steps_sampled": 368000, "num_steps_trained": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 73600, "training_iteration": 92, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-55", "timestamp": 1628629075, "time_this_iter_s": 3.9084699153900146, "time_total_s": 356.5732853412628, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 356.5732853412628, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 35.68333333333334, "ram_util_percent": 74.36666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13842772910931045, "mean_inference_ms": 0.5650906105684873, "mean_action_processing_ms": 0.044221449310802984, "mean_env_wait_ms": 0.04828716538150988, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 372000, "agent_timesteps_total": 372000, "timers": {"sample_time_ms": 1573.882, "sample_throughput": 2541.487, "load_time_ms": 0.947, "load_throughput": 4222276.582, "learn_time_ms": 2095.156, "learn_throughput": 1909.166, "update_time_ms": 1.459}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.1391383004120144e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.13445425033569336, "policy_loss": -0.13445435464382172, "vf_loss": 4.0340489602204085e-14, "vf_explained_var": 1.0, "kl": 0.36984705924987793, "entropy": 0.28734859824180603, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 372000, "num_agent_steps_sampled": 372000, "num_steps_trained": 372000, "num_agent_steps_trained": 372000}, "done": false, "episodes_total": 74400, "training_iteration": 93, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-57-59", "timestamp": 1628629079, "time_this_iter_s": 3.649109125137329, "time_total_s": 360.22239446640015, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 360.22239446640015, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 36.1, "ram_util_percent": 74.47999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 26.58625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 29.049999999999997, 29.05, 38.05, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.049999999999997, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 11.049999999999999, 29.05, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 29.05, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 20.049999999999997, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 20.05, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 20.050000000000004, 29.05, 29.049999999999997, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 38.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13837636798930453, "mean_inference_ms": 0.5648712677628209, "mean_action_processing_ms": 0.04420061011162743, "mean_env_wait_ms": 0.04827249307643758, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 376000, "agent_timesteps_total": 376000, "timers": {"sample_time_ms": 1578.657, "sample_throughput": 2533.799, "load_time_ms": 0.95, "load_throughput": 4209880.558, "learn_time_ms": 2098.06, "learn_throughput": 1906.523, "update_time_ms": 1.46}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.7087075927265687e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 31.37880516052246, "policy_loss": -0.08180850744247437, "vf_loss": 31.460617065429688, "vf_explained_var": 0.7405530214309692, "kl": 0.022884616628289223, "entropy": 0.2832242548465729, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 376000, "num_agent_steps_sampled": 376000, "num_steps_trained": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 75200, "training_iteration": 94, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-03", "timestamp": 1628629083, "time_this_iter_s": 3.6765100955963135, "time_total_s": 363.89890456199646, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 363.89890456199646, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 36.22, "ram_util_percent": 74.61999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 28.88000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 38.05, 29.050000000000004, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 29.049999999999997, 38.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 23.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 20.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.05, 20.049999999999997, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 11.049999999999999, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.049999999999997, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 20.049999999999997, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 38.05, 29.049999999999997, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 38.05, 38.05, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.049999999999997, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13838524764487903, "mean_inference_ms": 0.5656538398339082, "mean_action_processing_ms": 0.04420112008429229, "mean_env_wait_ms": 0.04828183649878759, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 380000, "agent_timesteps_total": 380000, "timers": {"sample_time_ms": 1613.445, "sample_throughput": 2479.167, "load_time_ms": 0.937, "load_throughput": 4269120.334, "learn_time_ms": 2088.947, "learn_throughput": 1914.841, "update_time_ms": 1.438}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.063061389089853e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 25.090091705322266, "policy_loss": -0.08030979335308075, "vf_loss": 25.17040252685547, "vf_explained_var": 0.7833169102668762, "kl": 0.036841463297605515, "entropy": 0.24575142562389374, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 380000, "num_agent_steps_sampled": 380000, "num_steps_trained": 380000, "num_agent_steps_trained": 380000}, "done": false, "episodes_total": 76000, "training_iteration": 95, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-07", "timestamp": 1628629087, "time_this_iter_s": 3.9716742038726807, "time_total_s": 367.87057876586914, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 367.87057876586914, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 36.31666666666667, "ram_util_percent": 74.95}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.05, "episode_reward_mean": 32.15500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 20.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.049999999999997, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 20.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 20.050000000000004, 38.05, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 20.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 38.05, 29.050000000000004, 38.05, 20.050000000000004, 38.05, 38.05, 38.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 20.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 20.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 20.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.05, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 38.05, 20.050000000000004, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 20.050000000000004, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1382715181102585, "mean_inference_ms": 0.5651467189228239, "mean_action_processing_ms": 0.04415953877254064, "mean_env_wait_ms": 0.0482421339276243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 384000, "agent_timesteps_total": 384000, "timers": {"sample_time_ms": 1609.721, "sample_throughput": 2484.902, "load_time_ms": 0.944, "load_throughput": 4238811.521, "learn_time_ms": 2095.649, "learn_throughput": 1908.717, "update_time_ms": 1.455}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.0594591230983497e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 26.82563591003418, "policy_loss": -0.0836869552731514, "vf_loss": 26.90932273864746, "vf_explained_var": 0.7877464294433594, "kl": 0.2941073775291443, "entropy": 0.036184586584568024, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 384000, "num_agent_steps_sampled": 384000, "num_steps_trained": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 76800, "training_iteration": 96, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-10", "timestamp": 1628629090, "time_this_iter_s": 3.6412971019744873, "time_total_s": 371.5118758678436, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 371.5118758678436, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 74.92}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 37.66750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 20.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 20.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13822268548950387, "mean_inference_ms": 0.5648952792077591, "mean_action_processing_ms": 0.04413638763645604, "mean_env_wait_ms": 0.048225268541615345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 388000, "agent_timesteps_total": 388000, "timers": {"sample_time_ms": 1607.418, "sample_throughput": 2488.463, "load_time_ms": 0.943, "load_throughput": 4241919.547, "learn_time_ms": 2096.711, "learn_throughput": 1907.75, "update_time_ms": 1.441}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.5891887414909434e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 3.5010485649108887, "policy_loss": -0.013532033190131187, "vf_loss": 3.514580488204956, "vf_explained_var": 0.9697245955467224, "kl": 0.00270085665397346, "entropy": 0.021556729450821877, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 388000, "num_agent_steps_sampled": 388000, "num_steps_trained": 388000, "num_agent_steps_trained": 388000}, "done": false, "episodes_total": 77600, "training_iteration": 97, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-14", "timestamp": 1628629094, "time_this_iter_s": 3.6895880699157715, "time_total_s": 375.2014639377594, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 375.2014639377594, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 37.01666666666666, "ram_util_percent": 74.83333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.88125000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13821243789125326, "mean_inference_ms": 0.5649064579917261, "mean_action_processing_ms": 0.04413061470740451, "mean_env_wait_ms": 0.04822646078231703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 392000, "agent_timesteps_total": 392000, "timers": {"sample_time_ms": 1615.648, "sample_throughput": 2475.787, "load_time_ms": 0.952, "load_throughput": 4200079.109, "learn_time_ms": 2097.168, "learn_throughput": 1907.334, "update_time_ms": 1.438}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.945943707454717e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.4382798671722412, "policy_loss": -0.00709821842610836, "vf_loss": 1.4453781843185425, "vf_explained_var": 0.9873929023742676, "kl": 0.002092651091516018, "entropy": 0.009566646069288254, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 392000, "num_agent_steps_sampled": 392000, "num_steps_trained": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 78400, "training_iteration": 98, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-18", "timestamp": 1628629098, "time_this_iter_s": 3.7307679653167725, "time_total_s": 378.9322319030762, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 378.9322319030762, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 37.9, "ram_util_percent": 74.94000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.01625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13813961106174732, "mean_inference_ms": 0.5646113462500765, "mean_action_processing_ms": 0.04410309625178513, "mean_env_wait_ms": 0.04820188708574145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 396000, "agent_timesteps_total": 396000, "timers": {"sample_time_ms": 1612.123, "sample_throughput": 2481.2, "load_time_ms": 0.952, "load_throughput": 4203551.814, "learn_time_ms": 2097.981, "learn_throughput": 1906.595, "update_time_ms": 1.428}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.9729718537273584e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.29527875781059265, "policy_loss": -0.0031877963338047266, "vf_loss": 0.2984665632247925, "vf_explained_var": 0.9972654581069946, "kl": 0.0009404985466971993, "entropy": 0.0031388355419039726, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 396000, "num_agent_steps_sampled": 396000, "num_steps_trained": 396000, "num_agent_steps_trained": 396000}, "done": false, "episodes_total": 79200, "training_iteration": 99, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-21", "timestamp": 1628629101, "time_this_iter_s": 3.692687749862671, "time_total_s": 382.62491965293884, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 382.62491965293884, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 35.839999999999996, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.03875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13807033704642416, "mean_inference_ms": 0.5642974497854104, "mean_action_processing_ms": 0.044074823423375854, "mean_env_wait_ms": 0.04817904522709595, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 400000, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 1611.197, "sample_throughput": 2482.626, "load_time_ms": 0.953, "load_throughput": 4195247.931, "learn_time_ms": 2096.462, "learn_throughput": 1907.976, "update_time_ms": 1.416}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.9864859268636792e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.09052250534296036, "policy_loss": -0.008073907345533371, "vf_loss": 0.09859638661146164, "vf_explained_var": 0.9991503357887268, "kl": 0.12966680526733398, "entropy": 0.14325016736984253, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 400000, "num_agent_steps_sampled": 400000, "num_steps_trained": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 80000, "training_iteration": 100, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-25", "timestamp": 1628629105, "time_this_iter_s": 3.6389691829681396, "time_total_s": 386.263888835907, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 386.263888835907, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 36.019999999999996, "ram_util_percent": 75.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 37.916001589900006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 35.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13801017095946785, "mean_inference_ms": 0.5640223083153528, "mean_action_processing_ms": 0.04405042114723129, "mean_env_wait_ms": 0.04815927059978387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 404000, "agent_timesteps_total": 404000, "timers": {"sample_time_ms": 1611.385, "sample_throughput": 2482.337, "load_time_ms": 0.969, "load_throughput": 4130081.237, "learn_time_ms": 2099.515, "learn_throughput": 1905.202, "update_time_ms": 1.429}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.979728890295519e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.08276309818029404, "policy_loss": -0.10263245552778244, "vf_loss": 0.019869321957230568, "vf_explained_var": 0.999826192855835, "kl": 0.1874607503414154, "entropy": 0.26060500741004944, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 404000, "num_agent_steps_sampled": 404000, "num_steps_trained": 404000, "num_agent_steps_trained": 404000}, "done": false, "episodes_total": 80800, "training_iteration": 101, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-29", "timestamp": 1628629109, "time_this_iter_s": 3.6924221515655518, "time_total_s": 389.95631098747253, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 389.95631098747253, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 36.91666666666667, "ram_util_percent": 75.53333333333333}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.05, "episode_reward_mean": 37.793826086200006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.58245576, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 34.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.80647976, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.58245576, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 33.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 34.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 33.05, 32.05, 37.76607976, 38.05, 38.05, 32.62285576, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 34.05, 37.80647976, 38.05, 38.05, 38.05, 37.76607976, 33.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 32.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1379396967314952, "mean_inference_ms": 0.5636943020011098, "mean_action_processing_ms": 0.0440244263856695, "mean_env_wait_ms": 0.04813401209527433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 408000, "agent_timesteps_total": 408000, "timers": {"sample_time_ms": 1578.895, "sample_throughput": 2533.417, "load_time_ms": 0.97, "load_throughput": 4124091.345, "learn_time_ms": 2106.147, "learn_throughput": 1899.203, "update_time_ms": 1.431}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.4695934775518253e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.5739017128944397, "policy_loss": -0.03855811804533005, "vf_loss": 0.612459659576416, "vf_explained_var": 0.9945117831230164, "kl": 0.06264998763799667, "entropy": 0.03766297549009323, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 408000, "num_agent_steps_sampled": 408000, "num_steps_trained": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 81600, "training_iteration": 102, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-33", "timestamp": 1628629113, "time_this_iter_s": 3.650527000427246, "time_total_s": 393.6068379878998, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 393.6068379878998, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 75.52000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 38.02972160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 31.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13789895623616366, "mean_inference_ms": 0.5635642001240244, "mean_action_processing_ms": 0.044008045424395445, "mean_env_wait_ms": 0.0481240722195748, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 412000, "agent_timesteps_total": 412000, "timers": {"sample_time_ms": 1586.989, "sample_throughput": 2520.497, "load_time_ms": 0.968, "load_throughput": 4133948.354, "learn_time_ms": 2103.014, "learn_throughput": 1902.032, "update_time_ms": 1.435}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.704390216327738e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08405549079179764, "policy_loss": -0.00418872619047761, "vf_loss": 0.08824420720338821, "vf_explained_var": 0.9991857409477234, "kl": 0.0002842604590114206, "entropy": 0.00964368972927332, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 412000, "num_agent_steps_sampled": 412000, "num_steps_trained": 412000, "num_agent_steps_trained": 412000}, "done": false, "episodes_total": 82400, "training_iteration": 103, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-36", "timestamp": 1628629116, "time_this_iter_s": 3.698207139968872, "time_total_s": 397.30504512786865, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 397.30504512786865, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 36.08, "ram_util_percent": 75.32000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 38.039366709400014, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13786012366727207, "mean_inference_ms": 0.5634031082759562, "mean_action_processing_ms": 0.04399184078533629, "mean_env_wait_ms": 0.04811150948096163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 416000, "agent_timesteps_total": 416000, "timers": {"sample_time_ms": 1587.429, "sample_throughput": 2519.798, "load_time_ms": 0.965, "load_throughput": 4144262.036, "learn_time_ms": 2103.032, "learn_throughput": 1902.015, "update_time_ms": 1.435}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.352195108163869e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.022673137485980988, "policy_loss": -0.0039277710020542145, "vf_loss": 0.026600908488035202, "vf_explained_var": 0.9997645020484924, "kl": 0.0006205156678333879, "entropy": 0.004865894094109535, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 416000, "num_agent_steps_sampled": 416000, "num_steps_trained": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 83200, "training_iteration": 104, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-40", "timestamp": 1628629120, "time_this_iter_s": 3.6813700199127197, "time_total_s": 400.9864151477814, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 400.9864151477814, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 37.5, "ram_util_percent": 75.41666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.05, "episode_reward_mean": 38.03561670940001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13782178439814527, "mean_inference_ms": 0.5632249862389194, "mean_action_processing_ms": 0.04397587100872349, "mean_env_wait_ms": 0.048098588284877106, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 420000, "agent_timesteps_total": 420000, "timers": {"sample_time_ms": 1552.466, "sample_throughput": 2576.546, "load_time_ms": 0.961, "load_throughput": 4160396.766, "learn_time_ms": 2111.458, "learn_throughput": 1894.426, "update_time_ms": 1.46}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.6760975540819345e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.028011254966259003, "policy_loss": -0.0049284216947853565, "vf_loss": 0.03293967247009277, "vf_explained_var": 0.9997251033782959, "kl": 0.00011156666005263105, "entropy": 0.0036676153540611267, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 420000, "num_agent_steps_sampled": 420000, "num_steps_trained": 420000, "num_agent_steps_trained": 420000}, "done": false, "episodes_total": 84000, "training_iteration": 105, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-44", "timestamp": 1628629124, "time_this_iter_s": 3.7068750858306885, "time_total_s": 404.69329023361206, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 404.69329023361206, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 36.22, "ram_util_percent": 75.7}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.76607976, "episode_reward_mean": 38.04964509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1377558288823612, "mean_inference_ms": 0.56290093966513, "mean_action_processing_ms": 0.04394852234118047, "mean_env_wait_ms": 0.048076213928600085, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 424000, "agent_timesteps_total": 424000, "timers": {"sample_time_ms": 1556.272, "sample_throughput": 2570.245, "load_time_ms": 0.956, "load_throughput": 4184261.772, "learn_time_ms": 2105.852, "learn_throughput": 1899.468, "update_time_ms": 1.449}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.380487770409673e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -0.07646964490413666, "policy_loss": -0.07671759277582169, "vf_loss": 0.00024791291798464954, "vf_explained_var": 0.9999978542327881, "kl": 0.33963170647621155, "entropy": 0.24428020417690277, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 424000, "num_agent_steps_sampled": 424000, "num_steps_trained": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 84800, "training_iteration": 106, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-47", "timestamp": 1628629127, "time_this_iter_s": 3.6230688095092773, "time_total_s": 408.31635904312134, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 408.31635904312134, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 36.04, "ram_util_percent": 75.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.050000000000004, "episode_reward_mean": 30.25000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 22.050000000000004, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.05, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 38.05, 30.05, 38.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 38.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 22.050000000000004, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 38.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.05, 30.05, 30.05, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 30.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1377341594663335, "mean_inference_ms": 0.5628108252992186, "mean_action_processing_ms": 0.043937275023896695, "mean_env_wait_ms": 0.04807055149957796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 428000, "agent_timesteps_total": 428000, "timers": {"sample_time_ms": 1559.466, "sample_throughput": 2564.98, "load_time_ms": 0.959, "load_throughput": 4170739.323, "learn_time_ms": 2105.039, "learn_throughput": 1900.202, "update_time_ms": 1.458}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.257073165561451e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 15.40503215789795, "policy_loss": -0.058070674538612366, "vf_loss": 15.463101387023926, "vf_explained_var": 0.8633514642715454, "kl": 0.10684279352426529, "entropy": 0.17460958659648895, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 428000, "num_agent_steps_sampled": 428000, "num_steps_trained": 428000, "num_agent_steps_trained": 428000}, "done": false, "episodes_total": 85600, "training_iteration": 107, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-51", "timestamp": 1628629131, "time_this_iter_s": 3.713899850845337, "time_total_s": 412.0302588939667, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 412.0302588939667, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 36.9, "ram_util_percent": 75.62}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.050000000000004, "episode_reward_mean": 35.220000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 22.050000000000004, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.050000000000004, 22.050000000000004, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 22.050000000000004, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 22.050000000000004, 38.05, 38.05, 30.05, 22.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 30.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13767149002896267, "mean_inference_ms": 0.5625694183429508, "mean_action_processing_ms": 0.04391442218264317, "mean_env_wait_ms": 0.04805105809729942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 432000, "agent_timesteps_total": 432000, "timers": {"sample_time_ms": 1551.282, "sample_throughput": 2578.512, "load_time_ms": 0.95, "load_throughput": 4209458.049, "learn_time_ms": 2108.818, "learn_throughput": 1896.797, "update_time_ms": 1.485}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.8856097483421763e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 16.973508834838867, "policy_loss": -0.054509375244379044, "vf_loss": 17.028018951416016, "vf_explained_var": 0.8631538152694702, "kl": 0.3309747874736786, "entropy": 0.0036595044657588005, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 432000, "num_agent_steps_sampled": 432000, "num_steps_trained": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 86400, "training_iteration": 108, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-55", "timestamp": 1628629135, "time_this_iter_s": 3.6874749660491943, "time_total_s": 415.71773386001587, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 415.71773386001587, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 37.166666666666664, "ram_util_percent": 75.60000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.050000000000004, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13763262452000047, "mean_inference_ms": 0.5623403961214748, "mean_action_processing_ms": 0.04389544899216782, "mean_env_wait_ms": 0.0480370603766633, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 436000, "agent_timesteps_total": 436000, "timers": {"sample_time_ms": 1552.673, "sample_throughput": 2576.203, "load_time_ms": 0.949, "load_throughput": 4216652.257, "learn_time_ms": 2106.428, "learn_throughput": 1898.949, "update_time_ms": 1.499}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.828414551458991e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.010611270554363728, "policy_loss": -0.06970600038766861, "vf_loss": 0.08031725138425827, "vf_explained_var": 0.9993160963058472, "kl": 0.104167141020298, "entropy": 0.15567553043365479, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 436000, "num_agent_steps_sampled": 436000, "num_steps_trained": 436000, "num_agent_steps_trained": 436000}, "done": false, "episodes_total": 87200, "training_iteration": 109, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-58-59", "timestamp": 1628629139, "time_this_iter_s": 3.682426691055298, "time_total_s": 419.40016055107117, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 419.40016055107117, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 35.9, "ram_util_percent": 75.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 36.80500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 30.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 29.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 30.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.050000000000004, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 30.05, 38.05, 34.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 35.05, 29.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 30.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13758571844065273, "mean_inference_ms": 0.5621690382655689, "mean_action_processing_ms": 0.043877648184304584, "mean_env_wait_ms": 0.04802372030119229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 440000, "agent_timesteps_total": 440000, "timers": {"sample_time_ms": 1555.402, "sample_throughput": 2571.682, "load_time_ms": 0.948, "load_throughput": 4220577.092, "learn_time_ms": 2108.453, "learn_throughput": 1897.125, "update_time_ms": 1.497}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.2426219692970335e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 2.5864040851593018, "policy_loss": -0.05527530238032341, "vf_loss": 2.641679525375366, "vf_explained_var": 0.9772130250930786, "kl": 0.23690088093280792, "entropy": 0.012475010938942432, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 440000, "num_agent_steps_sampled": 440000, "num_steps_trained": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 88000, "training_iteration": 110, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-02", "timestamp": 1628629142, "time_this_iter_s": 3.6867449283599854, "time_total_s": 423.08690547943115, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 423.08690547943115, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 36.58, "ram_util_percent": 75.82000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.03875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1375285480081079, "mean_inference_ms": 0.5619358823858733, "mean_action_processing_ms": 0.043856315304869255, "mean_env_wait_ms": 0.04800426386017421, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 444000, "agent_timesteps_total": 444000, "timers": {"sample_time_ms": 1555.044, "sample_throughput": 2572.275, "load_time_ms": 0.941, "load_throughput": 4249440.49, "learn_time_ms": 2107.567, "learn_throughput": 1897.923, "update_time_ms": 1.488}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.363932811837003e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.02955499477684498, "policy_loss": -0.00310550001449883, "vf_loss": 0.03266049176454544, "vf_explained_var": 0.9997096657752991, "kl": 0.0020621479488909245, "entropy": 0.0037599389906972647, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 444000, "num_agent_steps_sampled": 444000, "num_steps_trained": 444000, "num_agent_steps_trained": 444000}, "done": false, "episodes_total": 88800, "training_iteration": 111, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-06", "timestamp": 1628629146, "time_this_iter_s": 3.679896831512451, "time_total_s": 426.7668023109436, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 426.7668023109436, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 36.1, "ram_util_percent": 75.8}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.04625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1374746772747074, "mean_inference_ms": 0.5617034510256653, "mean_action_processing_ms": 0.04383407655204767, "mean_env_wait_ms": 0.04798621229959151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 448000, "agent_timesteps_total": 448000, "timers": {"sample_time_ms": 1556.458, "sample_throughput": 2569.938, "load_time_ms": 0.936, "load_throughput": 4273578.888, "learn_time_ms": 2108.955, "learn_throughput": 1896.674, "update_time_ms": 1.486}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.1819664059185016e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.008070888929069042, "policy_loss": -0.0020259565208107233, "vf_loss": 0.010096844285726547, "vf_explained_var": 0.9999130964279175, "kl": 8.376631740247831e-05, "entropy": 0.003089450066909194, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 448000, "num_agent_steps_sampled": 448000, "num_steps_trained": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 89600, "training_iteration": 112, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-10", "timestamp": 1628629150, "time_this_iter_s": 3.678391933441162, "time_total_s": 430.44519424438477, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 430.44519424438477, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 37.06666666666667, "ram_util_percent": 75.61666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1374510273349035, "mean_inference_ms": 0.5616234687370945, "mean_action_processing_ms": 0.04382283518135769, "mean_env_wait_ms": 0.04798074818728873, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 452000, "agent_timesteps_total": 452000, "timers": {"sample_time_ms": 1557.465, "sample_throughput": 2568.276, "load_time_ms": 0.938, "load_throughput": 4263478.946, "learn_time_ms": 2112.961, "learn_throughput": 1893.078, "update_time_ms": 1.496}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.5909832029592508e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.07931279391050339, "policy_loss": -0.0793129950761795, "vf_loss": 1.0085122400551021e-14, "vf_explained_var": 1.0, "kl": 1.2348483800888062, "entropy": 0.1792711764574051, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 452000, "num_agent_steps_sampled": 452000, "num_steps_trained": 452000, "num_agent_steps_trained": 452000}, "done": false, "episodes_total": 90400, "training_iteration": 113, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-14", "timestamp": 1628629154, "time_this_iter_s": 3.7485151290893555, "time_total_s": 434.1937093734741, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 434.1937093734741, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 75.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.190188000000003, "episode_reward_mean": 33.317381669899994, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.270988, 32.270988, 32.270988, 32.49800776, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.500439760000006, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.05, 37.05, 37.827287760000004, 32.270988, 36.70487176, 31.190188000000003, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 37.827287760000004, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 37.827287760000004, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 37.827287760000004, 32.270988, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 33.05, 32.270988, 32.270988, 32.270988, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 32.270988, 32.270988, 37.76607976, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.31560776, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 38.05, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.05, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 36.70487176, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.45760776, 32.270988, 32.56164776, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 36.70487176, 37.827287760000004, 32.270988, 37.05, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.05, 37.05, 32.270988, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.230588000000004, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 36.74527176000001, 37.05, 32.270988, 32.500439760000006, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 31.190188000000003, 32.270988, 32.56164776, 32.270988, 32.270988, 32.270988, 32.500439760000006, 37.05, 32.270988, 32.270988, 32.270988, 37.05, 32.230588000000004, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.05, 37.05, 32.270988, 37.05, 36.74527176000001, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 31.190188000000003, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.56164776, 32.270988, 37.05, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 37.827287760000004, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 32.230588000000004, 32.270988, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 37.05, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 37.827287760000004, 32.270988, 37.05, 32.270988, 32.270988, 37.827287760000004, 37.827287760000004, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 31.190188000000003, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 37.05, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.56164776, 32.270988, 32.270988, 37.827287760000004, 32.500439760000006, 32.270988, 36.70487176, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 32.270988, 37.827287760000004, 32.270988, 32.270988], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13739506845235283, "mean_inference_ms": 0.5613705656415444, "mean_action_processing_ms": 0.04380113020773974, "mean_env_wait_ms": 0.0479613969569885, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 456000, "agent_timesteps_total": 456000, "timers": {"sample_time_ms": 1553.652, "sample_throughput": 2574.578, "load_time_ms": 0.944, "load_throughput": 4235494.181, "learn_time_ms": 2113.613, "learn_throughput": 1892.494, "update_time_ms": 1.494}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.38647487549315e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.7446377873420715, "policy_loss": -0.08915932476520538, "vf_loss": 0.8337971568107605, "vf_explained_var": 0.9938217997550964, "kl": 0.2300270050764084, "entropy": 0.42641550302505493, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 456000, "num_agent_steps_sampled": 456000, "num_steps_trained": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 91200, "training_iteration": 114, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-17", "timestamp": 1628629157, "time_this_iter_s": 3.6497840881347656, "time_total_s": 437.8434934616089, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 437.8434934616089, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 36.46, "ram_util_percent": 75.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.190188000000003, "episode_reward_mean": 36.4857340831, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 36.70487176, 37.05, 32.270988, 32.270988, 37.05, 37.05, 37.827287760000004, 37.05, 33.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 32.270988, 37.05, 32.270988, 37.05, 37.05, 32.270988, 32.270988, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 32.270988, 37.05, 36.70487176, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.70487176, 32.270988, 32.270988, 37.827287760000004, 37.05, 32.270988, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 32.270988, 32.270988, 32.270988, 37.827287760000004, 37.05, 37.827287760000004, 36.70487176, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 32.270988, 37.05, 37.827287760000004, 32.270988, 32.270988, 37.05, 32.270988, 37.827287760000004, 32.270988, 37.05, 36.70487176, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 32.270988, 37.05, 36.70487176, 32.270988, 37.05, 37.05, 37.05, 37.05, 32.270988, 32.270988, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 36.70487176, 36.70487176, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 32.270988, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.05, 32.270988, 32.230588000000004, 37.05, 37.05, 32.270988, 37.05, 37.827287760000004, 36.70487176, 37.05, 38.05, 32.270988, 37.05, 32.270988, 37.827287760000004, 37.05, 32.270988, 37.05, 32.270988, 32.270988, 37.05, 37.827287760000004, 37.05, 32.270988, 32.270988, 37.05, 36.70487176, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 36.70487176, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.74527176000001, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.05, 32.270988, 37.05, 37.827287760000004, 36.70487176, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 31.190188000000003, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 32.270988, 37.05, 32.270988, 37.05, 37.05, 38.05, 32.270988, 32.270988, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 36.70487176, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 32.270988, 32.270988, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 37.827287760000004, 37.05, 32.270988, 36.74527176000001, 37.05, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 34.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 32.270988, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 32.270988, 36.68406376, 37.05, 38.05, 37.05, 37.05, 37.05, 36.74527176000001, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.827287760000004, 37.05, 36.70487176, 36.70487176, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 36.70487176, 37.05, 31.190188000000003, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 32.270988, 37.05, 37.05, 37.05, 36.70487176, 32.270988, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 32.270988, 38.05, 37.05, 37.05, 32.270988, 32.270988, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 38.05, 37.05, 32.270988, 37.827287760000004, 37.05, 32.270988, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 32.230588000000004, 38.05, 36.70487176, 36.70487176, 36.70487176, 37.05, 36.74527176000001, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 32.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 37.05, 37.05, 36.70487176, 32.270988, 37.05, 32.270988, 36.70487176, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.827287760000004, 32.270988, 36.70487176, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 35.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.05, 32.270988, 32.270988, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 38.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.70487176, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 37.05, 37.827287760000004, 32.270988, 32.270988, 37.827287760000004, 37.827287760000004, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.827287760000004, 32.270988, 37.05, 37.05, 36.70487176, 37.05, 37.05, 37.05, 37.827287760000004, 36.70487176, 37.827287760000004, 36.70487176, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 32.270988, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 36.70487176, 36.70487176, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.827287760000004, 32.270988, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.70487176, 36.70487176, 37.05, 37.05, 36.70487176, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 32.270988, 37.05, 36.70487176, 36.70487176, 37.05, 36.70487176, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 32.270988, 32.270988, 37.05, 37.05, 37.05, 37.05, 32.270988, 37.05, 37.827287760000004, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13734320862483018, "mean_inference_ms": 0.5610926966114232, "mean_action_processing_ms": 0.043778984834452084, "mean_env_wait_ms": 0.04794303688000455, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 460000, "agent_timesteps_total": 460000, "timers": {"sample_time_ms": 1549.762, "sample_throughput": 2581.042, "load_time_ms": 0.948, "load_throughput": 4220152.434, "learn_time_ms": 2114.575, "learn_throughput": 1891.633, "update_time_ms": 1.479}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.5797123132397246e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.6249368190765381, "policy_loss": -0.09273736923933029, "vf_loss": 0.7176740169525146, "vf_explained_var": 0.9939174652099609, "kl": 0.4371744692325592, "entropy": 0.3166956305503845, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 460000, "num_agent_steps_sampled": 460000, "num_steps_trained": 460000, "num_agent_steps_trained": 460000}, "done": false, "episodes_total": 92000, "training_iteration": 115, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-21", "timestamp": 1628629161, "time_this_iter_s": 3.678253650665283, "time_total_s": 441.52174711227417, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 441.52174711227417, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 37.050000000000004, "ram_util_percent": 75.60000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.52124776, "episode_reward_mean": 37.8094011831, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 32.52124776, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 36.70487176, 38.05, 38.05, 38.05, 37.05, 37.76607976, 38.05, 38.05, 37.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 36.643663759999995, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 36.70487176, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 36.70487176, 38.05, 38.05, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 36.70487176, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 37.76607976, 37.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.76607976, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 36.70487176, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 36.70487176, 38.05, 38.05, 37.05, 37.76607976, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 37.05, 32.56164776, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.76607976, 37.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 36.70487176, 37.76607976, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.05, 36.70487176, 38.05, 37.827287760000004, 36.70487176, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 36.05, 38.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 37.76607976, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 37.827287760000004, 36.70487176, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 36.70487176, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 36.70487176, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 36.74527176000001, 38.05, 38.05, 38.05, 38.05, 37.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 36.70487176, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 36.70487176, 38.05, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 36.70487176, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 36.643663759999995, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 36.643663759999995, 37.05, 38.05, 38.05, 38.05, 36.70487176, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 36.70487176, 37.827287760000004, 37.05, 37.827287760000004, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 36.70487176, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 36.70487176, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.05, 38.05, 36.70487176, 37.76607976, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13733546022025664, "mean_inference_ms": 0.5610618285435319, "mean_action_processing_ms": 0.04377230375558269, "mean_env_wait_ms": 0.04794261724176975, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 464000, "agent_timesteps_total": 464000, "timers": {"sample_time_ms": 1559.257, "sample_throughput": 2565.324, "load_time_ms": 0.95, "load_throughput": 4209563.668, "learn_time_ms": 2114.31, "learn_throughput": 1891.87, "update_time_ms": 1.474}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.369568043533945e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.056189585477113724, "policy_loss": -0.06276154518127441, "vf_loss": 0.11895102262496948, "vf_explained_var": 0.9989469051361084, "kl": 0.2099183052778244, "entropy": 0.15691019594669342, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 464000, "num_agent_steps_sampled": 464000, "num_steps_trained": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 92800, "training_iteration": 116, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-25", "timestamp": 1628629165, "time_this_iter_s": 3.7151339054107666, "time_total_s": 445.23688101768494, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 445.23688101768494, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 75.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.05, "episode_reward_mean": 37.711937706700006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 37.827287760000004, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 33.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1373064432338119, "mean_inference_ms": 0.5609467775584155, "mean_action_processing_ms": 0.043759500327632705, "mean_env_wait_ms": 0.04793350100754162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 468000, "agent_timesteps_total": 468000, "timers": {"sample_time_ms": 1557.739, "sample_throughput": 2567.824, "load_time_ms": 0.949, "load_throughput": 4217076.212, "learn_time_ms": 2116.593, "learn_throughput": 1889.829, "update_time_ms": 1.461}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.054352633735107e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.0584148168563843, "policy_loss": -0.029702190309762955, "vf_loss": 1.0881168842315674, "vf_explained_var": 0.9900951981544495, "kl": 0.04222816601395607, "entropy": 0.024244852364063263, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 468000, "num_agent_steps_sampled": 468000, "num_steps_trained": 468000, "num_agent_steps_trained": 468000}, "done": false, "episodes_total": 93600, "training_iteration": 117, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-29", "timestamp": 1628629169, "time_this_iter_s": 4.013356924057007, "time_total_s": 449.25023794174194, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 449.25023794174194, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 35.03333333333334, "ram_util_percent": 75.7}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 38.01380992880001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 32.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1372244271575761, "mean_inference_ms": 0.5605441896665531, "mean_action_processing_ms": 0.04372809609222378, "mean_env_wait_ms": 0.047904245504920215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 472000, "agent_timesteps_total": 472000, "timers": {"sample_time_ms": 1551.586, "sample_throughput": 2578.008, "load_time_ms": 0.949, "load_throughput": 4216016.485, "learn_time_ms": 2112.41, "learn_throughput": 1893.572, "update_time_ms": 1.445}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.2081528666385566e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.15092124044895172, "policy_loss": -0.006631037686020136, "vf_loss": 0.15755228698253632, "vf_explained_var": 0.9985981583595276, "kl": 0.0013417241862043738, "entropy": 0.008937865495681763, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 472000, "num_agent_steps_sampled": 472000, "num_steps_trained": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 94400, "training_iteration": 118, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-32", "timestamp": 1628629172, "time_this_iter_s": 3.5843918323516846, "time_total_s": 452.8346297740936, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 452.8346297740936, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 36.78, "ram_util_percent": 75.7}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.0454747579, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1372315697400291, "mean_inference_ms": 0.5605811123611528, "mean_action_processing_ms": 0.04372699380491458, "mean_env_wait_ms": 0.04790874845455145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 476000, "agent_timesteps_total": 476000, "timers": {"sample_time_ms": 1558.746, "sample_throughput": 2566.166, "load_time_ms": 0.949, "load_throughput": 4216016.485, "learn_time_ms": 2114.03, "learn_throughput": 1892.121, "update_time_ms": 1.433}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.040764333192783e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.003146372502669692, "policy_loss": -0.0025180683005601168, "vf_loss": 0.005664442665874958, "vf_explained_var": 0.9999470114707947, "kl": 0.00047649297630414367, "entropy": 0.004587124567478895, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 476000, "num_agent_steps_sampled": 476000, "num_steps_trained": 476000, "num_agent_steps_trained": 476000}, "done": false, "episodes_total": 95200, "training_iteration": 119, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-36", "timestamp": 1628629176, "time_this_iter_s": 3.769906997680664, "time_total_s": 456.6045367717743, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 456.6045367717743, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 36.279999999999994, "ram_util_percent": 75.8}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13718172124838612, "mean_inference_ms": 0.5603538132764494, "mean_action_processing_ms": 0.04370695817443779, "mean_env_wait_ms": 0.04789027733963549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 480000, "agent_timesteps_total": 480000, "timers": {"sample_time_ms": 1556.084, "sample_throughput": 2570.555, "load_time_ms": 0.949, "load_throughput": 4215592.743, "learn_time_ms": 2116.685, "learn_throughput": 1889.747, "update_time_ms": 1.439}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.0203821665963915e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0017204326577484608, "policy_loss": -0.00255750329233706, "vf_loss": 0.0008370706345885992, "vf_explained_var": 0.9999920129776001, "kl": 0.00013487570686265826, "entropy": 0.0021910793147981167, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 480000, "num_agent_steps_sampled": 480000, "num_steps_trained": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 96000, "training_iteration": 120, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-40", "timestamp": 1628629180, "time_this_iter_s": 3.686569929122925, "time_total_s": 460.2911067008972, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 460.2911067008972, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 35.86, "ram_util_percent": 75.8}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13716012457061488, "mean_inference_ms": 0.5602511035869489, "mean_action_processing_ms": 0.04369788004131056, "mean_env_wait_ms": 0.04788381468237386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 484000, "agent_timesteps_total": 484000, "timers": {"sample_time_ms": 1560.198, "sample_throughput": 2563.777, "load_time_ms": 0.938, "load_throughput": 4263695.647, "learn_time_ms": 2112.448, "learn_throughput": 1893.538, "update_time_ms": 1.45}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.5101910832981957e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.14708580076694489, "policy_loss": -0.14708605408668518, "vf_loss": 6.578250314262513e-14, "vf_explained_var": 1.0, "kl": 1.7033499479293823, "entropy": 0.23009184002876282, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 484000, "num_agent_steps_sampled": 484000, "num_steps_trained": 484000, "num_agent_steps_trained": 484000}, "done": false, "episodes_total": 96800, "training_iteration": 121, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-44", "timestamp": 1628629184, "time_this_iter_s": 3.6793479919433594, "time_total_s": 463.9704546928406, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 463.9704546928406, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 37.53333333333333, "ram_util_percent": 75.93333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 29.050000000000004, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 16.696250000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 29.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 29.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 20.049999999999997, 20.05, 20.049999999999997, 20.05, 11.049999999999999, 11.049999999999999, 29.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 29.050000000000004, 11.049999999999999, 29.050000000000004, 20.049999999999997, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.050000000000004, 29.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 29.05, 29.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 29.050000000000004, 19.050000000000004, 20.050000000000004, 20.049999999999997, 20.049999999999997, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 29.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 29.05, 20.049999999999997, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 29.050000000000004, 29.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 29.05, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 11.049999999999999, 29.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.05, 20.05, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.050000000000004, 29.050000000000004, 29.05, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 29.050000000000004, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 29.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 29.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 29.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.05, 20.05, 11.049999999999999, 29.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.049999999999997, 20.05, 11.049999999999999, 20.05, 20.049999999999997, 11.049999999999999, 20.05, 29.050000000000004, 11.049999999999999, 11.049999999999999, 29.05, 20.049999999999997, 20.050000000000004, 20.049999999999997, 20.049999999999997, 29.049999999999997, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.05, 29.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.05, 29.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 29.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.05, 11.049999999999999, 20.050000000000004, 20.05, 20.049999999999997, 11.049999999999999, 20.049999999999997, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.05, 29.049999999999997, 20.05, 29.050000000000004, 20.049999999999997, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.049999999999997, 11.049999999999999, 29.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.05, 29.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 29.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.049999999999997, 29.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.05, 11.049999999999999, 29.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.049999999999997, 11.049999999999999, 29.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 29.050000000000004, 20.05, 20.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 29.049999999999997, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 29.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 29.049999999999997, 20.05, 20.050000000000004, 29.05, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.05, 20.05, 11.049999999999999, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13716458511160246, "mean_inference_ms": 0.5602658186533762, "mean_action_processing_ms": 0.043696318224177674, "mean_env_wait_ms": 0.04788730686421989, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 488000, "agent_timesteps_total": 488000, "timers": {"sample_time_ms": 1567.76, "sample_throughput": 2551.411, "load_time_ms": 0.945, "load_throughput": 4230687.916, "learn_time_ms": 2109.377, "learn_throughput": 1896.294, "update_time_ms": 1.463}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.2652866960015672e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 121.10102081298828, "policy_loss": -0.0788465067744255, "vf_loss": 121.17987060546875, "vf_explained_var": 0.6026037931442261, "kl": 0.049204014241695404, "entropy": 0.3632284700870514, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 488000, "num_agent_steps_sampled": 488000, "num_steps_trained": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 97600, "training_iteration": 122, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-47", "timestamp": 1628629187, "time_this_iter_s": 3.722978115081787, "time_total_s": 467.69343280792236, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 467.69343280792236, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 75.96}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 29.050000000000004, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 19.948750000000008, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 29.05, 29.049999999999997, 20.05, 20.049999999999997, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 29.049999999999997, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.049999999999997, 20.05, 20.05, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.05, 29.05, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 20.05, 29.050000000000004, 20.05, 20.050000000000004, 29.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 20.049999999999997, 20.05, 29.05, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.05, 11.049999999999999, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.049999999999997, 20.05, 20.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.05, 20.050000000000004, 20.05, 20.049999999999997, 20.049999999999997, 20.050000000000004, 20.05, 29.050000000000004, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 29.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 29.05, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 29.050000000000004, 29.049999999999997, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.049999999999997, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 11.049999999999999, 20.049999999999997, 29.05, 20.05, 20.050000000000004, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.049999999999997, 20.050000000000004, 20.05, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.049999999999997, 29.05, 29.050000000000004, 20.05, 29.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 20.05, 29.05, 29.05, 20.050000000000004, 20.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.049999999999997, 29.05, 20.050000000000004, 20.049999999999997, 20.049999999999997, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.049999999999997, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 20.05, 20.050000000000004, 20.049999999999997, 20.049999999999997, 29.05, 20.049999999999997, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.05, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 29.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.050000000000004, 29.050000000000004, 11.049999999999999, 11.049999999999999, 29.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.05, 11.049999999999999, 20.049999999999997, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 11.049999999999999, 29.050000000000004, 20.05, 29.05, 20.050000000000004, 29.05, 11.049999999999999, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.050000000000004, 29.05, 11.049999999999999, 20.05, 20.050000000000004, 11.049999999999999, 20.05, 20.05, 29.049999999999997, 20.050000000000004, 20.049999999999997, 11.049999999999999, 11.049999999999999, 29.05, 11.049999999999999, 29.049999999999997, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.049999999999997, 29.049999999999997, 29.05, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.05, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.05, 20.05, 29.050000000000004, 29.05, 11.049999999999999, 20.049999999999997, 29.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 29.049999999999997, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 29.05, 11.049999999999999, 29.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.049999999999997, 29.05, 11.049999999999999, 20.050000000000004, 29.05, 20.05, 11.049999999999999, 29.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 11.049999999999999, 29.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 20.05, 29.05, 20.05, 20.049999999999997, 20.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.05, 29.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.049999999999997, 29.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.049999999999997, 20.05, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.05, 20.05, 20.049999999999997, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.05, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.049999999999997, 20.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 20.049999999999997, 29.05, 29.049999999999997, 20.049999999999997, 29.050000000000004, 20.050000000000004, 29.05, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.05, 11.049999999999999, 20.05, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.049999999999997, 29.05, 20.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 11.049999999999999, 20.05, 29.05, 20.050000000000004, 11.049999999999999, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.05, 29.050000000000004, 20.049999999999997, 20.049999999999997, 29.049999999999997, 20.049999999999997, 11.049999999999999, 11.049999999999999, 29.050000000000004, 20.049999999999997, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13711695398723348, "mean_inference_ms": 0.5600616524192096, "mean_action_processing_ms": 0.04367739912330634, "mean_env_wait_ms": 0.047869856977140426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 492000, "agent_timesteps_total": 492000, "timers": {"sample_time_ms": 1562.601, "sample_throughput": 2559.834, "load_time_ms": 0.948, "load_throughput": 4220895.643, "learn_time_ms": 2108.108, "learn_throughput": 1897.436, "update_time_ms": 1.439}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.3979299018938036e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 20.507009506225586, "policy_loss": -0.08084128797054291, "vf_loss": 20.587848663330078, "vf_explained_var": 0.7167766690254211, "kl": 0.06222885474562645, "entropy": 0.3828001022338867, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 492000, "num_agent_steps_sampled": 492000, "num_steps_trained": 492000, "num_agent_steps_trained": 492000}, "done": false, "episodes_total": 98400, "training_iteration": 123, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-51", "timestamp": 1628629191, "time_this_iter_s": 3.6845219135284424, "time_total_s": 471.3779547214508, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 471.3779547214508, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 35.879999999999995, "ram_util_percent": 75.82000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 24.077500000000008, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.050000000000004, 20.05, 20.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.05, 29.050000000000004, 20.05, 20.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 20.049999999999997, 29.05, 20.050000000000004, 20.05, 20.049999999999997, 20.050000000000004, 20.050000000000004, 29.05, 20.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 20.049999999999997, 11.049999999999999, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.05, 29.050000000000004, 20.05, 29.050000000000004, 29.050000000000004, 20.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 20.049999999999997, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 20.049999999999997, 20.049999999999997, 20.050000000000004, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 11.049999999999999, 20.05, 20.05, 11.049999999999999, 29.05, 20.05, 20.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.049999999999997, 11.049999999999999, 29.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 29.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 20.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 29.05, 29.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 20.049999999999997, 29.049999999999997, 29.049999999999997, 29.050000000000004, 20.05, 29.05, 20.05, 20.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.049999999999997, 20.049999999999997, 29.05, 29.050000000000004, 20.049999999999997, 20.049999999999997, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.05, 20.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.049999999999997, 11.049999999999999, 29.049999999999997, 20.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 29.05, 29.05, 29.050000000000004, 11.049999999999999, 20.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.05, 29.050000000000004, 20.049999999999997, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.049999999999997, 29.050000000000004, 20.05, 29.050000000000004, 29.049999999999997, 29.05, 11.049999999999999, 20.049999999999997, 29.050000000000004, 29.05, 29.049999999999997, 20.05, 20.050000000000004, 29.049999999999997, 29.05, 29.05, 29.05, 20.049999999999997, 29.050000000000004, 29.05, 29.050000000000004, 20.05, 29.050000000000004, 20.049999999999997, 11.049999999999999, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 20.050000000000004, 20.049999999999997, 20.05, 29.05, 29.05, 20.050000000000004, 20.05, 29.05, 29.05, 29.049999999999997, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.049999999999997, 29.050000000000004, 29.05, 20.05, 29.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 29.05, 29.05, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.05, 20.05, 29.050000000000004, 20.05, 20.05, 20.050000000000004, 20.05, 20.05, 29.05, 29.05, 11.049999999999999, 29.05, 29.049999999999997, 20.05, 20.050000000000004, 29.05, 20.05, 29.050000000000004, 20.050000000000004, 20.049999999999997, 29.050000000000004, 20.049999999999997, 20.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.049999999999997, 29.05, 29.05, 20.049999999999997, 11.049999999999999, 29.050000000000004, 20.049999999999997, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.049999999999997, 29.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.050000000000004, 29.05, 20.049999999999997, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.049999999999997, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.049999999999997, 29.05, 29.05, 11.049999999999999, 11.049999999999999, 11.049999999999999, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.05, 29.05, 20.050000000000004, 29.050000000000004, 20.049999999999997, 11.049999999999999, 29.049999999999997, 29.05, 29.05, 29.05, 29.05, 11.049999999999999, 29.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 29.05, 29.050000000000004, 29.049999999999997, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.049999999999997, 29.049999999999997, 20.050000000000004, 20.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.05, 29.05, 29.05, 29.050000000000004, 29.049999999999997, 20.049999999999997, 20.050000000000004, 29.049999999999997, 29.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.049999999999997, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.049999999999997, 29.05, 29.050000000000004, 20.05, 29.049999999999997, 29.05, 20.050000000000004, 20.049999999999997, 29.05, 20.049999999999997, 20.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 11.049999999999999, 29.05, 20.049999999999997, 20.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.049999999999997, 20.049999999999997, 20.050000000000004, 20.050000000000004, 29.049999999999997, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.05, 20.050000000000004, 29.05, 20.049999999999997, 20.049999999999997, 20.050000000000004, 29.05, 29.05, 29.049999999999997, 29.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 20.05, 20.049999999999997, 29.05, 29.05, 20.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.049999999999997, 20.05, 29.05, 29.049999999999997, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.05, 20.05, 20.049999999999997, 20.050000000000004, 29.05, 11.049999999999999, 29.050000000000004, 20.05, 20.050000000000004, 29.049999999999997, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.05, 20.050000000000004, 29.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.05, 29.05, 20.049999999999997, 29.050000000000004, 29.05, 29.05, 29.049999999999997, 20.05, 29.05, 20.050000000000004, 20.05, 29.049999999999997, 11.049999999999999, 29.05, 29.05, 11.049999999999999, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.05, 20.05, 29.05, 29.05, 29.05, 11.049999999999999, 20.050000000000004, 20.05, 20.05, 20.050000000000004, 29.049999999999997, 29.050000000000004, 29.050000000000004, 29.049999999999997, 20.05, 29.05, 11.049999999999999, 29.050000000000004, 29.049999999999997, 20.050000000000004, 20.050000000000004, 29.049999999999997, 20.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 20.049999999999997, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.05, 20.050000000000004, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.049999999999997, 20.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.049999999999997, 29.049999999999997, 29.050000000000004, 20.05, 20.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.05, 20.050000000000004, 20.05, 11.049999999999999, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 29.05, 20.049999999999997, 20.049999999999997, 20.05, 20.050000000000004, 29.05, 20.049999999999997, 29.050000000000004, 29.049999999999997, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 11.049999999999999, 11.049999999999999, 20.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.049999999999997, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.049999999999997, 29.05, 11.049999999999999, 20.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 20.05, 11.049999999999999, 20.050000000000004, 29.05, 29.05, 20.05, 20.05, 29.05, 29.05, 29.05, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 29.05, 29.049999999999997, 29.050000000000004, 20.05, 20.050000000000004, 20.05, 29.049999999999997, 20.049999999999997, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.049999999999997, 20.050000000000004, 20.05, 20.049999999999997, 29.05, 20.050000000000004, 20.05, 20.049999999999997, 29.05, 11.049999999999999, 20.050000000000004, 20.050000000000004, 29.05, 20.05, 29.049999999999997, 29.05, 29.050000000000004, 20.05, 20.049999999999997, 29.05, 20.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.049999999999997, 20.049999999999997, 29.05, 20.05, 20.049999999999997, 20.05, 20.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 20.05, 29.05, 29.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 29.049999999999997, 20.050000000000004, 11.049999999999999, 20.050000000000004, 20.050000000000004, 20.05, 29.050000000000004, 20.050000000000004, 20.05, 29.05, 20.050000000000004, 20.049999999999997, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.05, 29.05, 29.050000000000004, 29.050000000000004, 20.049999999999997, 29.05, 11.049999999999999, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 11.049999999999999, 20.049999999999997, 29.049999999999997, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 11.049999999999999, 20.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13709870458260176, "mean_inference_ms": 0.5599724100534768, "mean_action_processing_ms": 0.04366774217180123, "mean_env_wait_ms": 0.04786477429307826, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 496000, "agent_timesteps_total": 496000, "timers": {"sample_time_ms": 1567.628, "sample_throughput": 2551.626, "load_time_ms": 0.942, "load_throughput": 4246858.879, "learn_time_ms": 2108.548, "learn_throughput": 1897.04, "update_time_ms": 1.46}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.096894710732158e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 25.798948287963867, "policy_loss": -0.10373956710100174, "vf_loss": 25.902687072753906, "vf_explained_var": 0.7158486247062683, "kl": 0.08271574229001999, "entropy": 0.3098195195198059, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 496000, "num_agent_steps_sampled": 496000, "num_steps_trained": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 99200, "training_iteration": 124, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-55", "timestamp": 1628629195, "time_this_iter_s": 3.704158067703247, "time_total_s": 475.08211278915405, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 475.08211278915405, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 36.42, "ram_util_percent": 75.74}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 11.049999999999999, "episode_reward_mean": 28.86000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.050000000000004, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.05, 20.050000000000004, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 34.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 20.050000000000004, 38.05, 38.05, 38.05, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.049999999999997, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 38.05, 38.05, 29.049999999999997, 29.05, 20.050000000000004, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 38.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.049999999999997, 38.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 20.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 20.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 29.05, 29.049999999999997, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 38.05, 38.05, 20.050000000000004, 20.05, 29.050000000000004, 29.049999999999997, 29.050000000000004, 38.05, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.05, 29.05, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.049999999999997, 29.05, 29.05, 29.05, 29.050000000000004, 20.05, 29.050000000000004, 29.049999999999997, 29.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 28.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.049999999999997, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 20.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 29.049999999999997, 29.050000000000004, 20.049999999999997, 29.05, 29.05, 29.05, 29.05, 29.05, 29.049999999999997, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.049999999999997, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 20.05, 20.049999999999997, 29.05, 29.05, 29.049999999999997, 38.05, 20.05, 38.05, 29.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 20.05, 20.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.049999999999997, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 38.05, 20.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 20.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.049999999999997, 29.05, 29.050000000000004, 29.049999999999997, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 11.049999999999999, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.049999999999997, 29.049999999999997, 29.05, 29.050000000000004, 20.050000000000004, 29.049999999999997, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 20.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.049999999999997, 29.050000000000004, 38.05, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 11.049999999999999, 29.05, 29.05, 29.05, 38.05, 29.05, 20.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.049999999999997, 20.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 38.05, 38.05, 38.05, 11.049999999999999, 20.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.05, 38.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.049999999999997, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.049999999999997, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 38.05, 29.05, 20.049999999999997, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 20.049999999999997, 29.05, 29.050000000000004, 29.05, 29.05, 35.05, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 20.05, 20.050000000000004, 29.05, 20.05, 29.05, 29.05, 20.049999999999997, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 20.049999999999997, 29.05, 29.049999999999997, 38.05, 38.05, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 29.049999999999997, 20.050000000000004, 38.05, 29.05, 29.05, 29.05, 11.049999999999999, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.049999999999997, 29.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.049999999999997, 29.049999999999997, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 38.05, 29.05, 20.049999999999997, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1370584331848769, "mean_inference_ms": 0.5597950821392516, "mean_action_processing_ms": 0.04365195790330731, "mean_env_wait_ms": 0.047851445003979504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 500000, "agent_timesteps_total": 500000, "timers": {"sample_time_ms": 1569.638, "sample_throughput": 2548.358, "load_time_ms": 0.948, "load_throughput": 4218242.526, "learn_time_ms": 2110.365, "learn_throughput": 1895.407, "update_time_ms": 1.466}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.645342634532426e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 27.319700241088867, "policy_loss": -0.0843374952673912, "vf_loss": 27.404035568237305, "vf_explained_var": 0.76241135597229, "kl": 0.2888231575489044, "entropy": 0.11432477831840515, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 500000, "num_agent_steps_sampled": 500000, "num_steps_trained": 500000, "num_agent_steps_trained": 500000}, "done": false, "episodes_total": 100000, "training_iteration": 125, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_22-59-59", "timestamp": 1628629199, "time_this_iter_s": 3.7162368297576904, "time_total_s": 478.79834961891174, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 478.79834961891174, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 36.800000000000004, "ram_util_percent": 75.86666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 36.17625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 20.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 20.050000000000004, 34.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 20.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.050000000000004, 38.05, 29.050000000000004, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13703304079011214, "mean_inference_ms": 0.5597026257638303, "mean_action_processing_ms": 0.04364170484450394, "mean_env_wait_ms": 0.04784350435866089, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 504000, "agent_timesteps_total": 504000, "timers": {"sample_time_ms": 1565.206, "sample_throughput": 2555.574, "load_time_ms": 0.954, "load_throughput": 4190741.869, "learn_time_ms": 2115.443, "learn_throughput": 1890.857, "update_time_ms": 1.482}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.1468013099147356e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 13.377411842346191, "policy_loss": -0.029440168291330338, "vf_loss": 13.406851768493652, "vf_explained_var": 0.8907296657562256, "kl": 0.01468699611723423, "entropy": 0.08338525891304016, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 504000, "num_agent_steps_sampled": 504000, "num_steps_trained": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 100800, "training_iteration": 126, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-02", "timestamp": 1628629202, "time_this_iter_s": 3.7213518619537354, "time_total_s": 482.5197014808655, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 482.5197014808655, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 35.52, "ram_util_percent": 76.05999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.01000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.050000000000004, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 29.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13699032558318142, "mean_inference_ms": 0.5594911353082104, "mean_action_processing_ms": 0.043623142384430935, "mean_env_wait_ms": 0.04782835648128657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 508000, "agent_timesteps_total": 508000, "timers": {"sample_time_ms": 1561.379, "sample_throughput": 2561.839, "load_time_ms": 0.951, "load_throughput": 4206608.329, "learn_time_ms": 2115.602, "learn_throughput": 1890.714, "update_time_ms": 1.479}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.1468013099147356e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 7.828113555908203, "policy_loss": -0.026107728481292725, "vf_loss": 7.854220867156982, "vf_explained_var": 0.9349976181983948, "kl": 0.0762266293168068, "entropy": 0.004902539774775505, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 508000, "num_agent_steps_sampled": 508000, "num_steps_trained": 508000, "num_agent_steps_trained": 508000}, "done": false, "episodes_total": 101600, "training_iteration": 127, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-06", "timestamp": 1628629206, "time_this_iter_s": 3.6842639446258545, "time_total_s": 486.20396542549133, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 486.20396542549133, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 35.64, "ram_util_percent": 76.1}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.02750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13694854694992467, "mean_inference_ms": 0.5593077634397993, "mean_action_processing_ms": 0.04360771374403667, "mean_env_wait_ms": 0.047814102799740965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 512000, "agent_timesteps_total": 512000, "timers": {"sample_time_ms": 1567.516, "sample_throughput": 2551.808, "load_time_ms": 0.951, "load_throughput": 4206291.932, "learn_time_ms": 2119.384, "learn_throughput": 1887.341, "update_time_ms": 1.493}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.7202020217155223e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.19325362145900726, "policy_loss": -0.0026398207992315292, "vf_loss": 0.19589343667030334, "vf_explained_var": 0.9982463121414185, "kl": 0.0007207264425233006, "entropy": 0.006513075437396765, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 512000, "num_agent_steps_sampled": 512000, "num_steps_trained": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 102400, "training_iteration": 128, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-10", "timestamp": 1628629210, "time_this_iter_s": 3.6836841106414795, "time_total_s": 489.8876495361328, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 489.8876495361328, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 37.75000000000001, "ram_util_percent": 75.96666666666665}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.037052008500005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13693811416618584, "mean_inference_ms": 0.5592644517503719, "mean_action_processing_ms": 0.04360189837114132, "mean_env_wait_ms": 0.04781101097994572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 516000, "agent_timesteps_total": 516000, "timers": {"sample_time_ms": 1564.631, "sample_throughput": 2556.513, "load_time_ms": 0.954, "load_throughput": 4193046.086, "learn_time_ms": 2116.263, "learn_throughput": 1890.124, "update_time_ms": 1.491}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.601010108577611e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.097701795399189, "policy_loss": -0.001749859657138586, "vf_loss": 0.09945166856050491, "vf_explained_var": 0.9991112947463989, "kl": 0.00036978142452426255, "entropy": 0.004394276067614555, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 516000, "num_agent_steps_sampled": 516000, "num_steps_trained": 516000, "num_agent_steps_trained": 516000}, "done": false, "episodes_total": 103200, "training_iteration": 129, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-13", "timestamp": 1628629213, "time_this_iter_s": 3.709658145904541, "time_total_s": 493.59730768203735, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 493.59730768203735, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04847160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13691206780687326, "mean_inference_ms": 0.5591420781503688, "mean_action_processing_ms": 0.04359040734270914, "mean_env_wait_ms": 0.04780211907476714, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 520000, "agent_timesteps_total": 520000, "timers": {"sample_time_ms": 1567.669, "sample_throughput": 2551.559, "load_time_ms": 0.956, "load_throughput": 4182071.441, "learn_time_ms": 2116.675, "learn_throughput": 1889.757, "update_time_ms": 1.511}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.3005050542888057e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.0025901158805936575, "policy_loss": 0.0014579767594113946, "vf_loss": 0.0011321379570290446, "vf_explained_var": 0.9999901056289673, "kl": 0.00021661765640601516, "entropy": 0.002185994992032647, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 520000, "num_agent_steps_sampled": 520000, "num_steps_trained": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 104000, "training_iteration": 130, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-17", "timestamp": 1628629217, "time_this_iter_s": 3.7220540046691895, "time_total_s": 497.31936168670654, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 497.31936168670654, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 36.559999999999995, "ram_util_percent": 75.97999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.049999999999997, "episode_reward_mean": 38.03804019940001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1369062300617018, "mean_inference_ms": 0.5591139669691806, "mean_action_processing_ms": 0.04358499122147977, "mean_env_wait_ms": 0.04780089946966695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 524000, "agent_timesteps_total": 524000, "timers": {"sample_time_ms": 1569.888, "sample_throughput": 2547.953, "load_time_ms": 0.958, "load_throughput": 4174994.65, "learn_time_ms": 2120.635, "learn_throughput": 1886.227, "update_time_ms": 1.49}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.1502525271444028e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.08196539431810379, "policy_loss": -0.002351954113692045, "vf_loss": 0.08431734889745712, "vf_explained_var": 0.9992534518241882, "kl": 6.843599840067327e-05, "entropy": 0.0014511109329760075, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 524000, "num_agent_steps_sampled": 524000, "num_steps_trained": 524000, "num_agent_steps_trained": 524000}, "done": false, "episodes_total": 104800, "training_iteration": 131, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-21", "timestamp": 1628629221, "time_this_iter_s": 3.7403759956359863, "time_total_s": 501.05973768234253, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 501.05973768234253, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 37.43333333333334, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13686446931218463, "mean_inference_ms": 0.5589069857508794, "mean_action_processing_ms": 0.04356773447238769, "mean_env_wait_ms": 0.04778474892290835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 528000, "agent_timesteps_total": 528000, "timers": {"sample_time_ms": 1561.101, "sample_throughput": 2562.294, "load_time_ms": 0.954, "load_throughput": 4193884.612, "learn_time_ms": 2124.935, "learn_throughput": 1882.41, "update_time_ms": 1.479}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.0751262635722014e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.11459632962942123, "policy_loss": -0.11459635943174362, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 0.1217915341258049, "entropy": 0.15298248827457428, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 528000, "num_agent_steps_sampled": 528000, "num_steps_trained": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 105600, "training_iteration": 132, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-25", "timestamp": 1628629225, "time_this_iter_s": 3.6789350509643555, "time_total_s": 504.7386727333069, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 504.7386727333069, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 36.36, "ram_util_percent": 76.1}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 34.58875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 29.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 31.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 30.05, 37.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 30.05, 30.05, 30.05, 30.05, 30.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 38.05, 38.05, 30.05, 30.05, 30.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.136855946433774, "mean_inference_ms": 0.5588463652657878, "mean_action_processing_ms": 0.043561129454724304, "mean_env_wait_ms": 0.0477827541672225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 532000, "agent_timesteps_total": 532000, "timers": {"sample_time_ms": 1566.13, "sample_throughput": 2554.067, "load_time_ms": 0.954, "load_throughput": 4193570.125, "learn_time_ms": 2124.183, "learn_throughput": 1883.077, "update_time_ms": 1.498}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.612689430885439e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 15.055631637573242, "policy_loss": -0.06069860979914665, "vf_loss": 15.116328239440918, "vf_explained_var": 0.8836315870285034, "kl": 0.17422695457935333, "entropy": 0.030208632349967957, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 532000, "num_agent_steps_sampled": 532000, "num_steps_trained": 532000, "num_agent_steps_trained": 532000}, "done": false, "episodes_total": 106400, "training_iteration": 133, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-28", "timestamp": 1628629228, "time_this_iter_s": 3.727125883102417, "time_total_s": 508.4657986164093, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 508.4657986164093, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 35.8, "ram_util_percent": 76.08}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 37.81000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1368286850727306, "mean_inference_ms": 0.5587348933504606, "mean_action_processing_ms": 0.04354975591763148, "mean_env_wait_ms": 0.04777414017714027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 536000, "agent_timesteps_total": 536000, "timers": {"sample_time_ms": 1564.23, "sample_throughput": 2557.169, "load_time_ms": 0.955, "load_throughput": 4189172.264, "learn_time_ms": 2127.65, "learn_throughput": 1880.008, "update_time_ms": 1.476}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.419034217382432e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.8020185232162476, "policy_loss": -0.010257813148200512, "vf_loss": 1.8122763633728027, "vf_explained_var": 0.9843294024467468, "kl": 0.013922860845923424, "entropy": 0.0028599028009921312, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 536000, "num_agent_steps_sampled": 536000, "num_steps_trained": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 107200, "training_iteration": 134, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-32", "timestamp": 1628629232, "time_this_iter_s": 3.720041275024414, "time_total_s": 512.1858398914337, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 512.1858398914337, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 76.03999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 38.03000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13678298375393205, "mean_inference_ms": 0.5585293870130803, "mean_action_processing_ms": 0.04353357898476878, "mean_env_wait_ms": 0.047758303471986195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 540000, "agent_timesteps_total": 540000, "timers": {"sample_time_ms": 1562.404, "sample_throughput": 2560.158, "load_time_ms": 0.956, "load_throughput": 4185618.841, "learn_time_ms": 2127.652, "learn_throughput": 1880.007, "update_time_ms": 1.474}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.419034217382432e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.1319863647222519, "policy_loss": -0.007472785655409098, "vf_loss": 0.13945914804935455, "vf_explained_var": 0.9988176822662354, "kl": 0.00016377653810195625, "entropy": 0.0012534612324088812, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 540000, "num_agent_steps_sampled": 540000, "num_steps_trained": 540000, "num_agent_steps_trained": 540000}, "done": false, "episodes_total": 108000, "training_iteration": 135, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-36", "timestamp": 1628629236, "time_this_iter_s": 3.697755813598633, "time_total_s": 515.8835957050323, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 515.8835957050323, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 37.25000000000001, "ram_util_percent": 76.11666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1367431120467696, "mean_inference_ms": 0.5583501748386799, "mean_action_processing_ms": 0.04351782314305824, "mean_env_wait_ms": 0.04774504351508353, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 544000, "agent_timesteps_total": 544000, "timers": {"sample_time_ms": 1558.688, "sample_throughput": 2566.26, "load_time_ms": 0.949, "load_throughput": 4215274.993, "learn_time_ms": 2129.537, "learn_throughput": 1878.343, "update_time_ms": 1.494}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.209517108691216e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.07593494653701782, "policy_loss": -0.001912319683469832, "vf_loss": 0.07784727960824966, "vf_explained_var": 0.9993680715560913, "kl": 4.712077497970313e-05, "entropy": 0.0006912081153132021, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 544000, "num_agent_steps_sampled": 544000, "num_steps_trained": 544000, "num_agent_steps_trained": 544000}, "done": false, "episodes_total": 108800, "training_iteration": 136, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-40", "timestamp": 1628629240, "time_this_iter_s": 3.704364776611328, "time_total_s": 519.5879604816437, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 519.5879604816437, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 36.019999999999996, "ram_util_percent": 76.2}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1367522925524053, "mean_inference_ms": 0.5584000796299888, "mean_action_processing_ms": 0.04351958564217757, "mean_env_wait_ms": 0.047751619185141966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 548000, "agent_timesteps_total": 548000, "timers": {"sample_time_ms": 1567.884, "sample_throughput": 2551.209, "load_time_ms": 0.957, "load_throughput": 4181341.84, "learn_time_ms": 2128.282, "learn_throughput": 1879.45, "update_time_ms": 1.505}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.04758554345608e-08, "cur_lr": 4.999999873689376e-05, "total_loss": -0.035620350390672684, "policy_loss": -0.03562038764357567, "vf_loss": 1.0085122400551021e-14, "vf_explained_var": 1.0, "kl": 0.43723708391189575, "entropy": 0.10243033617734909, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 548000, "num_agent_steps_sampled": 548000, "num_steps_trained": 548000, "num_agent_steps_trained": 548000}, "done": false, "episodes_total": 109600, "training_iteration": 137, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-43", "timestamp": 1628629243, "time_this_iter_s": 3.764547824859619, "time_total_s": 523.3525083065033, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 523.3525083065033, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 36.68000000000001, "ram_util_percent": 76.46}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.05, "episode_reward_mean": 36.7960677609, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.05, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 34.05, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 37.76607976, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 38.05, 36.70487176, 35.05, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 34.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 31.05, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 37.827287760000004, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 34.05, 36.70487176, 38.05, 36.70487176, 38.05, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 38.05, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 33.05, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 37.827287760000004, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.827287760000004, 38.05, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 37.76607976, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 38.05, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 37.76607976, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 38.05, 36.70487176, 36.70487176, 31.05, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 37.76607976, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.643663759999995, 38.05, 36.70487176, 36.70487176, 36.70487176, 33.05, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 36.70487176, 35.05, 36.70487176, 36.70487176, 36.70487176, 35.05, 35.05, 36.70487176, 36.70487176, 38.05, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 36.70487176, 37.76607976, 36.70487176, 38.05, 37.76607976, 36.70487176, 38.05, 38.05, 38.05, 36.70487176, 36.643663759999995, 35.05, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 35.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 33.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 34.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 38.05, 36.643663759999995, 37.76607976, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 36.643663759999995, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 35.05, 38.05, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 36.70487176, 33.05, 36.70487176, 36.70487176, 38.05, 36.70487176, 36.70487176, 36.643663759999995, 36.70487176, 36.70487176, 36.70487176], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1367362400644425, "mean_inference_ms": 0.5583466383205474, "mean_action_processing_ms": 0.043512482570064515, "mean_env_wait_ms": 0.04774683647851388, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 552000, "agent_timesteps_total": 552000, "timers": {"sample_time_ms": 1571.958, "sample_throughput": 2544.597, "load_time_ms": 0.965, "load_throughput": 4145388.417, "learn_time_ms": 2127.292, "learn_throughput": 1880.325, "update_time_ms": 1.483}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 9.071377604641384e-08, "cur_lr": 4.999999873689376e-05, "total_loss": 0.1209535151720047, "policy_loss": -0.093116395175457, "vf_loss": 0.21406987309455872, "vf_explained_var": 0.9981241822242737, "kl": 0.3582365810871124, "entropy": 0.11034592986106873, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 552000, "num_agent_steps_sampled": 552000, "num_steps_trained": 552000, "num_agent_steps_trained": 552000}, "done": false, "episodes_total": 110400, "training_iteration": 138, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-47", "timestamp": 1628629247, "time_this_iter_s": 3.7137749195098877, "time_total_s": 527.0662832260132, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 527.0662832260132, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 30.46666666666667, "ram_util_percent": 76.48333333333333}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.050000000000004, "episode_reward_mean": 37.892498699700006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 37.76607976, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 36.70487176, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 36.70487176, 36.70487176, 37.76607976, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.643663759999995, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 36.643663759999995, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 36.70487176, 38.05, 36.70487176, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13672334259425756, "mean_inference_ms": 0.5582645886824307, "mean_action_processing_ms": 0.04350412494885381, "mean_env_wait_ms": 0.04774271262854077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 556000, "agent_timesteps_total": 556000, "timers": {"sample_time_ms": 1570.298, "sample_throughput": 2547.287, "load_time_ms": 0.971, "load_throughput": 4121052.295, "learn_time_ms": 2133.912, "learn_throughput": 1874.492, "update_time_ms": 1.498}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.3607066762233444e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.09049700200557709, "policy_loss": -0.040158338844776154, "vf_loss": 0.13065531849861145, "vf_explained_var": 0.9988768696784973, "kl": 0.11322944611310959, "entropy": 0.006557772867381573, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 556000, "num_agent_steps_sampled": 556000, "num_steps_trained": 556000, "num_agent_steps_trained": 556000}, "done": false, "episodes_total": 111200, "training_iteration": 139, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-51", "timestamp": 1628629251, "time_this_iter_s": 3.759941816329956, "time_total_s": 530.8262250423431, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 530.8262250423431, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 35.4, "ram_util_percent": 76.32000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.03839509970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13669661807403222, "mean_inference_ms": 0.5581348376723851, "mean_action_processing_ms": 0.043493178551867365, "mean_env_wait_ms": 0.04773503268170483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 560000, "agent_timesteps_total": 560000, "timers": {"sample_time_ms": 1570.678, "sample_throughput": 2546.671, "load_time_ms": 0.967, "load_throughput": 4134661.508, "learn_time_ms": 2131.83, "learn_throughput": 1876.322, "update_time_ms": 1.502}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.0410600143350166e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.09755250066518784, "policy_loss": -0.0014851498417556286, "vf_loss": 0.09903766214847565, "vf_explained_var": 0.9991322755813599, "kl": 4.533479659585282e-05, "entropy": 0.001287462073378265, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 560000, "num_agent_steps_sampled": 560000, "num_steps_trained": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 112000, "training_iteration": 140, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-55", "timestamp": 1628629255, "time_this_iter_s": 3.7053439617156982, "time_total_s": 534.5315690040588, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 534.5315690040588, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 36.82, "ram_util_percent": 76.25999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13669158480179153, "mean_inference_ms": 0.5581197976016833, "mean_action_processing_ms": 0.04348927279124798, "mean_env_wait_ms": 0.04773345212681988, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 564000, "agent_timesteps_total": 564000, "timers": {"sample_time_ms": 1570.818, "sample_throughput": 2546.443, "load_time_ms": 0.975, "load_throughput": 4104618.095, "learn_time_ms": 2134.108, "learn_throughput": 1874.319, "update_time_ms": 1.5}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.0205300071675083e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.11447740346193314, "policy_loss": -0.11447756737470627, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.3823634386062622, "entropy": 0.1276978999376297, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 564000, "num_agent_steps_sampled": 564000, "num_steps_trained": 564000, "num_agent_steps_trained": 564000}, "done": false, "episodes_total": 112800, "training_iteration": 141, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-00-59", "timestamp": 1628629259, "time_this_iter_s": 3.7645750045776367, "time_total_s": 538.2961440086365, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 538.2961440086365, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 36.583333333333336, "ram_util_percent": 76.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.05, "episode_reward_mean": 36.45625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 36.05, 37.05, 32.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 32.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 34.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 32.05, 32.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 32.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 32.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 32.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 32.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 38.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 32.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 32.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 36.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 32.05, 37.05, 36.05, 37.05, 37.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1366532737391325, "mean_inference_ms": 0.557898443353283, "mean_action_processing_ms": 0.04347274602474247, "mean_env_wait_ms": 0.04771868347562117, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 568000, "agent_timesteps_total": 568000, "timers": {"sample_time_ms": 1569.959, "sample_throughput": 2547.837, "load_time_ms": 0.973, "load_throughput": 4110551.513, "learn_time_ms": 2133.175, "learn_throughput": 1875.139, "update_time_ms": 1.518}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.5307949752241257e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.3947121500968933, "policy_loss": -0.07852701842784882, "vf_loss": 0.47323909401893616, "vf_explained_var": 0.9952465891838074, "kl": 0.15028654038906097, "entropy": 0.38402360677719116, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 568000, "num_agent_steps_sampled": 568000, "num_steps_trained": 568000, "num_agent_steps_trained": 568000}, "done": false, "episodes_total": 113600, "training_iteration": 142, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-02", "timestamp": 1628629262, "time_this_iter_s": 3.6610262393951416, "time_total_s": 541.9571702480316, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 541.9571702480316, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 36.46, "ram_util_percent": 76.36000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 32.05, "episode_reward_mean": 37.018440929600004, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.827287760000004, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.827287760000004, 37.05, 36.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 38.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.827287760000004, 37.05, 38.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 36.05, 37.05, 36.05, 38.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 36.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 36.05, 38.05, 37.05, 36.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 36.05, 38.05, 36.05, 38.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.74527176000001, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 32.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 36.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 36.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 38.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 36.05, 38.05, 36.05, 37.827287760000004, 36.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.80647976, 37.05, 38.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 38.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 36.05, 37.05, 38.05, 37.05, 38.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13666247095765885, "mean_inference_ms": 0.5579083486560187, "mean_action_processing_ms": 0.04347271282541728, "mean_env_wait_ms": 0.04772191309411128, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 572000, "agent_timesteps_total": 572000, "timers": {"sample_time_ms": 1572.572, "sample_throughput": 2543.604, "load_time_ms": 0.968, "load_throughput": 4133439.109, "learn_time_ms": 2130.829, "learn_throughput": 1877.204, "update_time_ms": 1.501}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.2961924628361885e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.29277217388153076, "policy_loss": -0.06949665397405624, "vf_loss": 0.3622688055038452, "vf_explained_var": 0.9964756965637207, "kl": 0.06565961986780167, "entropy": 0.35255691409111023, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 572000, "num_agent_steps_sampled": 572000, "num_steps_trained": 572000, "num_agent_steps_trained": 572000}, "done": false, "episodes_total": 114400, "training_iteration": 143, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-06", "timestamp": 1628629266, "time_this_iter_s": 3.7300448417663574, "time_total_s": 545.687215089798, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 545.687215089798, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 37.160000000000004, "ram_util_percent": 76.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 37.3409172147, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 31.049999999999997, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 36.05, 38.05, 36.05, 37.827287760000004, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.05, 32.270988, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 32.270988, 36.74527176000001, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.80647976, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 36.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 36.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 36.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 36.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 36.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 36.05, 37.05, 36.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.76607976, 36.05, 36.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 36.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 36.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.05, 38.05, 37.05, 37.827287760000004, 36.05, 37.05, 38.05, 33.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 36.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 36.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 36.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 36.05, 37.827287760000004, 37.827287760000004, 36.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.05, 36.05, 37.827287760000004, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 36.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 32.270988, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 36.05, 37.827287760000004, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.05, 38.05, 37.827287760000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13664888702583525, "mean_inference_ms": 0.5578556463816357, "mean_action_processing_ms": 0.04346546836413623, "mean_env_wait_ms": 0.04771725697593407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 576000, "agent_timesteps_total": 576000, "timers": {"sample_time_ms": 1574.792, "sample_throughput": 2540.019, "load_time_ms": 0.966, "load_throughput": 4139762.627, "learn_time_ms": 2128.548, "learn_throughput": 1879.215, "update_time_ms": 1.505}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.44428883636283e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.24838414788246155, "policy_loss": -0.07608849555253983, "vf_loss": 0.3244726359844208, "vf_explained_var": 0.9969276189804077, "kl": 0.09750138223171234, "entropy": 0.325154572725296, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 576000, "num_agent_steps_sampled": 576000, "num_steps_trained": 576000, "num_agent_steps_trained": 576000}, "done": false, "episodes_total": 115200, "training_iteration": 144, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-10", "timestamp": 1628629270, "time_this_iter_s": 3.7196168899536133, "time_total_s": 549.4068319797516, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 549.4068319797516, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 36.916666666666664, "ram_util_percent": 76.33333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 37.7045843832, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.827287760000004, 38.05, 37.76607976, 37.80647976, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.80647976, 37.05, 37.827287760000004, 37.80647976, 37.827287760000004, 37.80647976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.827287760000004, 37.827287760000004, 38.05, 37.80647976, 37.05, 37.80647976, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.80647976, 37.05, 38.05, 37.80647976, 37.827287760000004, 37.05, 37.76607976, 37.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.05, 37.05, 37.80647976, 37.05, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.827287760000004, 37.80647976, 38.05, 37.05, 37.05, 38.05, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.80647976, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.80647976, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.80647976, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.80647976, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.80647976, 37.05, 38.05, 37.76607976, 37.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 37.05, 37.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.05, 37.05, 38.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.80647976, 37.827287760000004, 37.05, 37.827287760000004, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.80647976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.76607976, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 38.05, 37.80647976, 37.05, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.80647976, 38.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.05, 37.05, 37.80647976, 37.05, 38.05, 38.05, 37.05, 37.76607976, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 38.05, 37.827287760000004, 37.827287760000004, 37.80647976, 37.76607976, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.76607976, 37.827287760000004, 37.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 38.05, 37.05, 37.05, 37.827287760000004, 37.76607976, 37.80647976, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.80647976, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.80647976, 37.827287760000004, 37.80647976, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.05, 38.05, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.80647976, 37.76607976, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.05, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.05, 37.76607976, 37.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 38.05, 37.80647976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.80647976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 37.80647976, 37.80647976, 37.76607976, 38.05, 37.80647976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.76607976, 37.76607976, 37.827287760000004, 37.80647976, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 37.80647976, 37.80647976, 37.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.05, 38.05, 37.76607976, 38.05, 37.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.05, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.05, 37.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.80647976, 37.05, 38.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 37.05, 38.05, 37.05, 37.827287760000004, 37.80647976, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 38.05, 37.80647976, 37.827287760000004, 38.05, 37.80647976, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 37.80647976, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.05, 38.05, 38.05, 37.05, 37.80647976, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.80647976, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.80647976, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.76607976, 37.80647976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.80647976, 38.05, 37.76607976, 37.827287760000004, 37.05, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.05, 37.827287760000004, 37.76607976, 38.05, 37.05, 37.76607976, 37.827287760000004, 37.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.76607976, 37.80647976, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13664041871740507, "mean_inference_ms": 0.5578027309267887, "mean_action_processing_ms": 0.04346024185586284, "mean_env_wait_ms": 0.0477153776984383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 580000, "agent_timesteps_total": 580000, "timers": {"sample_time_ms": 1580.707, "sample_throughput": 2530.513, "load_time_ms": 0.965, "load_throughput": 4144876.35, "learn_time_ms": 2127.225, "learn_throughput": 1880.384, "update_time_ms": 1.508}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.166432970327151e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.057092178612947464, "policy_loss": -0.05804719403386116, "vf_loss": 0.11513932794332504, "vf_explained_var": 0.9989604949951172, "kl": 0.09684740006923676, "entropy": 0.288226455450058, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 580000, "num_agent_steps_sampled": 580000, "num_steps_trained": 580000, "num_agent_steps_trained": 580000}, "done": false, "episodes_total": 116000, "training_iteration": 145, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-13", "timestamp": 1628629273, "time_this_iter_s": 3.743940830230713, "time_total_s": 553.1507728099823, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 553.1507728099823, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 35.88, "ram_util_percent": 76.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 37.218194191100004, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.827287760000004, 38.05, 34.05, 37.827287760000004, 38.05, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 37.05, 34.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 34.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 34.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 34.05, 37.76607976, 37.827287760000004, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 34.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 34.05, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 38.05, 34.05, 37.827287760000004, 34.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 34.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 33.05, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.80647976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.05, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 34.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 34.05, 34.05, 37.827287760000004, 34.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 38.05, 34.05, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 37.05, 34.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 37.05, 38.05, 34.05, 37.76607976, 34.05, 37.76607976, 37.05, 33.05, 34.05, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 34.05, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.80647976, 38.05, 37.827287760000004, 34.05, 37.827287760000004, 34.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 34.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 34.05, 34.05, 34.05, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 34.05, 37.827287760000004, 37.05, 33.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 38.05, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 34.05, 38.05, 38.05, 37.827287760000004, 38.05, 33.05, 38.05, 37.827287760000004, 37.827287760000004, 37.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 37.827287760000004, 38.05, 34.05, 37.827287760000004, 33.05, 38.05, 37.827287760000004, 37.80647976, 38.05, 37.05, 37.827287760000004, 37.05, 37.76607976, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.05, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 34.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 34.05, 38.05, 38.05, 37.76607976, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.80647976, 38.05, 38.05, 37.827287760000004, 38.05, 33.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 38.05, 37.827287760000004, 37.80647976, 38.05, 37.827287760000004, 37.76607976, 34.05, 34.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 34.05, 38.05, 38.05, 33.05, 37.80647976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 34.05, 37.827287760000004, 37.76607976, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 34.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 37.05, 37.827287760000004, 37.827287760000004, 37.05, 37.76607976, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 33.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 33.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 38.05, 34.05, 34.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 34.05, 37.76607976, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 34.05, 37.827287760000004, 37.827287760000004, 34.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 33.05, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 37.80647976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 34.05, 38.05, 37.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 33.05, 38.05, 37.827287760000004, 37.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.80647976, 37.76607976, 38.05, 34.05, 37.827287760000004, 34.05, 37.827287760000004, 34.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 34.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 33.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 34.05, 34.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.05, 37.827287760000004, 37.05, 37.76607976, 38.05, 37.827287760000004, 34.05, 34.05, 37.76607976, 38.05, 34.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 33.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 33.05, 37.76607976, 37.76607976, 37.827287760000004, 37.05, 37.827287760000004, 37.76607976, 37.827287760000004, 34.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 34.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 33.05, 38.05, 37.827287760000004, 37.76607976, 34.05, 34.05, 38.05, 34.05, 37.76607976, 37.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.05, 37.827287760000004, 38.05, 34.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13663830773258806, "mean_inference_ms": 0.5577863164753305, "mean_action_processing_ms": 0.04345789855829841, "mean_env_wait_ms": 0.04771573851017683, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 584000, "agent_timesteps_total": 584000, "timers": {"sample_time_ms": 1586.537, "sample_throughput": 2521.214, "load_time_ms": 0.966, "load_throughput": 4140477.789, "learn_time_ms": 2122.27, "learn_throughput": 1884.775, "update_time_ms": 1.483}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.74964973970782e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.3466119766235352, "policy_loss": -0.07298897951841354, "vf_loss": 1.4196008443832397, "vf_explained_var": 0.9866623282432556, "kl": 0.21684153378009796, "entropy": 0.22283633053302765, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 584000, "num_agent_steps_sampled": 584000, "num_steps_trained": 584000, "num_agent_steps_trained": 584000}, "done": false, "episodes_total": 116800, "training_iteration": 146, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-17", "timestamp": 1628629277, "time_this_iter_s": 3.712331771850586, "time_total_s": 556.8631045818329, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 556.8631045818329, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 37.11999999999999, "ram_util_percent": 76.3}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 37.9157145328, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 33.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.76607976, 37.76607976, 37.827287760000004, 38.05, 37.76607976, 38.05, 37.05, 37.827287760000004, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.76607976, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.76607976, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 37.827287760000004, 37.76607976, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 37.827287760000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1366261482631267, "mean_inference_ms": 0.5577164959481542, "mean_action_processing_ms": 0.043450974893733924, "mean_env_wait_ms": 0.0477112384755284, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 588000, "agent_timesteps_total": 588000, "timers": {"sample_time_ms": 1581.489, "sample_throughput": 2529.262, "load_time_ms": 0.965, "load_throughput": 4146412.931, "learn_time_ms": 2124.497, "learn_throughput": 1882.798, "update_time_ms": 1.47}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.162447460956173e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0348379872739315, "policy_loss": -0.0749974250793457, "vf_loss": 0.040158987045288086, "vf_explained_var": 0.999643087387085, "kl": 0.3841598331928253, "entropy": 0.3918839991092682, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 588000, "num_agent_steps_sampled": 588000, "num_steps_trained": 588000, "num_agent_steps_trained": 588000}, "done": false, "episodes_total": 117600, "training_iteration": 147, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-21", "timestamp": 1628629281, "time_this_iter_s": 3.735513210296631, "time_total_s": 560.5986177921295, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 560.5986177921295, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 36.550000000000004, "ram_util_percent": 76.39999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 35.275168804100005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.05, 35.05, 35.05, 35.05, 33.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 32.05, 38.05, 32.05, 35.05, 38.05, 35.05, 32.05, 38.05, 35.05, 38.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 32.05, 32.05, 35.05, 35.05, 35.05, 38.05, 35.05, 36.05, 37.827287760000004, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 37.827287760000004, 36.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 37.827287760000004, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 32.05, 32.05, 35.05, 32.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 36.05, 32.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 32.05, 35.05, 35.05, 37.76607976, 35.05, 35.05, 32.05, 35.05, 37.827287760000004, 38.05, 35.05, 37.827287760000004, 35.05, 35.05, 38.05, 32.05, 35.05, 35.05, 38.05, 35.05, 38.05, 32.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 38.05, 36.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 32.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 35.05, 32.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 32.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 32.05, 38.05, 35.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 32.05, 32.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 37.827287760000004, 35.05, 32.05, 38.05, 32.05, 35.05, 35.05, 32.05, 38.05, 35.05, 32.05, 35.05, 32.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 32.05, 35.05, 32.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 33.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 36.05, 37.827287760000004, 35.05, 35.05, 38.05, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 31.049999999999997, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 32.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 32.05, 38.05, 32.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 33.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 37.827287760000004, 32.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 36.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 37.827287760000004, 37.827287760000004, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 32.05, 32.05, 35.05, 32.05, 35.05, 35.05, 32.05, 35.05, 32.05, 35.05, 35.05, 35.05, 38.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 32.05, 35.05, 35.05, 35.05, 32.05, 38.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 33.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 37.827287760000004, 35.05, 35.05, 32.05, 32.05, 35.05, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 37.827287760000004, 38.05, 32.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 36.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 37.827287760000004, 32.05, 35.05, 35.05, 38.05, 32.05, 35.05, 38.05, 35.05, 38.05, 35.05, 37.827287760000004, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 36.05, 35.05, 38.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 35.05, 38.05, 35.05, 37.827287760000004, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 38.05, 32.05, 32.05, 38.05, 35.05, 32.05, 35.05, 38.05, 38.05, 35.05, 35.05, 37.827287760000004, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 32.05, 38.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 38.05, 35.05, 32.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 38.05, 37.827287760000004, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 36.05, 38.05, 35.05, 37.827287760000004, 35.05, 32.05, 35.05, 37.827287760000004, 35.05, 38.05, 35.05, 32.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 38.05, 38.05, 35.05, 35.05, 32.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 35.05, 38.05, 35.05, 35.05, 37.827287760000004, 35.05, 32.05, 35.05, 35.05, 32.05, 35.05, 32.05, 38.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13659029159899785, "mean_inference_ms": 0.557526725420618, "mean_action_processing_ms": 0.04343639621424483, "mean_env_wait_ms": 0.04769854605020503, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 592000, "agent_timesteps_total": 592000, "timers": {"sample_time_ms": 1576.458, "sample_throughput": 2537.333, "load_time_ms": 0.964, "load_throughput": 4150721.425, "learn_time_ms": 2128.549, "learn_throughput": 1879.214, "update_time_ms": 1.485}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.7436711914342595e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 2.7026479244232178, "policy_loss": -0.07785767316818237, "vf_loss": 2.7805051803588867, "vf_explained_var": 0.9746062755584717, "kl": 0.05577812343835831, "entropy": 0.3294382393360138, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 592000, "num_agent_steps_sampled": 592000, "num_steps_trained": 592000, "num_agent_steps_trained": 592000}, "done": false, "episodes_total": 118400, "training_iteration": 148, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-25", "timestamp": 1628629285, "time_this_iter_s": 3.7046561241149902, "time_total_s": 564.3032739162445, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 564.3032739162445, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 36.4, "ram_util_percent": 76.38}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 36.3616916817, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 35.05, 38.05, 35.05, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 30.05, 35.05, 35.05, 36.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 37.827287760000004, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 36.05, 35.05, 37.827287760000004, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 37.827287760000004, 37.827287760000004, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 32.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 36.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 36.05, 38.05, 35.05, 38.05, 36.05, 38.05, 35.05, 38.05, 37.827287760000004, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 36.05, 37.827287760000004, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 35.05, 37.827287760000004, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 37.827287760000004, 38.05, 38.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 36.05, 37.827287760000004, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 36.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 37.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 38.05, 35.05, 35.05, 36.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 37.827287760000004, 38.05, 32.05, 35.05, 35.05, 30.05, 33.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 32.05, 38.05, 35.05, 38.05, 37.827287760000004, 38.05, 35.05, 35.05, 36.05, 35.05, 35.05, 35.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 37.827287760000004, 37.827287760000004, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 32.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 32.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 37.827287760000004, 35.05, 35.05, 32.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 37.05, 35.05, 38.05, 38.05, 38.05, 35.05, 35.05, 37.827287760000004, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 32.05, 35.05, 35.05, 38.05, 35.05, 35.05, 35.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 38.05, 32.05, 35.05, 35.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 36.05, 32.05, 38.05, 38.05, 38.05, 35.05, 36.05, 35.05, 35.05, 38.05, 37.05, 38.05, 38.05, 35.05, 37.827287760000004, 35.05, 35.05, 35.05, 38.05, 35.05, 38.05, 37.827287760000004, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 35.05, 35.05, 35.05, 38.05, 37.827287760000004, 35.05, 35.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 37.827287760000004, 37.827287760000004, 38.05, 35.05, 38.05, 35.05, 38.05, 35.05, 38.05, 37.76607976, 37.827287760000004, 35.05, 35.05, 37.827287760000004, 35.05, 38.05, 36.05, 35.05, 35.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1365903744749143, "mean_inference_ms": 0.5575470168145048, "mean_action_processing_ms": 0.04343402971715369, "mean_env_wait_ms": 0.04770079269375128, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 596000, "agent_timesteps_total": 596000, "timers": {"sample_time_ms": 1579.65, "sample_throughput": 2532.206, "load_time_ms": 0.955, "load_throughput": 4187603.834, "learn_time_ms": 2122.454, "learn_throughput": 1884.611, "update_time_ms": 1.47}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.615506900838227e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 2.2145016193389893, "policy_loss": -0.07194177061319351, "vf_loss": 2.286442279815674, "vf_explained_var": 0.9798589944839478, "kl": 0.3306080996990204, "entropy": 0.13264200091362, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 596000, "num_agent_steps_sampled": 596000, "num_steps_trained": 596000, "num_agent_steps_trained": 596000}, "done": false, "episodes_total": 119200, "training_iteration": 149, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-28", "timestamp": 1628629288, "time_this_iter_s": 3.7303080558776855, "time_total_s": 568.0335819721222, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 568.0335819721222, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 36.4, "ram_util_percent": 76.38}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 37.9710465686, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 35.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.76607976, 35.05, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 35.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 37.76607976, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 37.827287760000004, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 37.76607976, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13655296067823638, "mean_inference_ms": 0.5573817222687504, "mean_action_processing_ms": 0.043419843025190606, "mean_env_wait_ms": 0.04768733341282744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 600000, "agent_timesteps_total": 600000, "timers": {"sample_time_ms": 1575.957, "sample_throughput": 2538.141, "load_time_ms": 0.96, "load_throughput": 4168045.315, "learn_time_ms": 2127.379, "learn_throughput": 1880.248, "update_time_ms": 1.468}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.923260010196827e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.0827903300523758, "policy_loss": -0.02175109088420868, "vf_loss": 0.10454101115465164, "vf_explained_var": 0.999051570892334, "kl": 0.10187023133039474, "entropy": 0.02083422802388668, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 600000, "num_agent_steps_sampled": 600000, "num_steps_trained": 600000, "num_agent_steps_trained": 600000}, "done": false, "episodes_total": 120000, "training_iteration": 150, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-32", "timestamp": 1628629292, "time_this_iter_s": 3.717879056930542, "time_total_s": 571.7514610290527, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 571.7514610290527, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 37.26666666666666, "ram_util_percent": 76.39999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.02513643880001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13654208641255994, "mean_inference_ms": 0.5573319610225654, "mean_action_processing_ms": 0.04341380557421945, "mean_env_wait_ms": 0.047684059631396575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 604000, "agent_timesteps_total": 604000, "timers": {"sample_time_ms": 1574.15, "sample_throughput": 2541.053, "load_time_ms": 0.954, "load_throughput": 4194618.596, "learn_time_ms": 2123.451, "learn_throughput": 1883.726, "update_time_ms": 1.469}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.884890470042592e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.06015390902757645, "policy_loss": -0.005496493075042963, "vf_loss": 0.06565039604902267, "vf_explained_var": 0.999431312084198, "kl": 0.0010420046746730804, "entropy": 0.008480259217321873, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 604000, "num_agent_steps_sampled": 604000, "num_steps_trained": 604000, "num_agent_steps_trained": 604000}, "done": false, "episodes_total": 120800, "training_iteration": 151, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-36", "timestamp": 1628629296, "time_this_iter_s": 3.7073240280151367, "time_total_s": 575.4587850570679, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 575.4587850570679, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 36.10000000000001, "ram_util_percent": 76.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.04250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1365242881803387, "mean_inference_ms": 0.5572595099745679, "mean_action_processing_ms": 0.043405800228745114, "mean_env_wait_ms": 0.04767854905573238, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 608000, "agent_timesteps_total": 608000, "timers": {"sample_time_ms": 1578.811, "sample_throughput": 2533.552, "load_time_ms": 0.953, "load_throughput": 4195352.838, "learn_time_ms": 2126.836, "learn_throughput": 1880.728, "update_time_ms": 1.465}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.942445235021296e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.019058989360928535, "policy_loss": -0.0027777687646448612, "vf_loss": 0.02183675393462181, "vf_explained_var": 0.9998036623001099, "kl": 0.00028314124210737646, "entropy": 0.005608272273093462, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 608000, "num_agent_steps_sampled": 608000, "num_steps_trained": 608000, "num_agent_steps_trained": 608000}, "done": false, "episodes_total": 121600, "training_iteration": 152, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-40", "timestamp": 1628629300, "time_this_iter_s": 3.7415659427642822, "time_total_s": 579.2003509998322, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 579.2003509998322, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 36.68, "ram_util_percent": 76.44000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.03472160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13652022710241163, "mean_inference_ms": 0.5572478313330671, "mean_action_processing_ms": 0.04340267918154234, "mean_env_wait_ms": 0.04767808806943309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 612000, "agent_timesteps_total": 612000, "timers": {"sample_time_ms": 1577.361, "sample_throughput": 2535.88, "load_time_ms": 0.962, "load_throughput": 4156068.173, "learn_time_ms": 2144.383, "learn_throughput": 1865.338, "update_time_ms": 1.499}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.471222617510648e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.1078995019197464, "policy_loss": -0.0024534810800105333, "vf_loss": 0.11035298556089401, "vf_explained_var": 0.9990253448486328, "kl": 6.189238047227263e-05, "entropy": 0.003923705779016018, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 612000, "num_agent_steps_sampled": 612000, "num_steps_trained": 612000, "num_agent_steps_trained": 612000}, "done": false, "episodes_total": 122400, "training_iteration": 153, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-44", "timestamp": 1628629304, "time_this_iter_s": 3.8911120891571045, "time_total_s": 583.0914630889893, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 583.0914630889893, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 38.083333333333336, "ram_util_percent": 76.53333333333332}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.827287760000004, "episode_reward_mean": 38.04972160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13648980470467403, "mean_inference_ms": 0.557092209826751, "mean_action_processing_ms": 0.043390164521189004, "mean_env_wait_ms": 0.04766772247528173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 616000, "agent_timesteps_total": 616000, "timers": {"sample_time_ms": 1572.488, "sample_throughput": 2543.74, "load_time_ms": 0.966, "load_throughput": 4140682.166, "learn_time_ms": 2146.081, "learn_throughput": 1863.863, "update_time_ms": 1.618}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.35611308755324e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.10117646306753159, "policy_loss": -0.10125472396612167, "vf_loss": 7.621537224622443e-05, "vf_explained_var": 0.9999994039535522, "kl": 2.793579339981079, "entropy": 0.07503543794155121, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 616000, "num_agent_steps_sampled": 616000, "num_steps_trained": 616000, "num_agent_steps_trained": 616000}, "done": false, "episodes_total": 123200, "training_iteration": 154, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-47", "timestamp": 1628629307, "time_this_iter_s": 3.6895689964294434, "time_total_s": 586.7810320854187, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 586.7810320854187, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 36.04, "ram_util_percent": 76.05999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 37.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 33.17875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 37.05, 36.05, 32.05, 32.05, 32.05, 36.05, 32.05, 37.05, 37.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 36.05, 32.05, 37.05, 32.05, 32.05, 37.05, 37.05, 36.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 37.05, 32.05, 36.05, 36.05, 32.05, 32.05, 37.05, 37.05, 31.049999999999997, 32.05, 32.05, 32.05, 37.05, 31.049999999999997, 32.05, 33.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 36.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 36.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 32.05, 32.05, 36.05, 36.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 31.049999999999997, 37.05, 32.05, 36.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 37.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 37.05, 32.05, 32.05, 37.05, 37.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 36.05, 37.05, 32.05, 32.05, 32.05, 33.05, 37.05, 37.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 36.05, 32.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 37.05, 37.05, 32.05, 36.05, 32.05, 32.05, 32.05, 36.05, 37.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 36.05, 37.05, 32.05, 37.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 36.05, 31.049999999999997, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 36.05, 37.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 36.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 33.05, 31.049999999999997, 31.049999999999997, 37.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 37.05, 32.05, 36.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 36.05, 37.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 31.049999999999997, 32.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 36.05, 37.05, 32.05, 32.05, 32.05, 32.05, 36.05, 36.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 37.05, 30.049999999999997, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 37.05, 37.05, 32.05, 32.05, 36.05, 36.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 36.05, 32.05, 37.05, 32.05, 37.05, 32.05, 36.05, 37.05, 32.05, 31.049999999999997, 32.05, 37.05, 37.05, 37.05, 36.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 36.05, 32.05, 37.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 33.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 36.05, 32.05, 36.05, 36.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 37.05, 36.05, 32.05, 32.05, 36.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 31.049999999999997, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 32.05, 33.05, 32.05, 37.05, 36.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 32.05, 37.05, 32.05, 32.05, 36.05, 32.05, 37.05, 32.05, 32.05, 32.05, 32.05, 37.05, 32.05, 37.05, 32.05, 32.05, 37.05, 36.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1364989395925704, "mean_inference_ms": 0.5571650905610914, "mean_action_processing_ms": 0.04339142999583798, "mean_env_wait_ms": 0.04767367266233817, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 620000, "agent_timesteps_total": 620000, "timers": {"sample_time_ms": 1577.007, "sample_throughput": 2536.45, "load_time_ms": 0.96, "load_throughput": 4167527.635, "learn_time_ms": 2143.96, "learn_throughput": 1865.707, "update_time_ms": 1.626}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.1034169347112766e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 3.297119379043579, "policy_loss": -0.0603940412402153, "vf_loss": 3.357512950897217, "vf_explained_var": 0.9557162523269653, "kl": 0.34182316064834595, "entropy": 0.2944525182247162, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 620000, "num_agent_steps_sampled": 620000, "num_steps_trained": 620000, "num_agent_steps_trained": 620000}, "done": false, "episodes_total": 124000, "training_iteration": 155, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-51", "timestamp": 1628629311, "time_this_iter_s": 3.7680530548095703, "time_total_s": 590.5490851402283, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 590.5490851402283, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 75.92}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 35.80250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 33.05, 37.05, 33.05, 33.05, 32.05, 32.05, 36.05, 33.05, 38.05, 33.05, 36.05, 33.05, 38.05, 33.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 33.05, 37.05, 36.05, 36.05, 37.05, 37.05, 33.05, 33.05, 37.05, 38.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.05, 32.05, 33.05, 33.05, 37.05, 33.05, 37.05, 37.05, 32.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 33.05, 37.05, 37.05, 37.05, 33.05, 37.05, 36.05, 36.05, 33.05, 37.05, 33.05, 36.05, 37.05, 37.05, 38.05, 38.05, 33.05, 37.05, 33.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 32.05, 33.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 33.05, 37.05, 37.05, 36.05, 37.05, 32.05, 37.05, 33.05, 33.05, 37.05, 33.05, 33.05, 32.05, 33.05, 36.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 32.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 36.05, 37.05, 37.05, 36.05, 38.05, 36.05, 38.05, 33.05, 36.05, 37.05, 37.05, 37.05, 33.05, 37.05, 33.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 33.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 33.05, 37.05, 33.05, 33.05, 33.05, 37.05, 33.05, 33.05, 37.05, 33.05, 37.05, 33.05, 36.05, 37.05, 37.05, 32.05, 37.05, 36.05, 33.05, 36.05, 32.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 37.05, 32.05, 37.05, 33.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 33.05, 33.05, 37.05, 33.05, 37.05, 37.05, 33.05, 37.05, 37.05, 32.05, 36.05, 33.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 36.05, 32.05, 37.05, 33.05, 37.05, 36.05, 33.05, 37.05, 38.05, 37.05, 32.05, 33.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 33.05, 37.05, 36.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 32.05, 33.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 37.05, 33.05, 37.05, 37.05, 32.05, 36.05, 37.05, 32.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 37.05, 33.05, 37.05, 33.05, 37.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 32.05, 38.05, 37.05, 37.05, 37.05, 32.05, 37.05, 37.05, 37.05, 37.05, 36.05, 33.05, 37.05, 33.05, 37.05, 38.05, 37.05, 33.05, 36.05, 37.05, 38.05, 32.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 32.05, 36.05, 37.05, 36.05, 33.05, 37.05, 37.05, 33.05, 36.05, 33.05, 37.05, 33.05, 37.05, 36.05, 33.05, 33.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 32.05, 37.05, 36.05, 37.05, 33.05, 33.05, 33.05, 36.05, 37.05, 32.05, 36.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 33.05, 33.05, 37.05, 37.05, 33.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 33.05, 33.05, 33.05, 36.05, 33.05, 33.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 37.05, 37.05, 33.05, 37.05, 33.05, 33.05, 37.05, 33.05, 33.05, 38.05, 38.05, 37.05, 37.05, 36.05, 33.05, 33.05, 36.05, 37.05, 37.05, 36.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 33.05, 38.05, 37.05, 37.05, 33.05, 37.05, 37.05, 38.05, 36.05, 32.05, 37.05, 32.05, 36.05, 38.05, 37.05, 33.05, 37.05, 36.05, 33.05, 37.05, 33.05, 33.05, 38.05, 32.05, 37.05, 37.05, 37.05, 32.05, 37.05, 38.05, 36.05, 37.05, 37.05, 38.05, 37.05, 36.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 33.05, 33.05, 37.05, 33.05, 33.05, 37.05, 32.05, 33.05, 33.05, 37.05, 36.05, 37.05, 37.05, 32.05, 33.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 33.05, 36.05, 37.05, 36.05, 37.05, 33.05, 37.05, 37.05, 37.05, 32.05, 36.05, 37.05, 36.05, 36.05, 37.05, 36.05, 33.05, 37.05, 36.05, 33.05, 33.05, 37.05, 36.05, 32.05, 37.05, 36.05, 37.05, 32.05, 37.05, 32.05, 37.05, 37.05, 37.05, 32.05, 37.05, 33.05, 37.05, 37.05, 36.05, 37.05, 36.05, 36.05, 37.05, 33.05, 37.05, 37.05, 36.05, 36.05, 37.05, 33.05, 37.05, 38.05, 37.05, 33.05, 32.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 33.05, 37.05, 37.05, 36.05, 32.05, 37.05, 33.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 32.05, 33.05, 37.05, 37.05, 33.05, 37.05, 36.05, 33.05, 36.05, 37.05, 33.05, 33.05, 32.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 31.049999999999997, 32.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 32.05, 32.05, 37.05, 37.05, 37.05, 36.05, 33.05, 37.05, 36.05, 36.05, 37.05, 37.05, 36.05, 36.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 37.05, 32.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 33.05, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 33.05, 31.049999999999997, 37.05, 32.05, 33.05, 37.05, 33.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 33.05, 36.05, 36.05, 37.05, 36.05, 33.05, 37.05, 36.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 33.05, 37.05, 37.05, 33.05, 37.05, 36.05, 37.05, 37.05, 36.05, 33.05, 33.05, 33.05, 33.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 32.05, 37.05, 37.05, 36.05, 33.05, 32.05, 37.05, 32.05, 33.05, 33.05, 36.05, 37.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13646948154576902, "mean_inference_ms": 0.5570531308267551, "mean_action_processing_ms": 0.043380056475107176, "mean_env_wait_ms": 0.047663083127324236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 624000, "agent_timesteps_total": 624000, "timers": {"sample_time_ms": 1572.312, "sample_throughput": 2544.024, "load_time_ms": 0.96, "load_throughput": 4165871.924, "learn_time_ms": 2151.643, "learn_throughput": 1859.045, "update_time_ms": 1.621}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.6551254020669148e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 2.4995954036712646, "policy_loss": -0.07009680569171906, "vf_loss": 2.569692373275757, "vf_explained_var": 0.972972571849823, "kl": 0.21045689284801483, "entropy": 0.1720341593027115, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 624000, "num_agent_steps_sampled": 624000, "num_steps_trained": 624000, "num_agent_steps_trained": 624000}, "done": false, "episodes_total": 124800, "training_iteration": 156, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-55", "timestamp": 1628629315, "time_this_iter_s": 3.7428579330444336, "time_total_s": 594.2919430732727, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 594.2919430732727, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 37.01666666666667, "ram_util_percent": 75.89999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 33.05, "episode_reward_mean": 37.02125000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 38.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 33.05, 37.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 36.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 38.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13646356515088867, "mean_inference_ms": 0.5570270295046713, "mean_action_processing_ms": 0.04337531485431771, "mean_env_wait_ms": 0.04766144197717842, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 628000, "agent_timesteps_total": 628000, "timers": {"sample_time_ms": 1573.692, "sample_throughput": 2541.794, "load_time_ms": 0.956, "load_throughput": 4182384.205, "learn_time_ms": 2147.364, "learn_throughput": 1862.749, "update_time_ms": 1.625}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.482688159943791e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.02786744199693203, "policy_loss": -0.09414482116699219, "vf_loss": 0.12201189994812012, "vf_explained_var": 0.9988216757774353, "kl": 0.15116465091705322, "entropy": 0.29638737440109253, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 628000, "num_agent_steps_sampled": 628000, "num_steps_trained": 628000, "num_agent_steps_trained": 628000}, "done": false, "episodes_total": 125600, "training_iteration": 157, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-01-59", "timestamp": 1628629319, "time_this_iter_s": 3.7063138484954834, "time_total_s": 597.9982569217682, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 597.9982569217682, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 75.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 31.049999999999997, "episode_reward_mean": 35.55125000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 38.05, 37.05, 34.05, 33.05, 37.05, 37.05, 37.05, 35.05, 38.05, 34.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 34.05, 37.05, 35.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 35.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 37.05, 34.05, 35.05, 34.05, 35.05, 37.05, 34.05, 34.05, 37.05, 35.05, 37.05, 34.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 34.05, 33.05, 37.05, 34.05, 35.05, 38.05, 37.05, 33.05, 37.05, 34.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 34.05, 35.05, 36.05, 34.05, 34.05, 34.05, 35.05, 34.05, 37.05, 35.05, 37.05, 34.05, 38.05, 34.05, 34.05, 38.05, 37.05, 34.05, 38.05, 37.05, 37.05, 34.05, 34.05, 37.05, 37.05, 35.05, 37.05, 37.05, 35.05, 37.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 37.05, 37.05, 36.05, 34.05, 34.05, 34.05, 34.05, 34.05, 35.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 34.05, 35.05, 36.05, 34.05, 34.05, 36.05, 34.05, 34.05, 37.05, 34.05, 34.05, 37.05, 35.05, 34.05, 34.05, 37.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 34.05, 34.05, 34.05, 34.05, 37.05, 33.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 34.05, 37.05, 34.05, 34.05, 38.05, 37.05, 35.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 38.05, 34.05, 34.05, 34.05, 34.05, 35.05, 34.05, 37.05, 34.05, 37.05, 34.05, 37.05, 34.05, 37.05, 34.05, 35.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 36.05, 34.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 31.049999999999997, 37.05, 34.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 34.05, 34.05, 37.05, 35.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 34.05, 34.05, 34.05, 34.05, 38.05, 37.05, 34.05, 34.05, 37.05, 36.05, 35.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 34.05, 37.05, 33.05, 34.05, 37.05, 37.05, 34.05, 37.05, 37.05, 34.05, 34.05, 34.05, 37.05, 35.05, 38.05, 35.05, 35.05, 35.05, 34.05, 33.05, 34.05, 34.05, 37.05, 38.05, 37.05, 34.05, 36.05, 34.05, 35.05, 37.05, 36.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 34.05, 35.05, 36.05, 37.05, 37.05, 37.05, 34.05, 34.05, 34.05, 38.05, 34.05, 37.05, 37.05, 33.05, 37.05, 38.05, 34.05, 34.05, 37.05, 37.05, 34.05, 33.05, 34.05, 37.05, 36.05, 37.05, 37.05, 38.05, 34.05, 34.05, 34.05, 37.05, 34.05, 34.05, 35.05, 34.05, 34.05, 34.05, 37.05, 37.05, 35.05, 37.05, 34.05, 35.05, 37.05, 37.05, 34.05, 34.05, 36.05, 37.05, 34.05, 37.05, 35.05, 37.05, 38.05, 37.05, 34.05, 37.05, 37.05, 35.05, 34.05, 34.05, 37.05, 38.05, 34.05, 37.05, 34.05, 34.05, 34.05, 37.05, 33.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 35.05, 35.05, 37.05, 35.05, 37.05, 37.05, 35.05, 35.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 36.05, 35.05, 38.05, 34.05, 34.05, 34.05, 37.05, 34.05, 35.05, 33.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 34.05, 35.05, 38.05, 34.05, 34.05, 35.05, 34.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 34.05, 35.05, 35.05, 34.05, 37.05, 34.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 34.05, 35.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 35.05, 34.05, 35.05, 38.05, 34.05, 37.05, 34.05, 37.05, 37.05, 34.05, 34.05, 35.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 34.05, 34.05, 37.05, 37.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 34.05, 34.05, 37.05, 34.05, 34.05, 34.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 37.05, 38.05, 37.05, 37.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 35.05, 34.05, 37.05, 34.05, 34.05, 35.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 37.05, 35.05, 34.05, 37.05, 34.05, 35.05, 37.05, 34.05, 34.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 38.05, 37.05, 34.05, 37.05, 35.05, 34.05, 35.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 36.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 37.05, 36.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 37.05, 37.05, 34.05, 34.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 34.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 33.05, 34.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 35.05, 37.05, 34.05, 36.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 38.05, 34.05, 34.05, 34.05, 37.05, 34.05, 35.05, 34.05, 34.05, 35.05, 34.05, 34.05, 34.05, 34.05, 37.05, 36.05, 35.05, 34.05, 34.05, 38.05, 34.05, 37.05, 35.05, 37.05, 34.05, 37.05, 34.05, 35.05, 34.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 38.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 35.05, 34.05, 34.05, 37.05, 34.05, 38.05, 35.05, 34.05, 34.05, 37.05, 34.05, 37.05, 36.05, 37.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 37.05, 35.05, 37.05, 36.05, 37.05, 37.05, 37.05, 34.05, 37.05, 38.05, 35.05, 34.05, 37.05, 34.05, 35.05, 37.05, 34.05, 37.05, 33.05, 35.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 37.05, 37.05, 34.05, 37.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 37.05, 37.05, 34.05, 35.05, 38.05, 37.05, 34.05, 34.05, 34.05, 37.05, 37.05, 37.05, 34.05, 34.05, 34.05, 34.05, 36.05, 34.05, 37.05, 37.05, 37.05, 34.05, 35.05, 34.05, 37.05, 37.05, 38.05, 35.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 37.05, 38.05, 37.05, 37.05, 34.05, 34.05, 34.05, 35.05, 37.05, 34.05, 34.05, 34.05, 37.05, 36.05, 37.05, 34.05, 34.05, 34.05, 34.05, 34.05, 37.05, 34.05, 38.05, 37.05, 35.05, 37.05, 34.05, 34.05, 34.05, 38.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13644162214432975, "mean_inference_ms": 0.5569629042422188, "mean_action_processing_ms": 0.04336828604546104, "mean_env_wait_ms": 0.04765580433612326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 632000, "agent_timesteps_total": 632000, "timers": {"sample_time_ms": 1577.528, "sample_throughput": 2535.612, "load_time_ms": 0.95, "load_throughput": 4208613.285, "learn_time_ms": 2148.121, "learn_throughput": 1862.092, "update_time_ms": 1.634}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.7240322399156867e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 2.109724521636963, "policy_loss": -0.06782081723213196, "vf_loss": 2.177543878555298, "vf_explained_var": 0.9798789024353027, "kl": 0.25711745023727417, "entropy": 0.1853526085615158, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 632000, "num_agent_steps_sampled": 632000, "num_steps_trained": 632000, "num_agent_steps_trained": 632000}, "done": false, "episodes_total": 126400, "training_iteration": 158, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-03", "timestamp": 1628629323, "time_this_iter_s": 3.750687837600708, "time_total_s": 601.7489447593689, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 601.7489447593689, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 36.32000000000001, "ram_util_percent": 76.02000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 34.05, "episode_reward_mean": 37.08375000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 34.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 34.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 34.05, 36.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.05, 36.05, 38.05, 34.05, 36.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 34.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 34.05, 37.05, 35.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 36.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 34.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 38.05, 36.05, 36.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 34.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 36.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 34.05, 37.05, 38.05, 37.05, 38.05, 35.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 35.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 34.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 34.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 36.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 34.05, 37.05, 37.05, 37.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13644001523586058, "mean_inference_ms": 0.5569562563027572, "mean_action_processing_ms": 0.04336616948648208, "mean_env_wait_ms": 0.047655362842158704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 636000, "agent_timesteps_total": 636000, "timers": {"sample_time_ms": 1576.287, "sample_throughput": 2537.608, "load_time_ms": 0.958, "load_throughput": 4174059.81, "learn_time_ms": 2147.344, "learn_throughput": 1862.766, "update_time_ms": 1.635}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.586048246186692e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.3808860778808594, "policy_loss": -0.04447593539953232, "vf_loss": 0.425361692905426, "vf_explained_var": 0.9959911704063416, "kl": 0.05930178612470627, "entropy": 0.15279041230678558, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 636000, "num_agent_steps_sampled": 636000, "num_steps_trained": 636000, "num_agent_steps_trained": 636000}, "done": false, "episodes_total": 127200, "training_iteration": 159, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-06", "timestamp": 1628629326, "time_this_iter_s": 3.7107911109924316, "time_total_s": 605.4597358703613, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 605.4597358703613, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 37.1, "ram_util_percent": 76.05}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 37.47250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 35.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 35.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13643212524219706, "mean_inference_ms": 0.5569098142168959, "mean_action_processing_ms": 0.04336117813738964, "mean_env_wait_ms": 0.04765281686902016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 640000, "agent_timesteps_total": 640000, "timers": {"sample_time_ms": 1581.303, "sample_throughput": 2529.56, "load_time_ms": 0.955, "load_throughput": 4186663.339, "learn_time_ms": 2142.042, "learn_throughput": 1867.377, "update_time_ms": 1.624}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.379071914532688e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.056608833372592926, "policy_loss": -0.07675754278898239, "vf_loss": 0.13336624205112457, "vf_explained_var": 0.9987663626670837, "kl": 0.015923580154776573, "entropy": 0.1360757201910019, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 640000, "num_agent_steps_sampled": 640000, "num_steps_trained": 640000, "num_agent_steps_trained": 640000}, "done": false, "episodes_total": 128000, "training_iteration": 160, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-10", "timestamp": 1628629330, "time_this_iter_s": 3.7148561477661133, "time_total_s": 609.1745920181274, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 609.1745920181274, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 36.12, "ram_util_percent": 75.92}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 37.69847160970001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.827287760000004, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 35.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 37.05, 37.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13644269069372247, "mean_inference_ms": 0.5569561726976603, "mean_action_processing_ms": 0.04336292634299422, "mean_env_wait_ms": 0.0476572951254759, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 644000, "agent_timesteps_total": 644000, "timers": {"sample_time_ms": 1585.25, "sample_throughput": 2523.262, "load_time_ms": 0.958, "load_throughput": 4173540.635, "learn_time_ms": 2142.656, "learn_throughput": 1866.842, "update_time_ms": 1.628}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.379071914532688e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.033648598939180374, "policy_loss": -0.0823444351553917, "vf_loss": 0.11599285155534744, "vf_explained_var": 0.9989495873451233, "kl": 0.02307625487446785, "entropy": 0.09301454573869705, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 644000, "num_agent_steps_sampled": 644000, "num_steps_trained": 644000, "num_agent_steps_trained": 644000}, "done": false, "episodes_total": 128800, "training_iteration": 161, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-14", "timestamp": 1628629334, "time_this_iter_s": 3.7529683113098145, "time_total_s": 612.9275603294373, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 612.9275603294373, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 36.44, "ram_util_percent": 75.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 37.87375000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 37.05, 37.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 37.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13643428959457476, "mean_inference_ms": 0.5568999226390777, "mean_action_processing_ms": 0.04335780985867879, "mean_env_wait_ms": 0.04765436614229463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 648000, "agent_timesteps_total": 648000, "timers": {"sample_time_ms": 1586.298, "sample_throughput": 2521.594, "load_time_ms": 0.96, "load_throughput": 4168459.551, "learn_time_ms": 2144.934, "learn_throughput": 1864.859, "update_time_ms": 1.624}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.2568608326546382e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.007770491298288107, "policy_loss": -0.05841969698667526, "vf_loss": 0.06618791818618774, "vf_explained_var": 0.9994046092033386, "kl": 0.1811189204454422, "entropy": 0.0013331550871953368, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 648000, "num_agent_steps_sampled": 648000, "num_steps_trained": 648000, "num_agent_steps_trained": 648000}, "done": false, "episodes_total": 129600, "training_iteration": 162, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-18", "timestamp": 1628629338, "time_this_iter_s": 3.7740883827209473, "time_total_s": 616.7016487121582, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 616.7016487121582, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 36.983333333333334, "ram_util_percent": 75.83333333333333}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13640760341673785, "mean_inference_ms": 0.5568031340277177, "mean_action_processing_ms": 0.0433482474229617, "mean_env_wait_ms": 0.04764619353167109, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 652000, "agent_timesteps_total": 652000, "timers": {"sample_time_ms": 1581.722, "sample_throughput": 2528.889, "load_time_ms": 0.955, "load_throughput": 4186767.818, "learn_time_ms": 2128.766, "learn_throughput": 1879.023, "update_time_ms": 1.591}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.8852912035072222e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.1326899379491806, "policy_loss": -0.13271987438201904, "vf_loss": 4.950878438768e-14, "vf_explained_var": 1.0, "kl": 1.5882071256637573, "entropy": 0.19850163161754608, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 652000, "num_agent_steps_sampled": 652000, "num_steps_trained": 652000, "num_agent_steps_trained": 652000}, "done": false, "episodes_total": 130400, "training_iteration": 163, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-21", "timestamp": 1628629341, "time_this_iter_s": 3.68287992477417, "time_total_s": 620.3845286369324, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 620.3845286369324, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 36.2, "ram_util_percent": 75.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 30.050000000000004, "episode_reward_min": 13.049999999999999, "episode_reward_mean": 18.048750000000005, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 22.049999999999997, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.05, 14.049999999999999, 22.050000000000004, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 22.049999999999997, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.049999999999997, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.049999999999997, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.05, 30.049999999999997, 14.049999999999999, 13.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.05, 30.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.049999999999997, 14.049999999999999, 22.049999999999997, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.05, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1364053221552922, "mean_inference_ms": 0.556769134243082, "mean_action_processing_ms": 0.043345287585176265, "mean_env_wait_ms": 0.047645361802104345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 656000, "agent_timesteps_total": 656000, "timers": {"sample_time_ms": 1586.535, "sample_throughput": 2521.218, "load_time_ms": 0.955, "load_throughput": 4189067.665, "learn_time_ms": 2127.96, "learn_throughput": 1879.735, "update_time_ms": 1.483}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.8279369871597737e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 86.30699157714844, "policy_loss": -0.07161761820316315, "vf_loss": 86.37861633300781, "vf_explained_var": 0.6655089855194092, "kl": 0.017772363498806953, "entropy": 0.27554553747177124, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 656000, "num_agent_steps_sampled": 656000, "num_steps_trained": 656000, "num_agent_steps_trained": 656000}, "done": false, "episodes_total": 131200, "training_iteration": 164, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-25", "timestamp": 1628629345, "time_this_iter_s": 3.7287590503692627, "time_total_s": 624.1132876873016, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 624.1132876873016, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 36.84, "ram_util_percent": 75.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 30.050000000000004, "episode_reward_min": 6.049999999999999, "episode_reward_mean": 19.970000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 22.050000000000004, 30.05, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 30.05, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 6.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.05, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.05, 30.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 14.049999999999999, 30.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 30.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.049999999999997, 22.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 30.05, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.049999999999997, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 22.049999999999997, 30.050000000000004, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.049999999999997, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.05, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 30.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 14.049999999999999, 30.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.05, 14.049999999999999, 30.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.05, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.049999999999997, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 22.049999999999997, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.049999999999997, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.049999999999997, 14.049999999999999, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.049999999999997, 30.05, 22.050000000000004, 14.049999999999999, 22.05, 14.049999999999999, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 22.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1364054115427167, "mean_inference_ms": 0.5567728687238186, "mean_action_processing_ms": 0.043343496831401096, "mean_env_wait_ms": 0.04764578859667222, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 660000, "agent_timesteps_total": 660000, "timers": {"sample_time_ms": 1583.641, "sample_throughput": 2525.826, "load_time_ms": 0.957, "load_throughput": 4178009.762, "learn_time_ms": 2127.644, "learn_throughput": 1880.013, "update_time_ms": 1.486}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.8279369871597737e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 18.290973663330078, "policy_loss": -0.07376185804605484, "vf_loss": 18.364734649658203, "vf_explained_var": 0.7410133481025696, "kl": 0.04570043459534645, "entropy": 0.32002416253089905, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 660000, "num_agent_steps_sampled": 660000, "num_steps_trained": 660000, "num_agent_steps_trained": 660000}, "done": false, "episodes_total": 132000, "training_iteration": 165, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-29", "timestamp": 1628629349, "time_this_iter_s": 3.7356278896331787, "time_total_s": 627.8489155769348, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 627.8489155769348, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 36.88333333333333, "ram_util_percent": 75.91666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 14.049999999999999, "episode_reward_mean": 22.83000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.049999999999997, 22.050000000000004, 22.050000000000004, 30.05, 22.05, 14.049999999999999, 30.049999999999997, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 30.05, 30.050000000000004, 22.05, 30.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 30.05, 22.050000000000004, 22.050000000000004, 30.049999999999997, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 30.05, 30.049999999999997, 30.050000000000004, 30.05, 30.05, 22.05, 30.05, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.049999999999997, 22.049999999999997, 30.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.05, 14.049999999999999, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 30.050000000000004, 14.049999999999999, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 30.049999999999997, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.049999999999997, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 38.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.05, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.049999999999997, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.049999999999997, 22.050000000000004, 30.050000000000004, 14.049999999999999, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.049999999999997, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.05, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.049999999999997, 22.05, 22.049999999999997, 14.049999999999999, 30.05, 30.05, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.049999999999997, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 14.049999999999999, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.05, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.05, 30.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 30.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 14.049999999999999, 30.050000000000004, 22.049999999999997, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 14.049999999999999, 30.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.05, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.049999999999997, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.05, 30.050000000000004, 22.050000000000004, 14.049999999999999, 30.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.049999999999997, 22.050000000000004, 30.049999999999997, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 38.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 14.049999999999999, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.049999999999997, 22.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 30.05, 22.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 14.049999999999999, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.049999999999997, 22.05, 14.049999999999999, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 14.049999999999999, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 22.049999999999997, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 22.049999999999997, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.049999999999997, 30.050000000000004, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.049999999999997, 14.049999999999999, 14.049999999999999, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 30.05, 30.05, 22.050000000000004, 22.049999999999997, 22.050000000000004, 30.05, 22.050000000000004, 22.05, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.05, 14.049999999999999, 30.050000000000004, 30.050000000000004, 14.049999999999999, 22.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.049999999999997, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 30.05, 22.049999999999997, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.049999999999997, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.05, 22.05, 22.050000000000004, 22.05, 22.049999999999997, 22.05, 22.050000000000004, 30.050000000000004, 14.049999999999999, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 22.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.050000000000004, 22.050000000000004, 14.049999999999999, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.049999999999997, 30.050000000000004, 30.049999999999997, 22.050000000000004, 22.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13639458541385008, "mean_inference_ms": 0.5567121624084485, "mean_action_processing_ms": 0.04333763361608406, "mean_env_wait_ms": 0.047642529134828984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 664000, "agent_timesteps_total": 664000, "timers": {"sample_time_ms": 1586.214, "sample_throughput": 2521.728, "load_time_ms": 0.959, "load_throughput": 4171983.886, "learn_time_ms": 2121.886, "learn_throughput": 1885.116, "update_time_ms": 1.493}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.2419054807396606e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 16.360361099243164, "policy_loss": -0.11329589784145355, "vf_loss": 16.473649978637695, "vf_explained_var": 0.7977821826934814, "kl": 0.11969974637031555, "entropy": 0.32446515560150146, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 664000, "num_agent_steps_sampled": 664000, "num_steps_trained": 664000, "num_agent_steps_trained": 664000}, "done": false, "episodes_total": 132800, "training_iteration": 166, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-33", "timestamp": 1628629353, "time_this_iter_s": 3.710336208343506, "time_total_s": 631.5592517852783, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 631.5592517852783, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 36.12, "ram_util_percent": 75.9}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 14.049999999999999, "episode_reward_mean": 28.04875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.050000000000004, 30.05, 22.050000000000004, 38.05, 30.05, 30.050000000000004, 35.05, 30.049999999999997, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 35.05, 30.05, 22.049999999999997, 35.05, 35.05, 35.05, 22.050000000000004, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 22.05, 35.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 35.05, 22.050000000000004, 22.050000000000004, 22.05, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 35.05, 38.05, 30.05, 30.05, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.049999999999997, 30.05, 22.05, 22.050000000000004, 35.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 35.05, 30.05, 22.050000000000004, 35.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 35.05, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 38.05, 38.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 35.05, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 30.05, 30.049999999999997, 35.05, 30.05, 35.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 30.05, 30.050000000000004, 22.05, 22.050000000000004, 22.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 30.05, 35.05, 30.05, 22.050000000000004, 22.049999999999997, 22.050000000000004, 30.05, 30.05, 30.05, 35.05, 35.05, 38.05, 22.050000000000004, 30.05, 35.05, 30.05, 30.050000000000004, 22.05, 38.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 22.049999999999997, 22.050000000000004, 22.05, 30.050000000000004, 22.050000000000004, 30.05, 35.05, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 14.049999999999999, 22.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 14.049999999999999, 30.05, 22.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 35.05, 22.050000000000004, 35.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 35.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 35.05, 22.050000000000004, 35.05, 22.050000000000004, 30.05, 35.05, 30.05, 35.05, 22.050000000000004, 30.05, 22.05, 38.05, 30.05, 27.05, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 35.05, 35.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 35.05, 14.049999999999999, 30.05, 30.05, 14.049999999999999, 22.050000000000004, 30.049999999999997, 38.05, 30.05, 35.05, 30.05, 22.050000000000004, 27.050000000000004, 30.050000000000004, 27.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 38.05, 35.05, 30.05, 22.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 35.05, 30.050000000000004, 35.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 35.05, 38.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 35.05, 35.05, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 22.05, 38.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 30.05, 38.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 35.05, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 27.050000000000004, 35.05, 22.050000000000004, 35.05, 35.05, 30.05, 30.05, 35.05, 22.050000000000004, 30.050000000000004, 38.05, 35.05, 30.050000000000004, 38.05, 22.050000000000004, 35.05, 35.05, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 38.05, 22.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 35.05, 30.050000000000004, 22.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.05, 30.050000000000004, 35.05, 35.05, 35.05, 22.05, 35.05, 22.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.049999999999997, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 30.05, 22.050000000000004, 30.05, 35.05, 30.050000000000004, 38.05, 30.05, 38.05, 35.05, 38.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 35.05, 30.049999999999997, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 35.05, 30.05, 22.049999999999997, 30.05, 30.050000000000004, 35.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 35.05, 35.05, 30.050000000000004, 30.050000000000004, 22.049999999999997, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 35.05, 30.05, 35.05, 30.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.05, 30.05, 22.049999999999997, 22.050000000000004, 22.050000000000004, 30.05, 22.049999999999997, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 27.05, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 22.050000000000004, 35.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 35.05, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 30.05, 35.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 30.05, 30.049999999999997, 30.05, 30.05, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 30.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 35.05, 14.049999999999999, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 22.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 30.05, 30.05, 35.05, 38.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 35.05, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.05, 35.05, 35.05, 35.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 22.050000000000004, 38.05, 22.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13640030122493627, "mean_inference_ms": 0.5567408624234839, "mean_action_processing_ms": 0.04333869834454772, "mean_env_wait_ms": 0.047646463028863176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 668000, "agent_timesteps_total": 668000, "timers": {"sample_time_ms": 1588.328, "sample_throughput": 2518.371, "load_time_ms": 0.969, "load_throughput": 4126424.32, "learn_time_ms": 2123.589, "learn_throughput": 1883.604, "update_time_ms": 1.508}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 6.362858403008431e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 24.650100708007812, "policy_loss": -0.09228501468896866, "vf_loss": 24.742382049560547, "vf_explained_var": 0.7735087275505066, "kl": 0.09108428657054901, "entropy": 0.3312471807003021, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 668000, "num_agent_steps_sampled": 668000, "num_steps_trained": 668000, "num_agent_steps_trained": 668000}, "done": false, "episodes_total": 133600, "training_iteration": 167, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-36", "timestamp": 1628629356, "time_this_iter_s": 3.745850086212158, "time_total_s": 635.3051018714905, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 635.3051018714905, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 36.839999999999996, "ram_util_percent": 75.94000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.049999999999997, "episode_reward_mean": 30.68750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.05, 34.05, 30.050000000000004, 34.05, 38.05, 30.05, 30.050000000000004, 30.05, 30.05, 35.05, 30.05, 22.050000000000004, 35.05, 34.05, 30.050000000000004, 34.05, 35.05, 38.05, 30.05, 30.05, 22.050000000000004, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 34.05, 30.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 22.049999999999997, 30.050000000000004, 22.050000000000004, 38.05, 38.05, 35.05, 30.050000000000004, 35.05, 34.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 35.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 38.05, 35.05, 30.050000000000004, 30.05, 34.05, 34.05, 35.05, 34.05, 34.05, 22.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 34.05, 34.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 35.05, 34.05, 30.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 35.05, 34.05, 22.050000000000004, 30.05, 30.050000000000004, 34.05, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 22.050000000000004, 30.05, 35.05, 22.050000000000004, 22.050000000000004, 34.05, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 38.05, 30.05, 34.05, 30.05, 22.050000000000004, 34.05, 30.050000000000004, 38.05, 30.05, 35.05, 22.050000000000004, 30.050000000000004, 30.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 30.05, 30.05, 34.05, 22.050000000000004, 30.05, 30.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 38.05, 35.05, 35.05, 30.05, 38.05, 30.05, 30.050000000000004, 34.05, 30.050000000000004, 22.050000000000004, 35.05, 30.05, 35.05, 30.05, 22.050000000000004, 34.05, 30.05, 34.05, 30.050000000000004, 34.05, 35.05, 22.050000000000004, 35.05, 22.050000000000004, 38.05, 38.05, 38.05, 38.05, 22.050000000000004, 34.05, 34.05, 22.050000000000004, 35.05, 30.05, 34.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 34.05, 34.05, 35.05, 34.05, 30.05, 35.05, 30.050000000000004, 35.05, 38.05, 22.050000000000004, 35.05, 22.050000000000004, 30.050000000000004, 35.05, 30.05, 30.05, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 35.05, 38.05, 22.050000000000004, 34.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 34.05, 30.05, 30.050000000000004, 38.05, 30.05, 35.05, 34.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 34.05, 34.05, 30.05, 22.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 34.05, 22.050000000000004, 38.05, 30.05, 30.05, 34.05, 30.050000000000004, 34.05, 22.050000000000004, 30.05, 34.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 22.050000000000004, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 35.05, 34.05, 38.05, 30.050000000000004, 22.050000000000004, 30.05, 30.05, 30.05, 30.05, 35.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 34.05, 34.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 35.05, 30.05, 30.050000000000004, 35.05, 34.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 34.05, 30.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 34.05, 34.05, 30.050000000000004, 34.05, 34.05, 34.05, 22.050000000000004, 30.05, 38.05, 34.05, 34.05, 22.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 34.05, 34.05, 22.050000000000004, 35.05, 35.05, 30.050000000000004, 34.05, 22.050000000000004, 35.05, 22.050000000000004, 34.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 34.05, 22.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 35.05, 35.05, 30.050000000000004, 30.05, 30.050000000000004, 30.05, 34.05, 22.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.05, 30.05, 35.05, 30.050000000000004, 38.05, 22.050000000000004, 35.05, 30.050000000000004, 38.05, 30.050000000000004, 35.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 34.05, 35.05, 30.05, 22.050000000000004, 22.050000000000004, 35.05, 35.05, 34.05, 30.050000000000004, 22.050000000000004, 30.05, 30.050000000000004, 30.05, 35.05, 30.050000000000004, 35.05, 30.05, 30.050000000000004, 35.05, 38.05, 30.050000000000004, 38.05, 34.05, 38.05, 30.05, 30.05, 30.050000000000004, 35.05, 30.05, 22.050000000000004, 22.050000000000004, 34.05, 30.050000000000004, 35.05, 38.05, 34.05, 34.05, 30.050000000000004, 30.050000000000004, 34.05, 38.05, 38.05, 30.050000000000004, 35.05, 34.05, 34.05, 30.05, 30.05, 30.050000000000004, 34.05, 34.05, 38.05, 35.05, 22.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 34.05, 30.050000000000004, 34.05, 30.05, 22.050000000000004, 30.050000000000004, 34.05, 30.05, 30.050000000000004, 34.05, 34.05, 34.05, 22.050000000000004, 30.05, 34.05, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 35.05, 38.05, 30.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.05, 34.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 34.05, 30.05, 35.05, 22.050000000000004, 38.05, 22.050000000000004, 35.05, 35.05, 22.050000000000004, 30.05, 30.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 22.050000000000004, 35.05, 22.050000000000004, 35.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 34.05, 34.05, 38.05, 30.05, 34.05, 35.05, 30.050000000000004, 38.05, 30.050000000000004, 34.05, 22.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 34.05, 38.05, 34.05, 34.05, 34.05, 35.05, 30.05, 32.05, 38.05, 22.050000000000004, 38.05, 30.05, 34.05, 35.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 30.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 30.050000000000004, 30.05, 34.05, 34.05, 30.050000000000004, 22.050000000000004, 38.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 35.05, 38.05, 35.05, 34.05, 34.05, 30.05, 30.050000000000004, 30.05, 30.05, 22.050000000000004, 30.050000000000004, 22.050000000000004, 22.050000000000004, 35.05, 22.050000000000004, 34.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 34.05, 30.05, 30.050000000000004, 30.05, 30.05, 30.05, 30.050000000000004, 38.05, 34.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.050000000000004, 22.050000000000004, 35.05, 34.05, 22.050000000000004, 35.05, 30.050000000000004, 34.05, 38.05, 22.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 30.05, 22.050000000000004, 30.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 34.05, 38.05, 22.050000000000004, 22.050000000000004, 38.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 35.05, 30.050000000000004, 30.050000000000004, 34.05, 22.050000000000004, 34.05, 34.05, 35.05, 30.050000000000004, 30.05, 34.05, 34.05, 34.05, 34.05, 34.05, 30.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 38.05, 22.050000000000004, 38.05, 34.05, 30.05, 22.050000000000004, 22.050000000000004, 34.05, 34.05, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 30.05, 34.05, 30.05, 35.05, 34.05, 34.05, 38.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 34.05, 38.05, 22.050000000000004, 38.05, 38.05, 22.050000000000004, 38.05, 30.05, 22.050000000000004, 22.050000000000004, 30.05, 22.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 38.05, 35.05, 35.05, 30.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 30.05, 30.050000000000004, 35.05, 22.050000000000004, 34.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 34.05, 30.05, 30.050000000000004, 22.050000000000004, 38.05, 34.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.05, 35.05, 38.05, 22.050000000000004, 30.050000000000004, 34.05, 35.05, 38.05, 38.05, 30.050000000000004, 34.05, 34.05, 35.05, 30.05, 38.05, 38.05, 34.05, 30.050000000000004, 30.05, 30.05, 30.050000000000004, 22.050000000000004, 22.050000000000004, 34.05, 35.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 30.05, 22.050000000000004, 30.050000000000004, 34.05, 34.05, 22.050000000000004, 30.05, 34.05, 22.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 35.05, 22.050000000000004, 35.05, 34.05, 34.05, 30.050000000000004, 22.050000000000004, 34.05, 30.05, 35.05, 34.05, 30.050000000000004, 22.050000000000004, 30.05, 35.05, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 34.05, 38.05, 34.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 34.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13639903558221564, "mean_inference_ms": 0.556733680899438, "mean_action_processing_ms": 0.043336195062188665, "mean_env_wait_ms": 0.04764691006170464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 672000, "agent_timesteps_total": 672000, "timers": {"sample_time_ms": 1591.175, "sample_throughput": 2513.865, "load_time_ms": 0.969, "load_throughput": 4127845.684, "learn_time_ms": 2120.964, "learn_throughput": 1885.935, "update_time_ms": 1.513}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 9.544286876916885e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 23.02118492126465, "policy_loss": -0.08539588004350662, "vf_loss": 23.10657501220703, "vf_explained_var": 0.7999871969223022, "kl": 0.041133955121040344, "entropy": 0.3089139461517334, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 672000, "num_agent_steps_sampled": 672000, "num_steps_trained": 672000, "num_agent_steps_trained": 672000}, "done": false, "episodes_total": 134400, "training_iteration": 168, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-40", "timestamp": 1628629360, "time_this_iter_s": 3.7521610260009766, "time_total_s": 639.0572628974915, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 639.0572628974915, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 36.766666666666666, "ram_util_percent": 75.88333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 22.050000000000004, "episode_reward_mean": 33.54625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 34.05, 30.050000000000004, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 35.05, 35.05, 34.05, 38.05, 34.05, 38.05, 30.05, 38.05, 38.05, 38.05, 34.05, 34.05, 35.05, 30.05, 22.050000000000004, 22.050000000000004, 34.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 35.05, 22.050000000000004, 30.050000000000004, 35.05, 30.05, 34.05, 34.05, 30.050000000000004, 35.05, 38.05, 34.05, 30.05, 30.05, 30.050000000000004, 38.05, 35.05, 38.05, 35.05, 30.050000000000004, 34.05, 38.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 27.050000000000004, 22.050000000000004, 34.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 34.05, 34.05, 30.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.05, 35.05, 38.05, 38.05, 34.05, 34.05, 30.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 38.05, 22.050000000000004, 38.05, 34.05, 38.05, 34.05, 30.05, 34.05, 38.05, 38.05, 34.05, 38.05, 30.05, 38.05, 22.050000000000004, 30.05, 34.05, 38.05, 34.05, 22.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 34.05, 35.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 35.05, 22.050000000000004, 35.05, 35.05, 38.05, 30.050000000000004, 34.05, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 34.05, 22.050000000000004, 30.05, 35.05, 34.05, 38.05, 38.05, 30.05, 30.05, 30.05, 38.05, 30.050000000000004, 38.05, 30.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 30.05, 35.05, 38.05, 38.05, 35.05, 35.05, 38.05, 34.05, 38.05, 34.05, 30.050000000000004, 38.05, 22.050000000000004, 30.05, 30.050000000000004, 34.05, 38.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 30.05, 35.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 30.050000000000004, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 34.05, 30.050000000000004, 34.05, 22.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 38.05, 30.050000000000004, 34.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.05, 34.05, 35.05, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 34.05, 35.05, 38.05, 22.050000000000004, 38.05, 35.05, 35.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 30.05, 35.05, 38.05, 35.05, 34.05, 35.05, 30.05, 30.05, 35.05, 34.05, 22.050000000000004, 38.05, 35.05, 34.05, 30.05, 34.05, 34.05, 30.05, 30.050000000000004, 35.05, 38.05, 38.05, 38.05, 35.05, 22.050000000000004, 30.05, 34.05, 30.050000000000004, 22.050000000000004, 30.05, 38.05, 30.05, 30.050000000000004, 34.05, 38.05, 30.050000000000004, 30.050000000000004, 35.05, 38.05, 30.050000000000004, 30.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 38.05, 34.05, 22.050000000000004, 38.05, 34.05, 30.05, 38.05, 38.05, 35.05, 38.05, 34.05, 30.050000000000004, 38.05, 34.05, 34.05, 30.050000000000004, 38.05, 34.05, 30.050000000000004, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 35.05, 35.05, 22.050000000000004, 30.050000000000004, 34.05, 30.05, 34.05, 22.050000000000004, 34.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 38.05, 30.05, 35.05, 34.05, 22.050000000000004, 30.050000000000004, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 30.05, 30.05, 30.050000000000004, 34.05, 38.05, 38.05, 35.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 30.05, 38.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 30.050000000000004, 34.05, 30.05, 38.05, 22.050000000000004, 35.05, 35.05, 34.05, 34.05, 38.05, 35.05, 35.05, 38.05, 38.05, 35.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 30.050000000000004, 38.05, 38.05, 34.05, 30.05, 34.05, 38.05, 38.05, 35.05, 38.05, 34.05, 34.05, 30.05, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 34.05, 38.05, 30.050000000000004, 38.05, 38.05, 34.05, 38.05, 30.05, 30.05, 35.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 34.05, 34.05, 30.050000000000004, 38.05, 34.05, 38.05, 30.05, 30.050000000000004, 38.05, 30.05, 35.05, 35.05, 38.05, 34.05, 34.05, 38.05, 38.05, 30.050000000000004, 35.05, 38.05, 30.05, 38.05, 27.05, 38.05, 38.05, 38.05, 35.05, 38.05, 22.050000000000004, 38.05, 38.05, 30.05, 30.05, 38.05, 35.05, 30.05, 38.05, 34.05, 38.05, 30.05, 30.05, 38.05, 35.05, 38.05, 30.05, 38.05, 30.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 35.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 22.050000000000004, 30.050000000000004, 34.05, 38.05, 34.05, 34.05, 35.05, 38.05, 38.05, 38.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 38.05, 30.05, 38.05, 34.05, 38.05, 30.05, 22.050000000000004, 34.05, 38.05, 22.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 34.05, 38.05, 22.050000000000004, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 30.05, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 38.05, 35.05, 30.050000000000004, 30.050000000000004, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 38.05, 34.05, 38.05, 35.05, 35.05, 30.05, 34.05, 30.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 34.05, 30.050000000000004, 35.05, 30.050000000000004, 34.05, 30.050000000000004, 34.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 34.05, 34.05, 22.050000000000004, 38.05, 30.05, 35.05, 35.05, 30.050000000000004, 34.05, 30.05, 38.05, 30.050000000000004, 38.05, 22.050000000000004, 35.05, 38.05, 30.05, 38.05, 30.050000000000004, 30.05, 38.05, 30.050000000000004, 38.05, 38.05, 35.05, 38.05, 22.050000000000004, 34.05, 34.05, 30.05, 35.05, 30.05, 38.05, 34.05, 34.05, 30.050000000000004, 35.05, 30.05, 34.05, 38.05, 38.05, 34.05, 22.050000000000004, 22.050000000000004, 30.050000000000004, 30.050000000000004, 22.050000000000004, 34.05, 30.05, 38.05, 22.050000000000004, 38.05, 30.050000000000004, 30.05, 30.05, 38.05, 22.050000000000004, 38.05, 22.050000000000004, 34.05, 30.050000000000004, 35.05, 30.050000000000004, 35.05, 38.05, 34.05, 30.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 38.05, 35.05, 38.05, 35.05, 22.050000000000004, 30.050000000000004, 38.05, 38.05, 38.05, 30.050000000000004, 30.050000000000004, 38.05, 34.05, 30.050000000000004, 38.05, 30.05, 30.05, 30.050000000000004, 30.050000000000004, 35.05, 30.050000000000004, 34.05, 30.050000000000004, 34.05, 38.05, 34.05, 30.05, 35.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 30.050000000000004, 38.05, 38.05, 30.05, 30.050000000000004, 30.05, 35.05, 30.050000000000004, 38.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 35.05, 22.050000000000004, 30.05, 30.050000000000004, 30.050000000000004, 35.05, 35.05, 30.05, 35.05, 35.05, 38.05, 30.050000000000004, 30.050000000000004, 35.05, 30.05, 38.05, 38.05, 35.05, 34.05, 38.05, 34.05, 30.050000000000004, 34.05, 34.05, 38.05, 38.05, 34.05, 30.05, 38.05, 35.05, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 34.05, 38.05, 30.05, 34.05, 30.050000000000004, 38.05, 34.05, 30.05, 22.050000000000004, 30.05, 30.050000000000004, 34.05, 30.050000000000004, 38.05, 22.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05, 30.050000000000004, 38.05, 30.05, 30.050000000000004, 34.05, 22.050000000000004, 38.05, 38.05, 35.05, 30.05, 30.05, 34.05, 38.05, 38.05, 30.05, 30.050000000000004, 30.050000000000004, 30.05, 38.05, 34.05, 30.05, 38.05, 30.050000000000004, 30.050000000000004, 34.05, 34.05, 30.05, 30.05, 22.050000000000004, 35.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 30.05, 30.05, 38.05, 30.05, 35.05, 34.05, 30.050000000000004, 38.05, 38.05, 34.05, 38.05, 30.050000000000004, 35.05, 35.05, 30.05, 38.05, 38.05, 34.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13637528687580713, "mean_inference_ms": 0.5566036016526924, "mean_action_processing_ms": 0.043325367961575906, "mean_env_wait_ms": 0.04763828734007168, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 676000, "agent_timesteps_total": 676000, "timers": {"sample_time_ms": 1585.825, "sample_throughput": 2522.347, "load_time_ms": 0.962, "load_throughput": 4159571.577, "learn_time_ms": 2128.725, "learn_throughput": 1879.059, "update_time_ms": 1.532}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00014316430315375328, "cur_lr": 4.999999873689376e-05, "total_loss": 18.009065628051758, "policy_loss": -0.08158732950687408, "vf_loss": 18.090620040893555, "vf_explained_var": 0.8477611541748047, "kl": 0.21969346702098846, "entropy": 0.11141622811555862, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 676000, "num_agent_steps_sampled": 676000, "num_steps_trained": 676000, "num_agent_steps_trained": 676000}, "done": false, "episodes_total": 135200, "training_iteration": 169, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-44", "timestamp": 1628629364, "time_this_iter_s": 3.7353270053863525, "time_total_s": 642.7925899028778, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 642.7925899028778, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 36.4, "ram_util_percent": 76.14}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 37.227500000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 35.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 35.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 34.05, 38.05, 38.05, 38.05, 30.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 30.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 35.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 34.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 35.05, 38.05, 38.05, 34.05, 30.05, 38.05, 38.05, 38.05, 30.050000000000004, 35.05, 38.05, 35.05, 38.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 30.05, 30.05, 38.05, 35.05, 38.05, 30.050000000000004, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 35.05, 38.05, 30.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 35.05, 38.05, 34.05, 30.050000000000004, 30.050000000000004, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13637708144542873, "mean_inference_ms": 0.5566127544970353, "mean_action_processing_ms": 0.04332501802844412, "mean_env_wait_ms": 0.04763994615469489, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 680000, "agent_timesteps_total": 680000, "timers": {"sample_time_ms": 1588.065, "sample_throughput": 2518.788, "load_time_ms": 0.962, "load_throughput": 4157922.181, "learn_time_ms": 2128.156, "learn_throughput": 1879.562, "update_time_ms": 1.52}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.00021474645473062992, "cur_lr": 4.999999873689376e-05, "total_loss": 3.0801198482513428, "policy_loss": -0.047439273446798325, "vf_loss": 3.1275365352630615, "vf_explained_var": 0.9730067849159241, "kl": 0.10567442327737808, "entropy": 0.1840793788433075, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 680000, "num_agent_steps_sampled": 680000, "num_steps_trained": 680000, "num_agent_steps_trained": 680000}, "done": false, "episodes_total": 136000, "training_iteration": 170, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-48", "timestamp": 1628629368, "time_this_iter_s": 3.73117995262146, "time_total_s": 646.5237698554993, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 646.5237698554993, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 37.4, "ram_util_percent": 76.10000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 34.54625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 35.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 34.05, 29.05, 29.05, 38.05, 34.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 35.05, 29.05, 38.05, 29.05, 34.05, 34.05, 38.05, 29.05, 34.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 34.05, 29.05, 38.05, 35.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 34.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 35.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 34.05, 38.05, 35.05, 38.05, 29.05, 29.05, 34.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 34.05, 34.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 34.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 34.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.05, 34.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 35.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 29.05, 29.05, 34.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 29.05, 29.05, 29.05, 34.05, 29.05, 34.05, 34.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 35.05, 38.05, 38.05, 29.05, 34.05, 29.05, 34.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 34.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 29.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 29.05, 38.05, 35.05, 29.05, 38.05, 38.05, 38.05, 35.05, 29.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 29.05, 38.05, 34.05, 38.05, 34.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 34.05, 38.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 34.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 34.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 29.05, 34.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 35.05, 29.05, 34.05, 38.05, 35.05, 38.05, 29.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 29.05, 29.05, 38.05, 38.05, 35.05, 35.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 34.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 30.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 35.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 29.05, 38.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13636969197148852, "mean_inference_ms": 0.5566115207853874, "mean_action_processing_ms": 0.04332174668913319, "mean_env_wait_ms": 0.04763853249460118, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 684000, "agent_timesteps_total": 684000, "timers": {"sample_time_ms": 1584.994, "sample_throughput": 2523.669, "load_time_ms": 0.961, "load_throughput": 4164010.821, "learn_time_ms": 2129.917, "learn_throughput": 1878.008, "update_time_ms": 1.549}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0003221196820959449, "cur_lr": 4.999999873689376e-05, "total_loss": 17.172847747802734, "policy_loss": -0.05670734867453575, "vf_loss": 17.229516983032227, "vf_explained_var": 0.8678821921348572, "kl": 0.10885783284902573, "entropy": 0.07964812219142914, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 684000, "num_agent_steps_sampled": 684000, "num_steps_trained": 684000, "num_agent_steps_trained": 684000}, "done": false, "episodes_total": 136800, "training_iteration": 171, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-51", "timestamp": 1628629371, "time_this_iter_s": 3.740677833557129, "time_total_s": 650.2644476890564, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 650.2644476890564, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 36.519999999999996, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.35375000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 35.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 29.05, 29.05, 29.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 35.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 29.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 29.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 29.05, 38.05, 38.05, 38.05, 29.05, 29.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13640505829226027, "mean_inference_ms": 0.5567718018139548, "mean_action_processing_ms": 0.043332621281793805, "mean_env_wait_ms": 0.04765282857525522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 688000, "agent_timesteps_total": 688000, "timers": {"sample_time_ms": 1595.357, "sample_throughput": 2507.276, "load_time_ms": 0.963, "load_throughput": 4155347.616, "learn_time_ms": 2144.05, "learn_throughput": 1865.628, "update_time_ms": 1.557}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0004831795231439173, "cur_lr": 4.999999873689376e-05, "total_loss": 4.862740516662598, "policy_loss": -0.022089697420597076, "vf_loss": 4.884793281555176, "vf_explained_var": 0.9588961601257324, "kl": 0.07651092112064362, "entropy": 0.0028531954158097506, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 688000, "num_agent_steps_sampled": 688000, "num_steps_trained": 688000, "num_agent_steps_trained": 688000}, "done": false, "episodes_total": 137600, "training_iteration": 172, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-02-56", "timestamp": 1628629376, "time_this_iter_s": 4.020359992980957, "time_total_s": 654.2848076820374, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 654.2848076820374, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 39.65, "ram_util_percent": 76.46666666666665}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.03875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13645569138674918, "mean_inference_ms": 0.5570007416344527, "mean_action_processing_ms": 0.04335071459941392, "mean_env_wait_ms": 0.04767277271478764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 692000, "agent_timesteps_total": 692000, "timers": {"sample_time_ms": 1611.74, "sample_throughput": 2481.79, "load_time_ms": 0.966, "load_throughput": 4140682.166, "learn_time_ms": 2166.075, "learn_throughput": 1846.658, "update_time_ms": 1.583}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0007247693138197064, "cur_lr": 4.999999873689376e-05, "total_loss": 0.09616579115390778, "policy_loss": -0.0019146567210555077, "vf_loss": 0.0980803370475769, "vf_explained_var": 0.9990689754486084, "kl": 0.00013910669076722115, "entropy": 0.0018501473823562264, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 692000, "num_agent_steps_sampled": 692000, "num_steps_trained": 692000, "num_agent_steps_trained": 692000}, "done": false, "episodes_total": 138400, "training_iteration": 173, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-00", "timestamp": 1628629380, "time_this_iter_s": 4.069067001342773, "time_total_s": 658.3538746833801, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 658.3538746833801, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 38.86, "ram_util_percent": 76.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13645133422820258, "mean_inference_ms": 0.5569887714959889, "mean_action_processing_ms": 0.043348648549900656, "mean_env_wait_ms": 0.047671103308187635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 696000, "agent_timesteps_total": 696000, "timers": {"sample_time_ms": 1612.839, "sample_throughput": 2480.099, "load_time_ms": 0.964, "load_throughput": 4148668.645, "learn_time_ms": 2168.141, "learn_throughput": 1844.898, "update_time_ms": 1.569}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0003623846569098532, "cur_lr": 4.999999873689376e-05, "total_loss": 0.07573382556438446, "policy_loss": -0.0019133661407977343, "vf_loss": 0.07764716446399689, "vf_explained_var": 0.9993559122085571, "kl": 7.21536562195979e-05, "entropy": 0.0011081031989306211, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 696000, "num_agent_steps_sampled": 696000, "num_steps_trained": 696000, "num_agent_steps_trained": 696000}, "done": false, "episodes_total": 139200, "training_iteration": 174, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-03", "timestamp": 1628629383, "time_this_iter_s": 3.7600860595703125, "time_total_s": 662.1139607429504, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 662.1139607429504, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 38.11666666666667, "ram_util_percent": 76.64999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 37.05, "episode_reward_mean": 38.04875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 37.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13644847849001263, "mean_inference_ms": 0.5569868045725261, "mean_action_processing_ms": 0.04334667218813178, "mean_env_wait_ms": 0.04767119581529938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 700000, "agent_timesteps_total": 700000, "timers": {"sample_time_ms": 1612.414, "sample_throughput": 2480.753, "load_time_ms": 0.966, "load_throughput": 4141602.113, "learn_time_ms": 2171.13, "learn_throughput": 1842.358, "update_time_ms": 1.567}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.0001811923284549266, "cur_lr": 4.999999873689376e-05, "total_loss": -0.0025581803638488054, "policy_loss": -0.003186034969985485, "vf_loss": 0.0006278418586589396, "vf_explained_var": 0.9999946355819702, "kl": 6.595629383809865e-05, "entropy": 0.0007454004371538758, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 700000, "num_agent_steps_sampled": 700000, "num_steps_trained": 700000, "num_agent_steps_trained": 700000}, "done": false, "episodes_total": 140000, "training_iteration": 175, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-07", "timestamp": 1628629387, "time_this_iter_s": 3.762028217315674, "time_total_s": 665.8759889602661, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 665.8759889602661, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 36.48, "ram_util_percent": 76.6}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.04625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13646579237213266, "mean_inference_ms": 0.5570616742521467, "mean_action_processing_ms": 0.04335208688823239, "mean_env_wait_ms": 0.04767800191855285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 704000, "agent_timesteps_total": 704000, "timers": {"sample_time_ms": 1618.683, "sample_throughput": 2471.145, "load_time_ms": 0.965, "load_throughput": 4145798.162, "learn_time_ms": 2171.354, "learn_throughput": 1842.169, "update_time_ms": 1.57}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 9.05961642274633e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.007953747175633907, "policy_loss": -0.001992989331483841, "vf_loss": 0.0099467309191823, "vf_explained_var": 0.9999133348464966, "kl": 5.740495453210315e-06, "entropy": 0.0005740972119383514, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 704000, "num_agent_steps_sampled": 704000, "num_steps_trained": 704000, "num_agent_steps_trained": 704000}, "done": false, "episodes_total": 140800, "training_iteration": 176, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-11", "timestamp": 1628629391, "time_this_iter_s": 3.7749600410461426, "time_total_s": 669.6509490013123, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 669.6509490013123, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 37.333333333333336, "ram_util_percent": 76.60000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13643530314174904, "mean_inference_ms": 0.5569299678791768, "mean_action_processing_ms": 0.043340687506603665, "mean_env_wait_ms": 0.04766693429784371, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 708000, "agent_timesteps_total": 708000, "timers": {"sample_time_ms": 1610.649, "sample_throughput": 2483.471, "load_time_ms": 0.96, "load_throughput": 4167010.084, "learn_time_ms": 2177.426, "learn_throughput": 1837.031, "update_time_ms": 1.591}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.529808211373165e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 0.0004612051125150174, "policy_loss": 0.0004612051125150174, "vf_loss": 1.4210854715202004e-14, "vf_explained_var": 1.0, "kl": 4.321800133766374e-06, "entropy": 0.0007746207993477583, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 708000, "num_agent_steps_sampled": 708000, "num_steps_trained": 708000, "num_agent_steps_trained": 708000}, "done": false, "episodes_total": 141600, "training_iteration": 177, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-15", "timestamp": 1628629395, "time_this_iter_s": 3.7265069484710693, "time_total_s": 673.3774559497833, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 673.3774559497833, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 27.880000000000003, "ram_util_percent": 76.52000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1364383702438855, "mean_inference_ms": 0.556951674166265, "mean_action_processing_ms": 0.04334057362994362, "mean_env_wait_ms": 0.04766932033446333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 712000, "agent_timesteps_total": 712000, "timers": {"sample_time_ms": 1612.184, "sample_throughput": 2481.106, "load_time_ms": 0.959, "load_throughput": 4169184.662, "learn_time_ms": 2174.376, "learn_throughput": 1839.609, "update_time_ms": 1.56}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.2649041056865826e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 3.765380097320303e-05, "policy_loss": 3.765380097320303e-05, "vf_loss": 1.1001951709692023e-14, "vf_explained_var": 1.0, "kl": 3.67741037621272e-08, "entropy": 0.0007951895822770894, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 712000, "num_agent_steps_sampled": 712000, "num_steps_trained": 712000, "num_agent_steps_trained": 712000}, "done": false, "episodes_total": 142400, "training_iteration": 178, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-19", "timestamp": 1628629399, "time_this_iter_s": 3.737337827682495, "time_total_s": 677.1147937774658, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 677.1147937774658, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 36.3, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13641565061234295, "mean_inference_ms": 0.5568780248286824, "mean_action_processing_ms": 0.04333296484678964, "mean_env_wait_ms": 0.04766366307569436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 716000, "agent_timesteps_total": 716000, "timers": {"sample_time_ms": 1613.81, "sample_throughput": 2478.606, "load_time_ms": 0.963, "load_throughput": 4151954.069, "learn_time_ms": 2174.407, "learn_throughput": 1839.582, "update_time_ms": 1.571}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.1324520528432913e-05, "cur_lr": 4.999999873689376e-05, "total_loss": 1.1338386684656143e-05, "policy_loss": 1.1338386684656143e-05, "vf_loss": 1.1001951709692023e-14, "vf_explained_var": 1.0, "kl": 2.896848272371244e-08, "entropy": 0.0008120819111354649, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 716000, "num_agent_steps_sampled": 716000, "num_steps_trained": 716000, "num_agent_steps_trained": 716000}, "done": false, "episodes_total": 143200, "training_iteration": 179, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-22", "timestamp": 1628629402, "time_this_iter_s": 3.7523248195648193, "time_total_s": 680.8671185970306, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 680.8671185970306, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 38.01666666666666, "ram_util_percent": 75.96666666666667}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13641197969296767, "mean_inference_ms": 0.5568708574204546, "mean_action_processing_ms": 0.0433308394467081, "mean_env_wait_ms": 0.04766269497617603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 720000, "agent_timesteps_total": 720000, "timers": {"sample_time_ms": 1612.65, "sample_throughput": 2480.389, "load_time_ms": 0.966, "load_throughput": 4140682.166, "learn_time_ms": 2175.205, "learn_throughput": 1838.907, "update_time_ms": 1.573}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.6622602642164566e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -1.802922270144336e-05, "policy_loss": -1.802922270144336e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.1457994730790233e-07, "entropy": 0.0008417095523327589, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 720000, "num_agent_steps_sampled": 720000, "num_steps_trained": 720000, "num_agent_steps_trained": 720000}, "done": false, "episodes_total": 144000, "training_iteration": 180, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-26", "timestamp": 1628629406, "time_this_iter_s": 3.7269701957702637, "time_total_s": 684.5940887928009, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 684.5940887928009, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 36.2, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13638377714221517, "mean_inference_ms": 0.5567456686953912, "mean_action_processing_ms": 0.0433197145329971, "mean_env_wait_ms": 0.04765303564906908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 724000, "agent_timesteps_total": 724000, "timers": {"sample_time_ms": 1606.886, "sample_throughput": 2489.286, "load_time_ms": 0.967, "load_throughput": 4135884.63, "learn_time_ms": 2178.231, "learn_throughput": 1836.352, "update_time_ms": 1.553}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.8311301321082283e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -3.0693049666297156e-06, "policy_loss": -3.0693049666297156e-06, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 4.119567051930062e-07, "entropy": 0.0009167294483631849, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 724000, "num_agent_steps_sampled": 724000, "num_steps_trained": 724000, "num_agent_steps_trained": 724000}, "done": false, "episodes_total": 144800, "training_iteration": 181, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-30", "timestamp": 1628629410, "time_this_iter_s": 3.712712049484253, "time_total_s": 688.3068008422852, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 688.3068008422852, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 35.5, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13638659751883475, "mean_inference_ms": 0.556767958694712, "mean_action_processing_ms": 0.043318918974376557, "mean_env_wait_ms": 0.04765474182008764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 728000, "agent_timesteps_total": 728000, "timers": {"sample_time_ms": 1599.957, "sample_throughput": 2500.068, "load_time_ms": 0.969, "load_throughput": 4129776.246, "learn_time_ms": 2160.649, "learn_throughput": 1851.296, "update_time_ms": 1.54}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.4155650660541141e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 1.920459180837497e-05, "policy_loss": 1.920459180837497e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.864096589088149e-06, "entropy": 0.0010818778537213802, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 728000, "num_agent_steps_sampled": 728000, "num_steps_trained": 728000, "num_agent_steps_trained": 728000}, "done": false, "episodes_total": 145600, "training_iteration": 182, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-34", "timestamp": 1628629414, "time_this_iter_s": 3.7740888595581055, "time_total_s": 692.0808897018433, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 692.0808897018433, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 36.78333333333333, "ram_util_percent": 75.94999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13635966984046047, "mean_inference_ms": 0.5566688851981008, "mean_action_processing_ms": 0.04330921228335704, "mean_env_wait_ms": 0.04764592234457602, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 732000, "agent_timesteps_total": 732000, "timers": {"sample_time_ms": 1582.849, "sample_throughput": 2527.088, "load_time_ms": 0.965, "load_throughput": 4145695.718, "learn_time_ms": 2140.568, "learn_throughput": 1868.663, "update_time_ms": 1.511}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 7.077825330270571e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -3.931790706701577e-05, "policy_loss": -3.931790706701577e-05, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 1.7873953765956685e-05, "entropy": 0.001678396831266582, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 732000, "num_agent_steps_sampled": 732000, "num_steps_trained": 732000, "num_agent_steps_trained": 732000}, "done": false, "episodes_total": 146400, "training_iteration": 183, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-37", "timestamp": 1628629417, "time_this_iter_s": 3.695646047592163, "time_total_s": 695.7765357494354, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 695.7765357494354, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 36.08, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.050000000000004, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.050000000000004, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13635295765182526, "mean_inference_ms": 0.5566481016567483, "mean_action_processing_ms": 0.04330509406410529, "mean_env_wait_ms": 0.04764449412700125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 736000, "agent_timesteps_total": 736000, "timers": {"sample_time_ms": 1582.207, "sample_throughput": 2528.115, "load_time_ms": 0.981, "load_throughput": 4076394.295, "learn_time_ms": 2140.011, "learn_throughput": 1869.149, "update_time_ms": 1.514}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.5389126651352854e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.07960895448923111, "policy_loss": -0.001852995133958757, "vf_loss": 0.08146194368600845, "vf_explained_var": 0.9992654323577881, "kl": 9.602213685866445e-05, "entropy": 0.0006559754256159067, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 736000, "num_agent_steps_sampled": 736000, "num_steps_trained": 736000, "num_agent_steps_trained": 736000}, "done": false, "episodes_total": 147200, "training_iteration": 184, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-41", "timestamp": 1628629421, "time_this_iter_s": 3.747978925704956, "time_total_s": 699.5245146751404, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 699.5245146751404, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 35.56, "ram_util_percent": 76.03999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13635393225834594, "mean_inference_ms": 0.5566637430210605, "mean_action_processing_ms": 0.043304366271768605, "mean_env_wait_ms": 0.04764624522000589, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 740000, "agent_timesteps_total": 740000, "timers": {"sample_time_ms": 1583.196, "sample_throughput": 2526.535, "load_time_ms": 0.979, "load_throughput": 4085825.337, "learn_time_ms": 2138.932, "learn_throughput": 1870.092, "update_time_ms": 1.504}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.7694563325676427e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.08636646717786789, "policy_loss": -0.08636656403541565, "vf_loss": 0.0, "vf_explained_var": 1.0, "kl": 0.5137965083122253, "entropy": 0.07914082705974579, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 740000, "num_agent_steps_sampled": 740000, "num_steps_trained": 740000, "num_agent_steps_trained": 740000}, "done": false, "episodes_total": 148000, "training_iteration": 185, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-45", "timestamp": 1628629425, "time_this_iter_s": 3.760511875152588, "time_total_s": 703.285026550293, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 703.285026550293, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 37.25, "ram_util_percent": 76.25000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 25.049999999999997, "episode_reward_mean": 33.37750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 25.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 30.049999999999997, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 35.05, 33.05, 33.05, 33.05, 33.05, 33.05, 25.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 35.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 30.049999999999997, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1363454926562276, "mean_inference_ms": 0.5566327282261603, "mean_action_processing_ms": 0.04330006522924876, "mean_env_wait_ms": 0.0476439881495442, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 744000, "agent_timesteps_total": 744000, "timers": {"sample_time_ms": 1577.738, "sample_throughput": 2535.276, "load_time_ms": 0.985, "load_throughput": 4060510.189, "learn_time_ms": 2143.826, "learn_throughput": 1865.823, "update_time_ms": 1.515}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.654184356742917e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.5850433111190796, "policy_loss": -0.0469551719725132, "vf_loss": 1.6319984197616577, "vf_explained_var": 0.9786728024482727, "kl": 0.10920114070177078, "entropy": 0.14876903593540192, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 744000, "num_agent_steps_sampled": 744000, "num_steps_trained": 744000, "num_agent_steps_trained": 744000}, "done": false, "episodes_total": 148800, "training_iteration": 186, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-49", "timestamp": 1628629429, "time_this_iter_s": 3.7699739933013916, "time_total_s": 707.0550005435944, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 707.0550005435944, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 36.08, "ram_util_percent": 76.22}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 35.95750000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 35.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 30.049999999999997, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 30.049999999999997, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 30.049999999999997, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 33.05, 38.05, 33.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 33.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 33.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 38.05, 33.05, 38.05, 33.05, 33.05, 33.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 33.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1363315707757176, "mean_inference_ms": 0.5565583359271735, "mean_action_processing_ms": 0.043292685892055635, "mean_env_wait_ms": 0.04763926489878509, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 748000, "agent_timesteps_total": 748000, "timers": {"sample_time_ms": 1580.703, "sample_throughput": 2530.52, "load_time_ms": 0.98, "load_throughput": 4082941.763, "learn_time_ms": 2137.353, "learn_throughput": 1871.474, "update_time_ms": 1.481}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.9812766772229224e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 4.293278217315674, "policy_loss": -0.06562761217355728, "vf_loss": 4.358905792236328, "vf_explained_var": 0.9556519389152527, "kl": 0.3333643674850464, "entropy": 0.010921599343419075, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 748000, "num_agent_steps_sampled": 748000, "num_steps_trained": 748000, "num_agent_steps_trained": 748000}, "done": false, "episodes_total": 149600, "training_iteration": 187, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-52", "timestamp": 1628629432, "time_this_iter_s": 3.691358804702759, "time_total_s": 710.7463593482971, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 710.7463593482971, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 29.78000000000001, "ram_util_percent": 76.02000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.049999999999997, "episode_reward_mean": 38.001250000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 33.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.049999999999997, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13634239463003953, "mean_inference_ms": 0.5566168147705128, "mean_action_processing_ms": 0.0432947591318847, "mean_env_wait_ms": 0.04764410768806208, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 752000, "agent_timesteps_total": 752000, "timers": {"sample_time_ms": 1582.858, "sample_throughput": 2527.074, "load_time_ms": 0.982, "load_throughput": 4074711.226, "learn_time_ms": 2138.806, "learn_throughput": 1870.202, "update_time_ms": 1.484}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 5.971915015834384e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.16076797246932983, "policy_loss": -0.10230517387390137, "vf_loss": 0.2630727291107178, "vf_explained_var": 0.9976893663406372, "kl": 0.726753294467926, "entropy": 0.3538358807563782, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 752000, "num_agent_steps_sampled": 752000, "num_steps_trained": 752000, "num_agent_steps_trained": 752000}, "done": false, "episodes_total": 150400, "training_iteration": 188, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-03-56", "timestamp": 1628629436, "time_this_iter_s": 3.7733869552612305, "time_total_s": 714.5197463035583, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 714.5197463035583, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 37.233333333333334, "ram_util_percent": 76.0}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 25.49000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.050000000000004, 35.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 20.050000000000004, 26.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 34.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 25.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 25.05, 35.05, 29.05, 20.050000000000004, 25.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 29.05, 34.05, 20.050000000000004, 31.049999999999997, 20.050000000000004, 20.050000000000004, 27.05, 29.05, 26.049999999999997, 29.05, 20.050000000000004, 27.05, 30.049999999999997, 20.050000000000004, 29.05, 38.05, 29.05, 29.05, 20.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 27.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 25.05, 29.05, 25.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 25.050000000000004, 20.050000000000004, 29.050000000000004, 25.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 27.050000000000004, 25.050000000000004, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 27.050000000000004, 34.05, 20.050000000000004, 29.05, 25.05, 29.05, 25.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 25.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 25.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 25.050000000000004, 25.05, 34.05, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 35.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 29.05, 38.05, 38.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 25.05, 25.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 25.050000000000004, 25.050000000000004, 20.050000000000004, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 35.05, 20.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 25.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 27.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 20.050000000000004, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 34.05, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 27.05, 25.05, 29.050000000000004, 20.050000000000004, 35.05, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 30.049999999999997, 20.050000000000004, 29.05, 25.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 36.05, 29.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 25.050000000000004, 29.05, 34.05, 29.05, 20.050000000000004, 29.05, 34.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 25.05, 34.05, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 27.050000000000004, 20.050000000000004, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 25.05, 29.05, 20.050000000000004, 25.05, 20.050000000000004, 29.05, 20.050000000000004, 25.05, 20.050000000000004, 25.05, 29.050000000000004, 25.05, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 25.05, 20.050000000000004, 25.05, 38.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 25.05, 29.05, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 36.05, 29.050000000000004, 30.049999999999997, 29.050000000000004, 25.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 36.05, 25.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 30.049999999999997, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 25.050000000000004, 25.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 27.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 25.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 20.050000000000004, 36.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 25.050000000000004, 38.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 34.05, 27.05, 25.05, 20.050000000000004, 29.05, 25.05, 20.050000000000004, 20.050000000000004, 36.05, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 25.050000000000004, 34.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.05, 29.05, 29.05, 34.05, 29.05, 34.05, 20.050000000000004, 29.050000000000004, 25.05, 20.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 20.050000000000004, 25.050000000000004, 20.050000000000004, 25.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 25.05, 29.05, 20.050000000000004, 27.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 36.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 25.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 34.05, 20.050000000000004, 38.05, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 25.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 34.05, 29.05, 26.05, 29.050000000000004, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 25.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 34.05, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 27.050000000000004, 25.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 30.049999999999997, 20.050000000000004, 25.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 25.05, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 27.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 25.050000000000004, 29.050000000000004, 21.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 29.050000000000004, 25.050000000000004, 29.050000000000004, 29.05, 34.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 20.050000000000004, 25.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 25.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 34.05, 25.05, 36.05, 25.05, 29.05, 34.05, 20.050000000000004, 20.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1363325463904624, "mean_inference_ms": 0.5565994908270566, "mean_action_processing_ms": 0.04329132461233999, "mean_env_wait_ms": 0.04764195294302368, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 756000, "agent_timesteps_total": 756000, "timers": {"sample_time_ms": 1585.555, "sample_throughput": 2522.776, "load_time_ms": 0.98, "load_throughput": 4082842.402, "learn_time_ms": 2134.947, "learn_throughput": 1873.583, "update_time_ms": 1.461}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.957872523751575e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 31.283517837524414, "policy_loss": -0.08286953717470169, "vf_loss": 31.36638832092285, "vf_explained_var": 0.7640011310577393, "kl": 0.029696915298700333, "entropy": 0.4043050706386566, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 756000, "num_agent_steps_sampled": 756000, "num_steps_trained": 756000, "num_agent_steps_trained": 756000}, "done": false, "episodes_total": 151200, "training_iteration": 189, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-00", "timestamp": 1628629440, "time_this_iter_s": 3.7396390438079834, "time_total_s": 718.2593853473663, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 718.2593853473663, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 36.019999999999996, "ram_util_percent": 76.11999999999999}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 28.26250000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 25.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 25.050000000000004, 34.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 20.050000000000004, 29.05, 38.05, 20.050000000000004, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 25.050000000000004, 29.050000000000004, 38.05, 36.05, 29.05, 29.05, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 27.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 25.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 30.049999999999997, 20.050000000000004, 29.05, 34.05, 34.05, 38.05, 20.050000000000004, 25.05, 29.050000000000004, 25.05, 36.05, 29.05, 29.050000000000004, 34.05, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 27.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 29.05, 34.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 25.050000000000004, 29.05, 34.05, 29.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 25.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 34.05, 29.05, 20.050000000000004, 34.05, 29.05, 38.05, 29.05, 25.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 25.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 38.05, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 25.050000000000004, 25.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 25.050000000000004, 29.050000000000004, 29.050000000000004, 25.05, 34.05, 34.05, 26.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 30.049999999999997, 29.05, 29.05, 29.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 30.049999999999997, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 34.05, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 25.050000000000004, 20.050000000000004, 38.05, 34.05, 30.049999999999997, 20.050000000000004, 29.05, 25.050000000000004, 29.05, 20.050000000000004, 38.05, 25.050000000000004, 34.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 25.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 34.05, 29.05, 34.05, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 25.05, 29.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 34.05, 25.05, 38.05, 29.05, 29.050000000000004, 29.05, 30.049999999999997, 26.05, 38.05, 29.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 36.05, 29.050000000000004, 20.050000000000004, 38.05, 34.05, 20.050000000000004, 20.050000000000004, 34.05, 34.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 38.05, 29.05, 27.05, 38.05, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 25.05, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 25.05, 29.050000000000004, 25.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 34.05, 34.05, 29.05, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 29.050000000000004, 29.05, 30.049999999999997, 20.050000000000004, 29.05, 29.05, 36.05, 29.05, 29.05, 34.05, 20.050000000000004, 29.050000000000004, 34.05, 36.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 25.050000000000004, 34.05, 29.050000000000004, 34.05, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 38.05, 38.05, 29.05, 27.05, 25.050000000000004, 20.050000000000004, 25.050000000000004, 34.05, 29.050000000000004, 30.049999999999997, 38.05, 32.05, 29.05, 29.05, 29.05, 34.05, 20.050000000000004, 20.050000000000004, 38.05, 29.05, 34.05, 20.050000000000004, 34.05, 29.05, 20.050000000000004, 34.05, 38.05, 34.05, 34.05, 29.05, 38.05, 29.05, 34.05, 20.050000000000004, 34.05, 25.05, 29.05, 29.05, 29.05, 20.050000000000004, 36.05, 29.050000000000004, 34.05, 20.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 25.050000000000004, 29.05, 29.05, 20.050000000000004, 29.05, 34.05, 29.050000000000004, 29.050000000000004, 29.05, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 34.05, 29.050000000000004, 34.05, 38.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 25.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.05, 29.050000000000004, 25.050000000000004, 25.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 26.050000000000004, 29.050000000000004, 25.05, 20.050000000000004, 29.05, 29.05, 34.05, 34.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 25.05, 25.050000000000004, 29.05, 20.050000000000004, 29.05, 26.050000000000004, 34.05, 29.05, 20.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 25.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 34.05, 29.05, 38.05, 34.05, 29.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 29.05, 20.050000000000004, 25.05, 36.05, 25.050000000000004, 25.05, 29.05, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 25.05, 29.050000000000004, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 29.05, 25.050000000000004, 29.050000000000004, 20.050000000000004, 38.05, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 25.05, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 29.05, 25.05, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 25.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 25.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 38.05, 29.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 25.050000000000004, 29.05, 27.05, 29.050000000000004, 34.05, 36.05, 25.05, 25.050000000000004, 29.05, 29.05, 27.05, 20.050000000000004, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 38.05, 38.05, 29.050000000000004, 29.05, 25.050000000000004, 38.05, 29.05, 29.050000000000004, 25.05, 29.050000000000004, 34.05, 29.05, 34.05, 29.05, 29.050000000000004, 20.050000000000004, 25.05, 29.05, 27.05, 29.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 36.05, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 25.050000000000004, 34.05, 29.05, 38.05, 36.05, 29.05, 34.05, 29.05, 34.05, 20.050000000000004, 29.05, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 36.05, 20.050000000000004, 29.050000000000004, 25.05, 34.05, 29.050000000000004, 34.05, 29.05, 20.050000000000004, 27.05, 38.05, 25.050000000000004, 20.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 29.05, 20.050000000000004, 38.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 34.05, 29.050000000000004, 34.05, 29.05, 25.05, 38.05, 29.05, 38.05, 25.050000000000004, 29.05, 38.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 29.05, 25.05, 29.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.05, 25.050000000000004, 38.05, 38.05, 29.05, 29.05, 34.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.05, 25.05, 25.050000000000004, 29.05, 29.05, 27.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 29.05, 38.05, 34.05, 20.050000000000004, 29.05, 29.05, 25.05, 25.05, 29.05, 25.05, 20.050000000000004, 38.05, 29.05, 34.05, 29.05, 20.050000000000004, 29.05, 25.05, 34.05, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 36.05, 25.050000000000004, 20.050000000000004, 38.05, 20.050000000000004, 25.050000000000004, 29.050000000000004, 25.050000000000004, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 20.050000000000004, 29.05, 20.050000000000004, 20.050000000000004, 34.05, 38.05, 29.05, 25.05, 29.05, 29.05, 29.050000000000004, 29.05, 29.050000000000004, 29.05, 32.05, 29.05, 38.05, 29.050000000000004, 20.050000000000004, 20.050000000000004, 25.05, 20.050000000000004, 20.050000000000004, 34.05, 35.05, 29.050000000000004, 29.050000000000004, 29.05, 29.05, 34.05, 25.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 20.050000000000004, 34.05, 38.05, 27.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 34.05, 20.050000000000004, 20.050000000000004, 20.050000000000004, 25.050000000000004, 29.05, 29.050000000000004, 29.05, 25.05, 29.05, 20.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13632631816737173, "mean_inference_ms": 0.5565616338574967, "mean_action_processing_ms": 0.04328699672923368, "mean_env_wait_ms": 0.047640300225018334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 760000, "agent_timesteps_total": 760000, "timers": {"sample_time_ms": 1584.725, "sample_throughput": 2524.097, "load_time_ms": 0.979, "load_throughput": 4084631.64, "learn_time_ms": 2138.899, "learn_throughput": 1870.121, "update_time_ms": 1.455}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.3436808785627363e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 23.751962661743164, "policy_loss": -0.08225990831851959, "vf_loss": 23.83422088623047, "vf_explained_var": 0.788131833076477, "kl": 0.035933319479227066, "entropy": 0.3927001357078552, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 760000, "num_agent_steps_sampled": 760000, "num_steps_trained": 760000, "num_agent_steps_trained": 760000}, "done": false, "episodes_total": 152000, "training_iteration": 190, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-04", "timestamp": 1628629444, "time_this_iter_s": 3.758462905883789, "time_total_s": 722.0178482532501, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 722.0178482532501, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 28.6, "ram_util_percent": 76.2}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 30.61500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.05, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 34.05, 29.050000000000004, 29.05, 34.05, 34.05, 20.050000000000004, 36.05, 36.05, 20.050000000000004, 29.050000000000004, 34.05, 30.049999999999997, 38.05, 25.050000000000004, 34.05, 29.050000000000004, 29.05, 34.05, 29.05, 34.05, 29.05, 29.050000000000004, 36.05, 34.05, 38.05, 34.05, 20.050000000000004, 34.05, 35.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 29.05, 25.05, 29.05, 36.05, 34.05, 20.050000000000004, 35.05, 38.05, 36.05, 20.050000000000004, 27.050000000000004, 34.05, 29.050000000000004, 29.05, 34.05, 20.050000000000004, 36.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 34.05, 29.05, 29.050000000000004, 34.05, 38.05, 38.05, 38.05, 32.05, 38.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 34.05, 25.05, 29.050000000000004, 34.05, 34.05, 38.05, 25.05, 34.05, 29.050000000000004, 34.05, 38.05, 34.05, 27.050000000000004, 20.050000000000004, 36.05, 34.05, 29.050000000000004, 29.05, 34.05, 20.050000000000004, 34.05, 34.05, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 36.05, 29.05, 29.050000000000004, 29.05, 35.05, 20.050000000000004, 29.05, 29.05, 29.050000000000004, 34.05, 36.05, 34.05, 38.05, 20.050000000000004, 29.05, 29.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 25.05, 34.05, 29.050000000000004, 29.050000000000004, 36.05, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 29.050000000000004, 38.05, 36.05, 34.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 29.05, 29.05, 29.05, 34.05, 29.05, 25.05, 34.05, 34.05, 29.05, 34.05, 29.050000000000004, 29.05, 29.05, 34.05, 29.050000000000004, 34.05, 29.05, 34.05, 38.05, 29.05, 29.05, 38.05, 29.05, 30.049999999999997, 29.05, 29.05, 29.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 29.050000000000004, 29.05, 34.05, 20.050000000000004, 29.050000000000004, 25.050000000000004, 38.05, 34.05, 34.05, 34.05, 38.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 38.05, 34.05, 29.05, 34.05, 20.050000000000004, 34.05, 29.05, 29.05, 38.05, 20.050000000000004, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 34.05, 27.050000000000004, 29.05, 29.050000000000004, 20.050000000000004, 29.05, 34.05, 34.05, 25.05, 34.05, 29.05, 38.05, 29.050000000000004, 29.05, 25.05, 29.05, 34.05, 29.05, 29.050000000000004, 34.05, 25.050000000000004, 34.05, 38.05, 29.050000000000004, 31.049999999999997, 29.050000000000004, 29.05, 20.050000000000004, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 20.050000000000004, 34.05, 29.05, 29.050000000000004, 34.05, 34.05, 25.05, 29.050000000000004, 36.05, 20.050000000000004, 34.05, 38.05, 29.050000000000004, 34.05, 29.05, 34.05, 34.05, 36.05, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 34.05, 38.05, 34.05, 38.05, 29.050000000000004, 29.05, 38.05, 34.05, 38.05, 34.05, 34.05, 25.05, 29.050000000000004, 25.05, 29.050000000000004, 38.05, 29.050000000000004, 35.05, 29.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 32.05, 34.05, 29.050000000000004, 35.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 34.05, 36.05, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 38.05, 29.050000000000004, 38.05, 29.050000000000004, 36.05, 29.050000000000004, 25.05, 20.050000000000004, 38.05, 34.05, 34.05, 29.050000000000004, 36.05, 34.05, 32.05, 34.05, 38.05, 29.05, 29.05, 38.05, 34.05, 29.050000000000004, 34.05, 29.05, 20.050000000000004, 34.05, 34.05, 29.050000000000004, 34.05, 25.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 34.05, 34.05, 38.05, 29.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 25.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 34.05, 38.05, 20.050000000000004, 29.05, 38.05, 34.05, 36.05, 29.050000000000004, 29.05, 29.05, 29.05, 34.05, 34.05, 35.05, 29.050000000000004, 29.05, 20.050000000000004, 27.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 20.050000000000004, 38.05, 27.05, 29.050000000000004, 29.050000000000004, 35.05, 34.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 29.05, 30.049999999999997, 34.05, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 34.05, 34.05, 34.05, 29.05, 32.05, 29.05, 29.05, 34.05, 29.050000000000004, 29.05, 29.050000000000004, 34.05, 29.050000000000004, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 38.05, 34.05, 34.05, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 29.05, 38.05, 34.05, 29.050000000000004, 29.05, 34.05, 34.05, 29.05, 34.05, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 29.05, 36.05, 29.05, 34.05, 36.05, 20.050000000000004, 38.05, 34.05, 34.05, 34.05, 30.049999999999997, 34.05, 36.05, 36.05, 38.05, 38.05, 29.05, 29.050000000000004, 29.05, 34.05, 20.050000000000004, 36.05, 20.050000000000004, 34.05, 38.05, 36.05, 34.05, 38.05, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 31.049999999999997, 20.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 29.05, 29.05, 29.050000000000004, 27.05, 29.050000000000004, 38.05, 29.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 29.05, 29.050000000000004, 29.05, 38.05, 36.05, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 29.05, 34.05, 29.050000000000004, 34.05, 38.05, 29.05, 20.050000000000004, 38.05, 29.05, 34.05, 34.05, 29.05, 20.050000000000004, 20.050000000000004, 25.05, 34.05, 29.05, 29.05, 29.05, 29.05, 38.05, 30.049999999999997, 34.05, 29.05, 20.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 29.05, 25.05, 38.05, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 29.05, 34.05, 29.05, 34.05, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 34.05, 29.05, 29.05, 35.05, 25.050000000000004, 29.05, 20.050000000000004, 38.05, 20.050000000000004, 29.050000000000004, 29.05, 29.05, 29.05, 20.050000000000004, 34.05, 29.05, 38.05, 38.05, 34.05, 29.05, 34.05, 20.050000000000004, 34.05, 34.05, 38.05, 29.050000000000004, 29.05, 34.05, 34.05, 29.050000000000004, 38.05, 29.05, 29.05, 34.05, 29.050000000000004, 34.05, 38.05, 34.05, 38.05, 38.05, 20.050000000000004, 29.050000000000004, 30.049999999999997, 29.05, 29.05, 25.05, 38.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.05, 20.050000000000004, 29.05, 34.05, 29.050000000000004, 20.050000000000004, 34.05, 34.05, 29.05, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 29.05, 34.05, 34.05, 29.05, 34.05, 25.05, 34.05, 38.05, 34.05, 20.050000000000004, 20.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 25.050000000000004, 29.05, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 29.05, 25.050000000000004, 29.050000000000004, 38.05, 29.050000000000004, 34.05, 38.05, 34.05, 29.050000000000004, 29.05, 34.05, 29.05, 29.050000000000004, 34.05, 20.050000000000004, 38.05, 36.05, 29.05, 29.05, 20.050000000000004, 34.05, 36.05, 34.05, 20.050000000000004, 34.05, 35.05, 38.05, 20.050000000000004, 29.050000000000004, 34.05, 38.05, 29.05, 36.05, 20.050000000000004, 38.05, 34.05, 34.05, 34.05, 36.05, 38.05, 20.050000000000004, 20.050000000000004, 25.050000000000004, 29.050000000000004, 29.05, 25.05, 20.050000000000004, 20.050000000000004, 32.05, 29.050000000000004, 36.05, 20.050000000000004, 34.05, 34.05, 20.050000000000004, 25.050000000000004, 20.050000000000004, 20.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 20.050000000000004, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 20.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 29.05, 34.05, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 20.050000000000004, 29.050000000000004, 20.050000000000004, 20.050000000000004, 34.05, 36.05, 29.050000000000004, 34.05, 29.05, 38.05, 38.05, 25.05, 29.05, 27.05, 29.05, 20.050000000000004, 29.05, 38.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 29.05, 29.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 38.05, 34.05, 36.05, 29.050000000000004, 29.050000000000004, 30.049999999999997, 36.05, 35.05, 34.05, 34.05, 20.050000000000004, 34.05, 29.050000000000004, 29.05, 29.05, 20.050000000000004, 20.050000000000004, 38.05, 29.050000000000004, 29.050000000000004, 38.05, 25.05, 29.05, 20.050000000000004, 29.050000000000004, 29.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13632561724155878, "mean_inference_ms": 0.5565575149849376, "mean_action_processing_ms": 0.04328493856622851, "mean_env_wait_ms": 0.04764100499124564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 764000, "agent_timesteps_total": 764000, "timers": {"sample_time_ms": 1590.789, "sample_throughput": 2514.475, "load_time_ms": 0.98, "load_throughput": 4081352.568, "learn_time_ms": 2136.411, "learn_throughput": 1872.299, "update_time_ms": 1.459}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.0155212041572668e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 22.272350311279297, "policy_loss": -0.07528404891490936, "vf_loss": 22.347637176513672, "vf_explained_var": 0.8076345324516296, "kl": 0.04385186731815338, "entropy": 0.3316803574562073, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 764000, "num_agent_steps_sampled": 764000, "num_steps_trained": 764000, "num_agent_steps_trained": 764000}, "done": false, "episodes_total": 152800, "training_iteration": 191, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-08", "timestamp": 1628629448, "time_this_iter_s": 3.748546838760376, "time_total_s": 725.7663950920105, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 725.7663950920105, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 37.25, "ram_util_percent": 76.13333333333334}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 20.050000000000004, "episode_reward_mean": 33.24000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 36.05, 29.05, 38.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 29.05, 34.05, 38.05, 29.050000000000004, 34.05, 29.050000000000004, 34.05, 34.05, 38.05, 29.050000000000004, 34.05, 34.05, 34.05, 36.05, 29.050000000000004, 29.05, 38.05, 36.05, 30.049999999999997, 29.050000000000004, 29.05, 38.05, 34.05, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 29.05, 25.05, 34.05, 34.05, 34.05, 29.050000000000004, 29.05, 34.05, 20.050000000000004, 38.05, 34.05, 29.050000000000004, 34.05, 30.049999999999997, 34.05, 34.05, 29.050000000000004, 34.05, 36.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 34.05, 34.05, 29.050000000000004, 38.05, 34.05, 38.05, 34.05, 36.05, 34.05, 34.05, 38.05, 34.05, 34.05, 29.050000000000004, 29.05, 34.05, 34.05, 38.05, 29.05, 36.05, 29.05, 34.05, 34.05, 38.05, 29.050000000000004, 34.05, 29.05, 34.05, 38.05, 34.05, 34.05, 38.05, 36.05, 34.05, 34.05, 34.05, 34.05, 38.05, 29.05, 34.05, 34.05, 29.05, 29.050000000000004, 34.05, 29.05, 34.05, 34.05, 29.050000000000004, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 36.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 38.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 35.05, 34.05, 34.05, 38.05, 38.05, 29.050000000000004, 29.05, 38.05, 26.050000000000004, 36.05, 35.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 29.050000000000004, 34.05, 34.05, 20.050000000000004, 34.05, 38.05, 34.05, 29.05, 38.05, 36.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 35.05, 34.05, 34.05, 29.050000000000004, 30.049999999999997, 38.05, 29.05, 34.05, 34.05, 34.05, 36.05, 34.05, 38.05, 29.050000000000004, 34.05, 34.05, 38.05, 34.05, 36.05, 35.05, 38.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 35.05, 36.05, 29.050000000000004, 38.05, 34.05, 29.050000000000004, 29.050000000000004, 20.050000000000004, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 36.05, 29.050000000000004, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 29.050000000000004, 29.05, 29.05, 29.050000000000004, 29.050000000000004, 38.05, 34.05, 29.050000000000004, 34.05, 38.05, 29.05, 36.05, 32.05, 38.05, 29.050000000000004, 29.05, 34.05, 34.05, 29.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 36.05, 29.05, 34.05, 34.05, 34.05, 20.050000000000004, 34.05, 34.05, 38.05, 34.05, 36.05, 34.05, 29.050000000000004, 20.050000000000004, 25.05, 34.05, 34.05, 38.05, 29.05, 30.049999999999997, 29.050000000000004, 34.05, 34.05, 36.05, 34.05, 34.05, 29.050000000000004, 38.05, 34.05, 29.050000000000004, 38.05, 38.05, 34.05, 36.05, 34.05, 38.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 29.05, 34.05, 34.05, 36.05, 20.050000000000004, 34.05, 36.05, 29.050000000000004, 20.050000000000004, 29.050000000000004, 29.050000000000004, 38.05, 34.05, 34.05, 29.050000000000004, 38.05, 34.05, 20.050000000000004, 34.05, 29.050000000000004, 29.050000000000004, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 34.05, 29.05, 29.05, 38.05, 38.05, 38.05, 29.050000000000004, 34.05, 30.049999999999997, 34.05, 38.05, 26.05, 34.05, 29.05, 34.05, 38.05, 32.05, 34.05, 34.05, 30.049999999999997, 34.05, 35.05, 34.05, 30.049999999999997, 35.05, 38.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 29.05, 29.050000000000004, 36.05, 34.05, 34.05, 35.05, 38.05, 34.05, 34.05, 34.05, 29.05, 34.05, 34.05, 34.05, 34.05, 36.05, 29.05, 38.05, 36.05, 38.05, 34.05, 34.05, 20.050000000000004, 34.05, 34.05, 34.05, 29.05, 34.05, 34.05, 34.05, 29.050000000000004, 25.05, 34.05, 34.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 38.05, 29.05, 34.05, 20.050000000000004, 38.05, 29.050000000000004, 36.05, 29.050000000000004, 38.05, 29.050000000000004, 30.049999999999997, 38.05, 29.05, 38.05, 29.05, 36.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 29.05, 34.05, 34.05, 38.05, 34.05, 29.050000000000004, 34.05, 34.05, 38.05, 29.05, 29.050000000000004, 29.05, 25.050000000000004, 29.05, 38.05, 34.05, 38.05, 29.050000000000004, 34.05, 34.05, 38.05, 38.05, 38.05, 29.050000000000004, 34.05, 38.05, 20.050000000000004, 34.05, 29.050000000000004, 36.05, 38.05, 29.050000000000004, 29.050000000000004, 29.05, 36.05, 29.05, 38.05, 34.05, 36.05, 38.05, 38.05, 34.05, 38.05, 34.05, 29.05, 34.05, 34.05, 38.05, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 29.05, 29.050000000000004, 36.05, 38.05, 34.05, 38.05, 29.050000000000004, 38.05, 38.05, 34.05, 34.05, 29.050000000000004, 34.05, 32.05, 29.050000000000004, 34.05, 29.050000000000004, 38.05, 29.050000000000004, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 29.05, 34.05, 34.05, 38.05, 34.05, 34.05, 34.05, 38.05, 29.05, 38.05, 34.05, 34.05, 35.05, 34.05, 29.050000000000004, 34.05, 34.05, 38.05, 25.050000000000004, 34.05, 38.05, 34.05, 38.05, 34.05, 38.05, 34.05, 35.05, 34.05, 38.05, 38.05, 29.05, 29.050000000000004, 34.05, 34.05, 36.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 34.05, 38.05, 20.050000000000004, 38.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 29.05, 34.05, 29.050000000000004, 34.05, 29.050000000000004, 38.05, 34.05, 34.05, 38.05, 34.05, 36.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 38.05, 38.05, 29.05, 34.05, 29.05, 38.05, 34.05, 32.05, 34.05, 29.05, 38.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 34.05, 34.05, 34.05, 36.05, 34.05, 38.05, 38.05, 29.050000000000004, 36.05, 25.05, 29.050000000000004, 34.05, 34.05, 36.05, 34.05, 38.05, 29.050000000000004, 38.05, 34.05, 29.050000000000004, 38.05, 29.050000000000004, 34.05, 34.05, 29.05, 38.05, 38.05, 34.05, 34.05, 36.05, 34.05, 34.05, 38.05, 38.05, 29.05, 34.05, 34.05, 30.049999999999997, 29.05, 38.05, 34.05, 34.05, 34.05, 29.05, 34.05, 38.05, 20.050000000000004, 29.050000000000004, 32.05, 29.05, 34.05, 29.050000000000004, 34.05, 34.05, 29.05, 34.05, 34.05, 36.05, 34.05, 34.05, 29.050000000000004, 20.050000000000004, 34.05, 34.05, 34.05, 34.05, 35.05, 36.05, 38.05, 29.050000000000004, 29.05, 29.05, 34.05, 34.05, 34.05, 38.05, 34.05, 34.05, 29.05, 29.05, 34.05, 34.05, 38.05, 29.050000000000004, 36.05, 34.05, 34.05, 34.05, 38.05, 29.050000000000004, 34.05, 25.05, 34.05, 38.05, 34.05, 38.05, 29.050000000000004, 34.05, 38.05, 34.05, 34.05, 36.05, 29.050000000000004, 34.05, 29.050000000000004, 38.05, 29.050000000000004, 34.05, 35.05, 38.05, 34.05, 34.05, 29.05, 20.050000000000004, 34.05, 34.05, 29.05, 29.05, 20.050000000000004, 34.05, 29.05, 34.05, 34.05, 38.05, 29.050000000000004, 29.05, 34.05, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 38.05, 36.05, 29.050000000000004, 34.05, 34.05, 34.05, 34.05, 34.05, 29.05, 34.05, 34.05, 34.05, 34.05, 34.05, 38.05, 38.05, 34.05, 29.05, 29.050000000000004, 34.05, 34.05, 34.05, 38.05, 34.05, 20.050000000000004, 34.05, 34.05, 29.05, 38.05, 34.05, 29.05, 29.050000000000004, 29.050000000000004, 29.050000000000004, 34.05, 34.05, 38.05, 38.05, 34.05, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 29.050000000000004, 34.05, 34.05, 38.05, 34.05, 29.05, 34.05, 34.05, 36.05, 29.05, 34.05, 34.05, 34.05, 34.05, 20.050000000000004, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 29.05, 34.05, 29.050000000000004], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1363213144410188, "mean_inference_ms": 0.5565628009577703, "mean_action_processing_ms": 0.043283530483466226, "mean_env_wait_ms": 0.04764138669864661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 768000, "agent_timesteps_total": 768000, "timers": {"sample_time_ms": 1589.353, "sample_throughput": 2516.748, "load_time_ms": 0.978, "load_throughput": 4089809.371, "learn_time_ms": 2134.454, "learn_throughput": 1874.015, "update_time_ms": 1.472}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.0232820336095756e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 13.269057273864746, "policy_loss": -0.06979943811893463, "vf_loss": 13.338858604431152, "vf_explained_var": 0.8851678967475891, "kl": 0.40781694650650024, "entropy": 0.13149690628051758, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 768000, "num_agent_steps_sampled": 768000, "num_steps_trained": 768000, "num_agent_steps_trained": 768000}, "done": false, "episodes_total": 153600, "training_iteration": 192, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-11", "timestamp": 1628629451, "time_this_iter_s": 3.7414891719818115, "time_total_s": 729.5078842639923, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 729.5078842639923, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 35.94, "ram_util_percent": 76.02000000000001}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.21500000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 34.05, 36.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 34.05, 38.05, 36.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 36.05, 38.05, 35.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 34.05, 34.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 34.05, 34.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 29.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 35.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 36.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 36.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 36.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 34.05, 38.05, 36.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 29.05, 38.05, 36.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 36.05, 34.05, 34.05, 36.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 36.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 34.05, 29.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13633016736385967, "mean_inference_ms": 0.5565942914833903, "mean_action_processing_ms": 0.04328498596330395, "mean_env_wait_ms": 0.04764536141167653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 772000, "agent_timesteps_total": 772000, "timers": {"sample_time_ms": 1596.888, "sample_throughput": 2504.871, "load_time_ms": 0.976, "load_throughput": 4097300.413, "learn_time_ms": 2137.572, "learn_throughput": 1871.282, "update_time_ms": 1.493}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.534922936727526e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 2.7219319343566895, "policy_loss": -0.02571147121489048, "vf_loss": 2.74764347076416, "vf_explained_var": 0.976386547088623, "kl": 0.0040987334214150906, "entropy": 0.12925730645656586, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 772000, "num_agent_steps_sampled": 772000, "num_steps_trained": 772000, "num_agent_steps_trained": 772000}, "done": false, "episodes_total": 154400, "training_iteration": 193, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-15", "timestamp": 1628629455, "time_this_iter_s": 3.8022451400756836, "time_total_s": 733.310129404068, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 733.310129404068, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 36.31666666666667, "ram_util_percent": 76.06666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 37.556250000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 36.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 34.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 35.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 34.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 36.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 36.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 34.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13631071274516032, "mean_inference_ms": 0.5565095908430416, "mean_action_processing_ms": 0.043277110317713884, "mean_env_wait_ms": 0.04763898111350203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 776000, "agent_timesteps_total": 776000, "timers": {"sample_time_ms": 1593.077, "sample_throughput": 2510.864, "load_time_ms": 0.959, "load_throughput": 4171361.512, "learn_time_ms": 2142.547, "learn_throughput": 1866.937, "update_time_ms": 1.495}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.267461468363763e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 1.6375547647476196, "policy_loss": -0.034381717443466187, "vf_loss": 1.6719361543655396, "vf_explained_var": 0.9854799509048462, "kl": 0.18734155595302582, "entropy": 0.001481186831369996, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 776000, "num_agent_steps_sampled": 776000, "num_steps_trained": 776000, "num_agent_steps_trained": 776000}, "done": false, "episodes_total": 155200, "training_iteration": 194, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-19", "timestamp": 1628629459, "time_this_iter_s": 3.759993076324463, "time_total_s": 737.0701224803925, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 737.0701224803925, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 36.62, "ram_util_percent": 76.08}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 35.05, "episode_reward_mean": 38.04625000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 35.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13645972572621723, "mean_inference_ms": 0.5568596835999621, "mean_action_processing_ms": 0.04329096349357865, "mean_env_wait_ms": 0.04765577415148163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 780000, "agent_timesteps_total": 780000, "timers": {"sample_time_ms": 1613.577, "sample_throughput": 2478.965, "load_time_ms": 0.973, "load_throughput": 4109242.677, "learn_time_ms": 2159.125, "learn_throughput": 1852.602, "update_time_ms": 1.531}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 3.401192316232482e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.009341660887002945, "policy_loss": -0.0015719105722382665, "vf_loss": 0.010913575999438763, "vf_explained_var": 0.9999064803123474, "kl": 0.00015855478704907, "entropy": 0.0003912376123480499, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 780000, "num_agent_steps_sampled": 780000, "num_steps_trained": 780000, "num_agent_steps_trained": 780000}, "done": false, "episodes_total": 156000, "training_iteration": 195, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-23", "timestamp": 1628629463, "time_this_iter_s": 4.133089780807495, "time_total_s": 741.2032122612, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 741.2032122612, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 41.6, "ram_util_percent": 75.21666666666665}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 29.05, "episode_reward_mean": 38.03875000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 29.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13646114033125695, "mean_inference_ms": 0.5568603227689075, "mean_action_processing_ms": 0.04328916111290357, "mean_env_wait_ms": 0.04765773069432166, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 784000, "agent_timesteps_total": 784000, "timers": {"sample_time_ms": 1615.314, "sample_throughput": 2476.298, "load_time_ms": 0.972, "load_throughput": 4116098.135, "learn_time_ms": 2154.207, "learn_throughput": 1856.832, "update_time_ms": 1.503}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.700596158116241e-06, "cur_lr": 4.999999873689376e-05, "total_loss": 0.09642794728279114, "policy_loss": -0.0019097952172160149, "vf_loss": 0.09833774715662003, "vf_explained_var": 0.9991595149040222, "kl": 2.0722764020320028e-05, "entropy": 0.00024936586851254106, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 784000, "num_agent_steps_sampled": 784000, "num_steps_trained": 784000, "num_agent_steps_trained": 784000}, "done": false, "episodes_total": 156800, "training_iteration": 196, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-27", "timestamp": 1628629467, "time_this_iter_s": 3.7398200035095215, "time_total_s": 744.9430322647095, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 744.9430322647095, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 36.3, "ram_util_percent": 75.5}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13645859639121996, "mean_inference_ms": 0.55684514361722, "mean_action_processing_ms": 0.04328650868073544, "mean_env_wait_ms": 0.04765730981945072, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 788000, "agent_timesteps_total": 788000, "timers": {"sample_time_ms": 1618.268, "sample_throughput": 2471.778, "load_time_ms": 0.979, "load_throughput": 4087418.019, "learn_time_ms": 2160.456, "learn_throughput": 1851.461, "update_time_ms": 1.499}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 8.502980790581205e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.001041565672494471, "policy_loss": -0.001041565672494471, "vf_loss": 1.1918781018833025e-14, "vf_explained_var": 1.0, "kl": 1.0985269909724593e-05, "entropy": 0.00045013934141024947, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 788000, "num_agent_steps_sampled": 788000, "num_steps_trained": 788000, "num_agent_steps_trained": 788000}, "done": false, "episodes_total": 157600, "training_iteration": 197, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-31", "timestamp": 1628629471, "time_this_iter_s": 3.7836480140686035, "time_total_s": 748.7266802787781, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 748.7266802787781, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 36.68333333333333, "ram_util_percent": 74.86666666666666}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1364346994001423, "mean_inference_ms": 0.556735804514926, "mean_action_processing_ms": 0.043276805458599715, "mean_env_wait_ms": 0.04764832520029702, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 792000, "agent_timesteps_total": 792000, "timers": {"sample_time_ms": 1608.546, "sample_throughput": 2486.718, "load_time_ms": 0.979, "load_throughput": 4084731.089, "learn_time_ms": 2161.654, "learn_throughput": 1850.435, "update_time_ms": 1.5}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 4.2514903952906025e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -2.8620695957215503e-05, "policy_loss": -2.8620695957215503e-05, "vf_loss": 9.16829309141002e-15, "vf_explained_var": 1.0, "kl": 4.493201899435917e-08, "entropy": 0.00048559383139945567, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 792000, "num_agent_steps_sampled": 792000, "num_steps_trained": 792000, "num_agent_steps_trained": 792000}, "done": false, "episodes_total": 158400, "training_iteration": 198, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-34", "timestamp": 1628629474, "time_this_iter_s": 3.689412832260132, "time_total_s": 752.4160931110382, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 752.4160931110382, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 35.96, "ram_util_percent": 74.34}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 38.05, "episode_reward_mean": 38.05000000000001, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13644606576116874, "mean_inference_ms": 0.5567852367548813, "mean_action_processing_ms": 0.04327867586773047, "mean_env_wait_ms": 0.04765294192968006, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 796000, "agent_timesteps_total": 796000, "timers": {"sample_time_ms": 1612.952, "sample_throughput": 2479.926, "load_time_ms": 0.979, "load_throughput": 4086024.355, "learn_time_ms": 2160.938, "learn_throughput": 1851.048, "update_time_ms": 1.512}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 2.1257451976453012e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 1.9442681150394492e-05, "policy_loss": 1.9442681150394492e-05, "vf_loss": 8.251463782269017e-15, "vf_explained_var": 1.0, "kl": 6.731494295308948e-08, "entropy": 0.0005036158836446702, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 796000, "num_agent_steps_sampled": 796000, "num_steps_trained": 796000, "num_agent_steps_trained": 796000}, "done": false, "episodes_total": 159200, "training_iteration": 199, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-04-38", "timestamp": 1628629478, "time_this_iter_s": 3.777448892593384, "time_total_s": 756.1935420036316, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 756.1935420036316, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 27.96, "ram_util_percent": 74.4}, "trial_id": "c64d4_00000"}
{"episode_reward_max": 38.05, "episode_reward_min": 30.05, "episode_reward_mean": 38.040000000000006, "episode_len_mean": 5.0, "episode_media": {}, "episodes_this_iter": 800, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 30.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05, 38.05], "episode_lengths": [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13645428786828195, "mean_inference_ms": 0.5568173870674409, "mean_action_processing_ms": 0.04327980725248535, "mean_env_wait_ms": 0.047655174505538314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 800000, "agent_timesteps_total": 800000, "timers": {"sample_time_ms": 1616.322, "sample_throughput": 2474.755, "load_time_ms": 0.978, "load_throughput": 4090607.11, "learn_time_ms": 240113.227, "learn_throughput": 16.659, "update_time_ms": 1.534}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 1.0628725988226506e-07, "cur_lr": 4.999999873689376e-05, "total_loss": 0.07643452286720276, "policy_loss": -0.0018955538980662823, "vf_loss": 0.07833006978034973, "vf_explained_var": 0.9992958307266235, "kl": 3.364995791343972e-05, "entropy": 0.00014966710295993835, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 800000, "num_agent_steps_sampled": 800000, "num_steps_trained": 800000, "num_agent_steps_trained": 800000}, "done": true, "episodes_total": 160000, "training_iteration": 200, "experiment_id": "9091230cbcaa4de89f94433901c57612", "date": "2021-08-10_23-44-22", "timestamp": 1628631862, "time_this_iter_s": 2383.3160688877106, "time_total_s": 3139.509610891342, "pid": 88155, "hostname": "Annas-MBP", "node_ip": "192.168.1.19", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "SimpleRllibEnv", "env_config": {"episode_length": 5, "n_agents": 1}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3139.509610891342, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 36.528571428571425, "ram_util_percent": 74.21428571428571}, "trial_id": "c64d4_00000"}
